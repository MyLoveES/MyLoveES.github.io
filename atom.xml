<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>三点水</title>
  
  <subtitle>不积小流，无以成江海</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lotabout.me/"/>
  <updated>2021-05-22T10:33:50.833Z</updated>
  <id>https://lotabout.me/</id>
  
  <author>
    <name>Jinzhou Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>我的内存呢？Linux MemAvailable 如何计算</title>
    <link href="https://lotabout.me/2021/Linux-Available-Memory/"/>
    <id>https://lotabout.me/2021/Linux-Available-Memory/</id>
    <published>2021-05-20T21:16:23.000Z</published>
    <updated>2021-05-22T10:33:50.833Z</updated>
    
    <content type="html"><![CDATA[<p>使用 Linux 开发时最常见的问题是：我的内存呢？怎么只剩这么点了？这是怎么回事了呢？</p><h2 id="消失的内存"><a class="header-anchor" href="#消失的内存"></a>消失的内存</h2><p>通常我们会用 <code>free</code> 命令（如下）或 Node Exporter + Prometheus 来监控系统的内存。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ free -h</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           31Gi        13Gi       8.0Gi       747Mi        10Gi        16Gi</span><br><span class="line">Swap:         2.0Gi       321Mi       1.7Gi</span><br></pre></td></tr></table></figure><p>上面的输出中，我们很自然地以为 <code>free</code> 代表可以内存，所以经常会发现这个值特别低，造成“系统的内存用光了”的错觉。在比较新的内核里，<strong>会有 <code>available</code> 一项，它才是“可用内存”</strong>。</p><p>这里有个小知识，<code>free</code> 指的是完全没有被用到的内存，而 Linux 认为内存不用也是浪费，因此会尽量“多”地把内存用来做各种缓存，提高系统的性能。在内存不够用时，它会释放缓存腾出空间给应用程序。因此早期没有 <code>available</code> 这项指标时，一般会认为<code>free + buff/cache</code> 是系统当前的可用内存。那么现在的 <code>available</code> 是如何计算得到的？</p><h2 id="memavailable-估算"><a class="header-anchor" href="#memavailable-估算"></a>MemAvailable 估算</h2><p><code>free</code> 命令只输出简单几项指标，更详细的指标可以用 <code>cat /proc/meminfo</code> 得到：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MemTotal:       32729276 kB</span><br><span class="line">MemFree:         8348128 kB</span><br><span class="line">MemAvailable:   17735588 kB</span><br><span class="line">Active:         13969564 kB</span><br><span class="line">Inactive:        8494392 kB</span><br><span class="line">Active(anon):   10878224 kB</span><br><span class="line">Inactive(anon):  2218284 kB</span><br><span class="line">Active(file):    3091340 kB</span><br><span class="line">Inactive(file):  6276108 kB</span><br><span class="line">Unevictable:      212164 kB</span><br><span class="line">Slab:            1293804 kB</span><br><span class="line">SReclaimable:     487588 kB</span><br><span class="line">SUnreclaim:       806216 kB</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>指标非常多，一般需要对内核有一定了解才能看懂。这些指标的基础上，有<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MemAvailable &lt;&#x3D; MemFree + Active(file) + Inactive(file) + SReclaimable</span><br><span class="line">17735588 kB  &lt;&#x3D; 8348128 + 3091340 + 6276108 + 487588 &#x3D; 18203164 kB</span><br></pre></td></tr></table></figure><p>要理解这个公式，需要了解 Linux 是如何管理内存的。Linux 对内存的管理有多种视角。</p><ul><li>系统内存 = 空闲内存 + 内核内存 + 用户内存</li><li>内核内存<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> = Slab + VmallocUsed + PageTables + KernelStack + HardwareCorrupted + Bounce + X<ul><li>Slab = SUnreclaim + SReclaimable，其中 <code>SReclaimable</code> 指可回收部分</li></ul></li><li>用户内存有两个视角：<ul><li>LRU 视角 = Active + Inactive + Unevictable + (HugePages_Total * Hugepagesize)<ul><li>Active 与 Inactive 内存指的是活跃程度，如果内存紧张，会优先释放Inactive 的内存</li><li>Active = Active(File) + Inactive(Anon)</li><li>Inactive = Inactive(File) + Inactive(Anon)</li><li>File-Backend 内存会与磁盘中的文件关联，于是如果内存不足时可以先写回磁盘释放内存；Anonymous 内存不与文件关联，因此除非有 swap 文件，否则无法释放</li></ul></li><li>缓存视角 = Cached + AnonPages + Buffers + (HugePages_Total * Hugepagesize)</li></ul></li></ul><p>结合上述信息，可以看到可以释放的部分有：</p><ul><li>Slab 的 <code>SReclaimable</code>，是内核可释放的部分</li><li>所有的 File-Backend 内存 = Active(File) + Inactive(File)</li></ul><p>MemAvailable 公式的由来就很自然而然了。等等！？公式里的符号为什么是小于等于，不是等于？</p><h2 id="详细逻辑与样例"><a class="header-anchor" href="#详细逻辑与样例"></a>详细逻辑与样例</h2><p>上面的公式在详细计算时，并没有考虑 <code>watermark</code>（虽然代码里有），并且最新的内核已经修改了计算的公式<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，考虑了更多的内容。</p><ol><li><p>计算 <code>wmark_low</code>。low watermark，当系统可用内存小于 low watermark 时，<code>kswapd</code> 进程会开始尝试释放内存页。首先收集需要的信息：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep min</span><br><span class="line">        min      1</span><br><span class="line">        min      184</span><br><span class="line">        min      16710</span><br></pre></td></tr></table></figure><p>每个 ZONE 都有自己的 low watermark（单位为页，页大小为 4K），计算如下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wmark_low &#x3D; (1 + 230 + 20887) * 4</span><br><span class="line">          &#x3D; 84472 (KB)</span><br></pre></td></tr></table></figure></li><li><p>计算空闲页 <code>free_pages</code>，可以直接由 <code>/proc/zoneinfo</code> 中获取：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo |grep &#39;free &#39;</span><br><span class="line">    nr_free_pages 3969</span><br><span class="line">    nr_free_pages 611300</span><br><span class="line">    nr_free_pages 59976587</span><br></pre></td></tr></table></figure><p>加总即得到 <code>free_pages</code>:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free_pages &#x3D; (3969 + 611300 + 59976587) * 4</span><br><span class="line">           &#x3D; 242367424 (KB)</span><br></pre></td></tr></table></figure></li><li><p>计算保留内存<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。保留内存需要综合考虑各项指标：</p><ol><li><p><code>lowmem_reserve_ratio</code> ZONE<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> 是逻辑上的划分，lowmem 是指低位的 ZONE 为高位 ZONE 预留的内存<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。每个 ZONE 都会为更高位的 ZONE 做预留，因此结果是个矩阵：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep &#39;protection&#39;</span><br><span class="line">        protection: (0, 2815, 257771, 257771)</span><br><span class="line">        protection: (0, 0, 254955, 254955)</span><br><span class="line">        protection: (0, 0, 0, 0)</span><br></pre></td></tr></table></figure></li><li><p>high watermark。高水位线，可用内存超出它时，<code>kswapd</code> 会暂停工作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep &#39;high &#39;</span><br><span class="line">        high     1</span><br><span class="line">        high     276</span><br><span class="line">        high     25065</span><br></pre></td></tr></table></figure></li><li><p>managed 内存，没查到出处，大概指可被使用的内存。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep &#39;managed&#39;</span><br><span class="line">        managed  3977</span><br><span class="line">        managed  720847</span><br><span class="line">        managed  65268660</span><br></pre></td></tr></table></figure></li><li><p>计算如下：<code>total_reserved = Σ(min((max(lowmem) + high_watermark), managed))</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">total_reserved &#x3D; Σ(min((max(lowmem) + high_watermark), managed))</span><br><span class="line">               &#x3D;   min(max(0, 2815, 257771, 257771) + 1,     3977)</span><br><span class="line">                 + min(max(0, 0, 254955, 254955)    + 276,   720847)</span><br><span class="line">                 + min(max(0, 0, 0, 0)              + 25065, 65268660)</span><br><span class="line">               &#x3D; 3977 + 255231 + 25065</span><br><span class="line">               &#x3D; 284273  (page)</span><br><span class="line">               &#x3D; 1137092 (kB)</span><br></pre></td></tr></table></figure></li></ol></li></ol><ol start="4"><li><p>计算 <code>pagecache = active file + inactive file</code>，File Backend 的内存可以被释放。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo |grep nr_active_file</span><br><span class="line">    nr_active_file 0</span><br><span class="line">    nr_active_file 6032</span><br><span class="line">    nr_active_file 168031</span><br><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep nr_inactive_file</span><br><span class="line">    nr_inactive_file 0</span><br><span class="line">    nr_inactive_file 1833</span><br><span class="line">    nr_inactive_file 50064</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pagecache &#x3D; active file + inactive file</span><br><span class="line">          &#x3D; (0 + 6032 + 168031) + (0 + 1833 + 50064)</span><br><span class="line">          &#x3D; 225960 (page)</span><br><span class="line">          &#x3D; 903840 (kB)</span><br></pre></td></tr></table></figure></li><li><p><code>pagecache -= min(pagecache / 2, wmark_low)</code>，并不是所有的 pagecache 都被认为是可用的：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pagecache -&#x3D; min(pagecache &#x2F; 2, wmark_low)</span><br><span class="line">          -&#x3D; min(903840&#x2F;2, 84472)</span><br><span class="line">          -&#x3D; 84472</span><br><span class="line">           &#x3D; 903840 - 84472</span><br><span class="line">           &#x3D; 819368 (KB)</span><br></pre></td></tr></table></figure></li><li><p>计算 <code>SReclaimable</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;zoneinfo | grep nr_slab_reclaimable</span><br><span class="line">    nr_slab_reclaimable 0</span><br><span class="line">    nr_slab_reclaimable 428</span><br><span class="line">    nr_slab_reclaimable 36989</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SReclaimable &#x3D; (0 + 428 + 36989) * 4</span><br><span class="line">             &#x3D; 149668 (kB)</span><br></pre></td></tr></table></figure></li><li><p><code>SReclaimable -= min(SReclaimable/2, wmark_low)</code>，和 pagecache 相似，不能全用。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SReclaimable -&#x3D; min(SReclaimable&#x2F;2, wmark_low)</span><br><span class="line">             -&#x3D; min(149668 &#x2F; 2, 84472)</span><br><span class="line">             -&#x3D; 74834</span><br><span class="line">              &#x3D; 149668 - 74834</span><br><span class="line">              &#x3D; 74834 (kB)</span><br></pre></td></tr></table></figure></li><li><p><code>available = free_pages - total_reserved + pagecache + SReclaimable</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">available &#x3D; 242367424 - 1137092 + 819368 + 74834</span><br><span class="line">          &#x3D; 242124534 (kB)</span><br></pre></td></tr></table></figure></li></ol><p>最终的结果与 <code>/proc/meminfo</code> 的输出（和上小节的数据不同）只有细微的区别：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;proc&#x2F;meminfo</span><br><span class="line">MemFree:        242385648 kB</span><br><span class="line">MemAvailable:   242137968 kB</span><br><span class="line">Active(file):     689852 kB</span><br><span class="line">Inactive(file):   209196 kB</span><br><span class="line">SReclaimable:     149668 kB</span><br></pre></td></tr></table></figure><p>实际上差了约 13MB 左右，不过 zoneinfo 和 meminfo 的输出中间有少许的时间间隔，不确定是不是中间内存有了变化。</p><h2 id="补充：进程内存"><a class="header-anchor" href="#补充：进程内存"></a>补充：进程内存</h2><p>知道了系统级别的统计方法，自然会想和进程级别的统计做个对应关系。虽然有不少统计进程内存使用的方法，但基本上没办法精确地和系统统计对应。进程的统计指标一般有这几个：</p><ul><li><code>VSZ</code>：虚拟内存，不直接对应到物理内存</li><li><code>RSS</code>：常驻内存，可以理解成映射的内存的总和。注意进程间有共享的内存页（如libc 库），不同进程加总时会重复计算这部分</li><li><code>PSS</code>：与 <code>RSS</code> 几乎相同，区别在计算时进程共享的内存时，除于了共享的进程数量，因此可以用来加总</li><li><code>USS</code>：该进程独立占用的内存，即扣除了共享的内存页</li></ul><p><code>VSZ</code> 和 <code>RSS</code> 可以直接通过 <code>ps aux</code> 输出：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ps aux|head</span><br><span class="line">USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root           1  0.0  0.0 169416 13364 ?        Ss   May11   0:15 /sbin/init splash</span><br><span class="line">root           2  0.0  0.0      0     0 ?        S    May11   0:00 [kthreadd]</span><br><span class="line">root           3  0.0  0.0      0     0 ?        I&lt;   May11   0:00 [rcu_gp]</span><br></pre></td></tr></table></figure><p><code>PSS</code> 和 <code>USS</code> 可以通过 <code>/proc/&lt;pid&gt;/smaps</code> 中的字段统计得到。也可以用工具<a href="https://www.selenic.com/smem/" target="_blank" rel="noopener">smem</a> 直接输出和统计。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># PSS：通过 Pss 字段相加得到</span><br><span class="line">cat &#x2F;proc&#x2F;&lt;PID&gt;&#x2F;smaps | awk &#39;BEGIN &#123;i&#x3D;0&#125; &#x2F;^Pss&#x2F; &#123;i &#x3D; i + $2&#125; END &#123;print i&#125;&#39;</span><br><span class="line"></span><br><span class="line"># USS：通过 Private_Clean 和 Private_Dirty 相加得到</span><br><span class="line">cat &#x2F;proc&#x2F;&lt;PID&gt;&#x2F;smaps | awk &#39;BEGIN &#123;i&#x3D;0&#125; &#x2F;^Private&#x2F; &#123;i &#x3D; i + $2&#125; END &#123;print i&#125;&#39;</span><br></pre></td></tr></table></figure><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>介绍了几个知识点：</p><ol><li><code>free</code> 中的 <code>available</code> 才是可用内存/剩余内存</li><li><code>MemAvailable &lt;= MemFree + Active(file) + Inactive(file) + SReclaimable</code></li><li>MemAvailable 具体的计算方式，涉及到 ZONE, lowmem, watermark 等知识</li><li>补充了进程内存的一些统计方式（RSS、PSS、USS）</li></ol><p>好吧，对写业务的我其实也没什么用。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://access.redhat.com/solutions/22177" target="_blank" rel="noopener">https://access.redhat.com/solutions/22177</a> RedHat 对 <code>/proc/meminfo</code> 的解释</li><li><a href="https://access.redhat.com/sites/default/files/attachments/memory_usage.pdf" target="_blank" rel="noopener">Analyzing Memory Usage in Red Hat EnterpriseLinux</a>对进程内存和物理内存映射关系的讲解</li><li><a href="https://fritshoogland.files.wordpress.com/2018/02/linux-memory-explained.pdf" target="_blank" rel="noopener">LINUX MEMORY EXPLAINED</a>对进程的 VSZ、RSS、PSS、USS 有详细讲解</li><li><a href="http://linuxperf.com/?cat=7" target="_blank" rel="noopener">/PROC/MEMINFO之谜</a> 讲解了 meminfo 中一些“加起来不刚好”的项的原理</li><li><a href="https://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="noopener">https://man7.org/linux/man-pages/man5/proc.5.html</a> <code>/proc/smaps</code> 文件格式</li><li><a href="https://www.kernel.org/doc/Documentation/vm/pagemap.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/vm/pagemap.txt</a> <code>/proc/pagemap</code> 文件格式，内容上可以理解为是 smaps 的数据来源</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>这也是早期的大致计算逻辑：<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea</a> <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p><a href="https://segmentfault.com/a/1190000022518282" target="_blank" rel="noopener">linux内存占用分析之meminfo</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p>MemAvailable 计算的源码入口：<a href="https://elixir.bootlin.com/linux/v4.6/source/mm/page_alloc.c#L3732" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/v4.6/source/mm/page_alloc.c#L3732</a> <a href="#fnref3" class="footnote-backref">↩</a></p></li><li id="fn4" class="footnote-item"><p>保留内存的计算源码入口：<a href="https://elixir.bootlin.com/linux/v4.6/source/mm/page_alloc.c#L6248" target="_blank" rel="noopener">https://elixir.bootlin.com/linux/v4.6/source/mm/page_alloc.c#L6248</a> <a href="#fnref4" class="footnote-backref">↩</a></p></li><li id="fn5" class="footnote-item"><p>Linux 会将物理内存切分成几个 ZONE，在 64 位机器上，一般有 <code>ZONE_DMA</code>,<code>ZONE_DMA32</code> 和<code>ZONE_NORMAL</code>，是为了兼容早期的硬件设计而划分的。 <a href="#fnref5" class="footnote-backref">↩</a></p></li><li id="fn6" class="footnote-item"><p>关于 lowmem 和 ZONE 的细致讲解：<a href="https://zhuanlan.zhihu.com/p/68465952" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/68465952</a> <a href="#fnref6" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用 Linux 开发时最常见的问题是：我的内存呢？怎么只剩这么点了？这是怎么回事了呢？&lt;/p&gt;
&lt;h2 id=&quot;消失的内存&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#消失的内存&quot;&gt;&lt;/a&gt;消失的内存&lt;/h2&gt;
&lt;p&gt;通常我们会用 &lt;code&gt;fre
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="Linux" scheme="https://lotabout.me/tags/Linux/"/>
    
      <category term="Memory" scheme="https://lotabout.me/tags/Memory/"/>
    
  </entry>
  
  <entry>
    <title>Linux sysctl 网络相关参数</title>
    <link href="https://lotabout.me/2021/Linux-TCP-Options/"/>
    <id>https://lotabout.me/2021/Linux-TCP-Options/</id>
    <published>2021-05-01T14:06:23.000Z</published>
    <updated>2021-05-22T10:33:50.833Z</updated>
    
    <content type="html"><![CDATA[<p>本文对<a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" target="_blank" rel="noopener">ip-sysctl.txt</a>中关于 IP 和 TCP 部分的配置做了翻译，同时加了一些个人的理解，旨在见文知义。</p><p>（博主不是搞网络的，也不是搞内核的，如有错误请指正）</p><h2 id="ip-未分类"><a class="header-anchor" href="#ip-未分类"></a>IP 未分类</h2><h3 id="ip-forward-boolean"><a class="header-anchor" href="#ip-forward-boolean"></a>ip_forward - BOOLEAN</h3><ul><li><code>0</code> 代表关闭</li><li>非 <code>0</code> 代表开启。</li></ul><p>注：可以简单理解为开启了就是路由器了</p><h3 id="ip-default-ttl-integer"><a class="header-anchor" href="#ip-default-ttl-integer"></a>ip_default_ttl - INTEGER</h3><p>向外发送的 IP 报文（非转发报文）的默认 TTL(Time to Live) 值。</p><ul><li>范围为 1 到 255</li><li>默认值 64</li></ul><p>注：TTL 即“跳”。当前的实现里，每过一个路由会减少一跳，TTL 为 0 时会被路由器丢弃。</p><h3 id="ip-no-pmtu-disc-integer"><a class="header-anchor" href="#ip-no-pmtu-disc-integer"></a>ip_no_pmtu_disc - INTEGER</h3><p>是否关闭路径 MTU 发现功能 (Path MTU Discovery)</p><ul><li>0: 开启 MTU 发现（默认值 ）</li><li>1:，代表关闭，此时如果接收到“需要分片”的 ICMP 报文，则会将路径上的 PMTU设置成 <code>min_pmtu</code>。如果不希望 IP 报文被分片，则需要手工修改系统的<code>min_pmtu</code></li><li>2: 接收到的路径 MTU 发现消息会被丢弃，发送帧的处理同模式 1</li><li>3: 为强化的 PMTU 发现模式。（具体功能比较复杂，看不懂）</li></ul><p>注：MTU(Max Transmission Unit) 指的是每个网络包的有效载荷，是链路层的概念。以太网的 MTU 默认是 1500B（注意不包含以太网的包头包尾），但因为它是链路层的概念，上层的 IP 数据包头部、TCP 数据包头部的长度也要算在内，因此扣除 IP 头部的20B，以及 TCP 头部的 20B，TCP 包的 payload 也只能是 1460B 了。</p><p>路径 MTU 指的是路径上所有 MTU 的最小值，注意 MTU 是有方向的，A -&gt; B 的路径 MTU不等于 B-&gt; A 的路径 MTU。</p><p>路径 MTU 发现依赖两个要素：IP 头中的 DF 标志以及 ICMP 的“需要分片”报文。当 IP报文设置了 DF 标志，如果某个路由的 MTU 小于报文大小，则因为设置了 DF 标志，路由会丢弃这个 IP 包，并返回“需要分片” ICMP 报文，报文里会携带路由的 MTU，这样发送方就可以逐步学习到路径上的最小 MTU（参考 <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>）。</p><h3 id="min-pmtu-integer"><a class="header-anchor" href="#min-pmtu-integer"></a>min_pmtu - INTEGER</h3><p>最小的路径 MTU，默认为 <code>522</code></p><h3 id="ip-forward-use-pmtu-boolean"><a class="header-anchor" href="#ip-forward-use-pmtu-boolean"></a>ip_forward_use_pmtu - BOOLEAN</h3><p>默认情况在转发报文时不信任 PMTU 的结果，因为很容易伪造，会导致不需要的分组碎片。除非上面跑着自己的应用程序需要使用 PMTU，一般不需要。</p><ul><li>0（默认） 代表不使用 PMTU</li><li>1 代表使用 PMTU</li></ul><h3 id="fwmark-reflect-boolean"><a class="header-anchor" href="#fwmark-reflect-boolean"></a>fwmark_reflect - BOOLEAN</h3><p>控制内核产生的 IPv4 包的 fwmark，只对不与端口绑定的包生效，如 TCP RST 报文、ICMP echo 应答报文。如果选项设置为 <code>0</code>，则这些包的 fwmark 被设置为 0,如果选项设置为 <code>1</code>，则这些应答报文的 fwmark 会被设置为它们应答的原报文的值。</p><p>注：fwmark 是 firewall mark 的简称。Linux（及其它操作系统）通常允许指定一些规则（如通过 iptables），将一些符合规则的网络包打上标签，即为 fwmark。fwmark 可以用在路由的转发规则（基于策略的路由 <code>ip rule</code>）中，达到诸如：满足某个条件的包走哪个网卡的功能。</p><p>fwmark_reflect 解决的是这样的问题<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>：假设有机器是多网卡，正常情况下我们需要让包“从哪来到哪去”，于是会使用 fwmark 写规则。除了“从哪来到哪去”的需求，还会有“不要回答”的需求，例如有人攻击了机器，我们不希望机器回答如destination port unreachable 的 ICMP 报文，因为这样会透露一些机器的信息。但是我们希望将这些报文路由到内部的审计端口中，而不是发回原始的端口，有了fwmark_reflect 就可以方便地对 ICMP 做标记从而做更复杂的路由策略了。</p><h3 id="fib-multipath-use-neigh-boolean"><a class="header-anchor" href="#fib-multipath-use-neigh-boolean"></a>fib_multipath_use_neigh - BOOLEAN</h3><p>有多路径的路由下决定下一跳时，是否考虑已经存在的邻居表的状态。如果关闭选项，则不使用邻居表信息，数据包被定向到的下一跳有可能是不通的。需要在编译内核时开启<code>CONFIG_IP_ROUTE_MULTIPATH</code> 选项时才可使用。</p><ul><li>0: 关闭（默认）</li><li>1: 开启</li></ul><p>注：与该参数相关的是 ECMP(Equal Cost Multi Path) 功能，是路由里的一项技术。简单地说，它是一种通过一致性哈希将包发送到一组权重相同的网络设备的方式。虽然边缘路由器通常不关心包发到哪里，但一般希望同一个 Flow （四元组：源IP/Port、目标IP/port）的包以相同的路径经过各个设备<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。</p><p>注：邻居表<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>存储了当前主机物理连接的主机的地址信息（MAC），Linux 通过 ARP 协议来管理、更新。</p><h3 id="fib-multipath-hash-policy-integer"><a class="header-anchor" href="#fib-multipath-hash-policy-integer"></a>fib_multipath_hash_policy - INTEGER</h3><p>ECMP 使用的哈希算法，内核编译时开启了 <code>CONFIG_IP_ROUTE_MULTIPATH</code> 选项才生效。</p><ul><li>0 - L3 (source and destination addresses plus flow label) 默认值</li><li>1 - L4  (standard 5-tuple)</li><li>2 - Layer 3 or inner Layer 3 if present</li></ul><p>注：在 ECMP 中，要对一个包进行负载均衡，做哈希时会依赖多种信息<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>:</p><ul><li>L3: 指 IP 层，会使用如下信息做哈希<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;source address, destination address&#125;</span><br></pre></td></tr></table></figure></li><li>L4: 指 TCP/UDP 层，会使用如下信息做哈希<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;source address, destination address, protocol, source port, destination port&#125;</span><br></pre></td></tr></table></figure></li><li>IPv6 L3: 会使用如下信息做哈希，IPv6 因为有 Flow Label，所以 L3 也可以达到 L4的效果<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;source address, destination address, flow label, next header (protocol)&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="fib-sync-mem-unsigned-integer"><a class="header-anchor" href="#fib-sync-mem-unsigned-integer"></a>fib_sync_mem - UNSIGNED INTEGER</h3><p>在 synchronize_rcu 被强制触发前可用于存储 fib 条目的脏内存</p><ul><li>默认值 512KB</li><li>最小值 64KB</li><li>最大值 64MB</li></ul><p>注：RCU<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> 可以理解成内核的一个读写锁机制，它将“更新”操作分解成“移除”和“清理”两个步骤。例如一个指针 P，现在指向 A，要更新成指向 B，则会先将 P 置为 NULL，此时不会有新的读者引用 A，再等待老的引用了 A 的读者退出，此时可以清理A 对应的资源，再将 P 指向 B。<code>synchronize_rcu</code> 指的是该机制中等待已有读者退出的 API。</p><h3 id="ip-forward-update-priority-integer"><a class="header-anchor" href="#ip-forward-update-priority-integer"></a>ip_forward_update_priority - INTEGER</h3><p>转发一个 IPv4 的包后，是否要用 IP 头中的 TOS 字段来更新 SKB 优先级。新的 SKB优先级通过 <code>rt_tos2priority</code> 映射表获得（参见 <code>man tc-prio</code>）</p><ul><li>0: 不更新优先级</li><li>1: 更新优先级（默认）</li></ul><p>注：SKB 指的是 socket buffer，SKB 结构中有个字段 <code>priority</code> 用来指定报文在outgoing 队列的优先级。而 TOS<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> 是 IP 协议中用来指定 IP 报文优先级的字段。因此该选项相当于是指定在转发 IP 报文时，要不要支持 TOS 功能。</p><h3 id="route-max-size-integer"><a class="header-anchor" href="#route-max-size-integer"></a>route/max_size - INTEGER</h3><p>内核中允许的最大路由条数。如果使用了大量的网卡或加了很多路由项，则考虑加大该参数。从 3.6 开始，对 ipv4 该参数不再推荐使用，因为不再使用路由缓存。</p><h3 id="neigh-default-gc-thresh1-integer"><a class="header-anchor" href="#neigh-default-gc-thresh1-integer"></a>neigh/default/gc_thresh1 - INTEGER</h3><p>最小保存条数。当邻居表中的条数小于该数值，则 GC 不会做任何清理</p><ul><li>默认值 128</li></ul><h3 id="neigh-default-gc-thresh2-integer"><a class="header-anchor" href="#neigh-default-gc-thresh2-integer"></a>neigh/default/gc_thresh2 - INTEGER</h3><p>高于该阈值时，GC 会变得更激进，此时存在时间大于 5s 的条目会被清理</p><ul><li>默认值 512</li></ul><h3 id="neigh-default-gc-thresh3-integer"><a class="header-anchor" href="#neigh-default-gc-thresh3-integer"></a>neigh/default/gc_thresh3 - INTEGER</h3><p>允许的最大临时条目数。当使用的网卡数很多，或直连了很多其它机器时考虑增大该参数。</p><ul><li>默认值：1024</li></ul><h3 id="neigh-default-unres-qlen-bytes-integer"><a class="header-anchor" href="#neigh-default-unres-qlen-bytes-integer"></a>neigh/default/unres_qlen_bytes - INTEGER</h3><p>对每个未解析的地址，所有排队报文允许占用的最大字节数。（Linux 3.3 新增）。负值无效且返回错误。</p><ul><li><p>默认值：<code>SK_WMEM_MAX</code>（与 <code>net.core.wmem_default</code> 相同）</p><p>具体值随架构和内核版本有变化，一般需要能允许中等大小的 256 个报文排队</p></li></ul><h3 id="neigh-default-unres-qlen-integer"><a class="header-anchor" href="#neigh-default-unres-qlen-integer"></a>neigh/default/unres_qlen - INTEGER</h3><p>对每个未解析的地址，允许排队的最大报文数。（Linux 3.3 不推荐使用）：建议用新的<code>unres_qlen_bytes</code> 参数，Linux 3.3 之前默认参数为 3，有时会有意料之外的包丢失，现在的值是通过 <code>unres_qlen_bytes</code> 和真实的包大小计算得到的。</p><h3 id="mtu-expires-integer"><a class="header-anchor" href="#mtu-expires-integer"></a>mtu_expires - INTEGER</h3><p>缓存的 PMTU 信息过期时间，秒</p><h3 id="min-adv-mss-integer"><a class="header-anchor" href="#min-adv-mss-integer"></a>min_adv_mss - INTEGER</h3><p>通告 MSS（Advertised MSS）由第一跳路由的 MTU 决定，但不能小于这个值。</p><h2 id="ip-分片"><a class="header-anchor" href="#ip-分片"></a>IP 分片</h2><h3 id="ipfrag-high-thresh-long-integer"><a class="header-anchor" href="#ipfrag-high-thresh-long-integer"></a>ipfrag_high_thresh - LONG INTEGER</h3><p>重组 IP 分片时使用的最大内存</p><p>注：一旦用尽，分片处理程序会丢弃分片，直到 ipfrag_low_thresh。</p><h3 id="ipfrag-low-thresh-long-integer"><a class="header-anchor" href="#ipfrag-low-thresh-long-integer"></a>ipfrag_low_thresh - LONG INTEGER</h3><p>(linux-4.17 开始弃用) 重组 IP 分片使用的内存下限，超过该值后内会通过移除不完整的分片队列来释放资源。过程中内核依旧会接收新的分片。</p><h3 id="ipfrag-time-integer"><a class="header-anchor" href="#ipfrag-time-integer"></a>ipfrag_time - INTEGER</h3><p>一个 IP 分片在内存中保留的最大时间，秒</p><h3 id="ipfrag-max-dist-integer"><a class="header-anchor" href="#ipfrag-max-dist-integer"></a>ipfrag_max_dist - INTEGER</h3><p>该参数定义了同一个 IP 源的数据分片所允许的最大“失序程度”。IP 分片乱序到达的情况并非不常见，但如果从某个源 IP 上已经收到了许多分片，而其中的某个分片队列的分片还不完整，则多半该队列中的一片或多片数据已经丢失了。<code>ipfrag_max_dist</code> 为正时，分片在加入重组队列前会做一个额外的检查：如果某个队列两次加入新分片期间，来自某个源 IP 的分片数量超过了 <code>ipfrag_max_dist</code> ，则认为该队列的某些分片已经丢失，现有的队列会被丢弃，被替换成了一个新队列。<code>ipfrag_max_dist</code> 为<code>0</code>时关闭该检查。</p><p>如果该值过小，如 <code>1</code> 或 <code>2</code>，则正常的重排序现象也会引发不必要的队列丢弃，进而导致性能下降；而过大的值，如 <code>50000</code> 则会导致不同 IP 数据报文的分片错误重组在一起的可能性，导致数据出错。</p><ul><li>默认值：64</li></ul><p>注：TCP/IP 详解一书中提到，一般 TCP 会尽量通过设置 MSS 来使底层的 IP 报文不分片。</p><h2 id="inet-peer-存储"><a class="header-anchor" href="#inet-peer-存储"></a>INET peer 存储</h2><p>注：INET peer 是 IP 层的实现概念。与本机有交互的主机就叫 IP peer。出于性能的考虑，Linux 会为每个主机保存一些 IP 相关的信息，其中最重要的是 IP 的数据包 ID(packet ID) <sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。</p><h3 id="inet-peer-threshold-integer"><a class="header-anchor" href="#inet-peer-threshold-integer"></a>inet_peer_threshold - INTEGER</h3><p>允许的最大存储的估计值。当存储大于该阈值后，系统会激进地丢弃 peer 条目。该阈值同时也决定了 peer 条目的 TTL 以及两次 GC 的时间间隔。条目数据越多，TTL 越短，GC 越频繁。</p><h3 id="inet-peer-minttl-integer"><a class="header-anchor" href="#inet-peer-minttl-integer"></a>inet_peer_minttl - INTEGER</h3><p>条目的最小 TTL。在 IP 报文重组端，要保证大于分片的 TTL。当条目池使用的存储小于 <code>inet_peer_threshold</code> 时，则该最小的 TTL 是系统能保证满足的，如果超过阈值则可能被提前回收。单位为秒。</p><h3 id="inet-peer-maxttl-integer"><a class="header-anchor" href="#inet-peer-maxttl-integer"></a>inet_peer_maxttl - INTEGER</h3><p>条目的最大 TTL。在没有内存压力的前提下，没被使用的条目超过该时间就会失效。单位为秒。</p><h2 id="tcp-变量"><a class="header-anchor" href="#tcp-变量"></a>TCP 变量</h2><ul><li>参考：<a href="https://man7.org/linux/man-pages/man7/tcp.7.html" target="_blank" rel="noopener">https://man7.org/linux/man-pages/man7/tcp.7.html</a></li></ul><h3 id="somaxconn-integer"><a class="header-anchor" href="#somaxconn-integer"></a>somaxconn - INTEGER</h3><p>socket API <code>listen</code> 允许设置的积压（backlog）。默认值为 <code>4096</code>（Linux 5.4 之前为 <code>128</code>）。更多的关于 TCP socket 调参，也可以参考 <code>tcp_max_syn_backlog</code></p><p>注<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>：</p><ul><li>该值是在 <code>listen</code> 中不设置 backlog 时的默认值，而 <code>tcp_max_syn_backlog</code> 是上限。</li><li>这是个常调的参数。TCP 三次握手的 server 端有两个队列，一个是 syn queue，存储接收到第一次握手 SYN 连接（SYN_RECV）信息，当第三次握手 ACK 到来时，会将连接信息从 syn queue 移到 accept queue，等待调用 <code>accept()</code> 取走连接信息，这里设置的是 accept queue 的大小。</li><li>当第三次握手 ACK 到来，在尝试将连接从 syn queue 移动到 accept queue 时，如果accept queue 满了，则会完全忽略该 ACK，server 一段时间认为还没收到 ACK，会重发SYN+ACK，client 会重发 ACK。</li><li>当 accept queue 满了，即使 syn queue 没满，新的 SYN 也会被忽略</li></ul><p>在 Linux 中的术语中，SYN queue 一般称为 SYN backlog，accept queue 就称为accept queue。为什么 <code>socket</code> 选项的参数称为 <code>backlog</code> 呢？猜想 socket API 是BSD 风格的，而在 BSD 风格的实现中，并没有两个 queue。</p><h3 id="tcp-abort-on-overflow-boolean"><a class="header-anchor" href="#tcp-abort-on-overflow-boolean"></a>tcp_abort_on_overflow - BOOLEAN</h3><p>如果用户程序调用 accept 的速度太慢，新的连接没法被及时 accept，则重置连接（通过发送 RST）。该值默认为 False，意味着如果瞬时涌入了大量连接，server 会等待负载（accept 能力）慢慢恢复。<strong>只有</strong>在你真的确认用户程序没法更快 accept 连接的时候才设置成 True。设置这个参数可能会损害 client（如虽然服务还在，只是负载高，但 client 认为服务不存在）</p><p>注：这里和在 <a href="#somaxconn-integer">somaxconn</a> 中提到的 accept queue 满了有关，当接到 ACK 时队列满了，默认情况下是完全忽略该 ACK，这样 server 认为在一段时间内没有收到 ACK，会重发 SYN+ACK，client 重发 ACK，server 接收第二个 ACK 时如果accept queue 又有空间了，就能恢复连接。如果 <code>tcp_abort_on_overflow</code> 设置成True 且发生接到 ACK 时 accept queue 满的情况，则会直接重置连接。</p><h3 id="tcp-adv-win-scale-integer"><a class="header-anchor" href="#tcp-adv-win-scale-integer"></a>tcp_adv_win_scale - INTEGER</h3><p>指定计算缓冲 Overhead 的方式：如果 <code>tcp_adv_win_scale &gt; 0</code> 则为<code>bytes/2^tcp_adv_win_scale</code> 否则为<code>bytes - bytes/2^(-tcp_adv_win_scale)</code>。</p><ul><li>默认值：1（低版本默认值是 2）</li><li>可选值：[-31, 31]</li></ul><p>注：所谓的缓冲 overhead 指的是<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>：正常一个 TCP 的报文，除了包中的数据(payload)外，还会有 TCP 头、IP 头、以太头等；此外内核在存储报文时，还会有 <code>sk_buff</code> 和 <code>skb_shared_info</code> 等开销。因此在 TCP 层计算通告窗口时，需要把这部分排除在外。注意的是 <code>tcp_adv_win_scale</code> 的实际作用其实是指定数据和额外开销的比例的，和 <a href="#tcp-app-win-integer">tcp_app_win</a> 区分开。</p><p>注：<a href="https://man7.org/linux/man-pages/man7/tcp.7.html" target="_blank" rel="noopener">man 7 tcp</a> 中提到 socket的缓冲区分为内核部分和应用部分，其中内核部分用来维护 TCP Window，应用部分的作用是“used to isolate the network from scheduling and application latencies”，具体指的应该是上面说的 <code>skb_shared_info</code> 结构，对 TCP 本身没什么用，但对其它模块有用。</p><h3 id="tcp-allowed-congestion-control-string"><a class="header-anchor" href="#tcp-allowed-congestion-control-string"></a>tcp_allowed_congestion_control - STRING</h3><p>设置允许普通进程(non-privileged process)使用的拥塞控制算法。这个参数的值阈是<code>tcp_available_congestion_control</code> 参数的子集。默认值为 “reno” 加上<code>tcp_congestion_control</code> 参数设置的算法。</p><p>注：可以通过 <code>setsockopt</code> API 的 <code>TCP_CONGESTION</code> 参数为某个连接单独设置拥塞控制算法。</p><h3 id="tcp-app-win-integer"><a class="header-anchor" href="#tcp-app-win-integer"></a>tcp_app_win - INTEGER</h3><p>保留 <code>max(window/2^tcp_app_win, mss)</code> 大小的缓冲作为用户缓冲（参考<a href="#tcp-adv-win-scale-integer">tcp_adv_win_scale</a>）。当值为 <code>0</code> 时有特殊含义，代表不保留。</p><ul><li>默认值：31</li></ul><p>注：在 TCP 初始化(<a href="https://github.com/torvalds/linux/blob/master/net/ipv4/tcp_input.c#L504" target="_blank" rel="noopener">tcp_init_buffer_space</a>)缓冲时会为 application 预留一些空间，即由该值指定。与<a href="#tcp-adv-win-scale-integer">tcp_adv_win_scale</a> 不同的是，<code>tcp_adv_win_scale</code>是用来指定 overhead 在计算时的比例的，在初始化时，在窗口增长时都会用到，但<code>tcp_app_win</code> 只会在初始化时用到。</p><h3 id="tcp-autocorking-boolean"><a class="header-anchor" href="#tcp-autocorking-boolean"></a>tcp_autocorking - BOOLEAN</h3><p>是否开遍 TCP auto corking: 当应用程序连续调用 <code>write()/sendmsg()</code> 系统调用写入小量数据，内核会尽量将这些调用合并，减少需要发送的数据包数量。当同一个流(flow)至少有一个之前的数据包在 Qdisc 队列或设备发送队列中等待时才会做合并。选项开启的情况下，应用层依旧可以使用 <code>TCP_CORK</code> 选项来决定是否启用合并功能。</p><ul><li>默认值：1（开启）</li></ul><p>注：Qdisc 队列指的是 Queueing Discipling 队列，是 IP 协议栈与驱动队列之间的队列，实现的是 Linux 内核的流量管理功能，包括流量分类、优先级排序和整流功能<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。</p><h3 id="tcp-available-congestion-control-string"><a class="header-anchor" href="#tcp-available-congestion-control-string"></a>tcp_available_congestion_control - STRING</h3><p>只读选项，列出可用的拥塞控制算法。</p><h3 id="tcp-base-mss-integer"><a class="header-anchor" href="#tcp-base-mss-integer"></a>tcp_base_mss - INTEGER</h3><p>MTU 探测中 <code>search_low</code> 的初始值，在开启 MTU 探测时，同时作为连接的初始 MSS 值。</p><ul><li>默认值：512</li></ul><p>注：这里的 MTU 探测（PLPMTUD packetization layer Path MTU discovery，又称 MTUProbing） 与前文的路径 MTU 发现（PMTUD）不太一样，PMTUD 发现依赖 ICMP需要分片的报文来确认 MTU 大太，可以理解成是 IP 层的。现在出于安全性问题，很多设备会禁用 ICMP 报文，PLPMTUD 是由 <a href="https://tools.ietf.org/html/rfc4821" target="_blank" rel="noopener">RFC4821</a> 引入，尝试解决没有 ICMP 报文情况下的 MTU 发现。简单地说，在 TCP 层实现的话，依赖的是 TCP 的超时机制来确认包丢失，在开启 SACK 机制的情况下也会利用 SACK 信息。</p><p>注：PLPMTUD 也有自己的问题<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>，如容易把拥塞控制相关的丢包划分为 MTU 问题，长期运行时最终使用的 MTU 值可能较小；同时没有为 IPv6 实现相关功能。</p><h3 id="tcp-mtu-probe-floor-integer"><a class="header-anchor" href="#tcp-mtu-probe-floor-integer"></a>tcp_mtu_probe_floor - INTEGER</h3><p>开启 MTU 探测时，该参数限定允许 <code>search_low</code> 到达的最小值。</p><ul><li>默认值：48</li></ul><p>注：该参数是 Linux 5.4 由这个<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=c04b79b6cfd714144f6a2cf359603d82ee631e62" target="_blank" rel="noopener">commit</a>加入。commit 中解释了如果因为丢包严重，会导致 MTU “卡” 在 <code>48</code> 上（之前的默认值），现在加了个参数可供调整。</p><p>注：为什么之前默认值是 <code>48</code>？因为 <a href="https://tools.ietf.org/html/rfc791" target="_blank" rel="noopener">IPv4</a>指出 “Every internet module must be able to forward a datagram of 68 octetswithout further fragmentation”，即 IP 设备至少应该支持 68B，扣除 20B 的 TCP 头，得到最小支持 48B MSS。</p><h3 id="tcp-min-snd-mss-integer"><a class="header-anchor" href="#tcp-min-snd-mss-integer"></a>tcp_min_snd_mss - INTEGER</h3><p>TCP 的 SYN 和 SYNACK 报文通常会携带 ADVMSS 选项，来通告 MSS 信息，如果通告的MSS 小于 <code>tcp_min_snd_mss</code>，则 Linux 会偷偷地将 MSS 提高到 <code>tcp_min_snd_mss</code>的值。</p><ul><li>默认值：48</li></ul><h3 id="tcp-congestion-control-string"><a class="header-anchor" href="#tcp-congestion-control-string"></a>tcp_congestion_control - STRING</h3><p>设置新连接的拥塞控制算法，保底的算法是 “reno”，总是可用，其它可选的算法得看内核的配置。对于 passive 连接（即对 server）来说，新连接会继承 listener 通过<code>setsockopt(listenfd, SOL_TCP, TCP_CONGESTION, &quot;name&quot; ...)</code> 配置的算法。</p><ul><li>默认值是在内核中配置时设置的</li></ul><h3 id="tcp-dsack-boolean"><a class="header-anchor" href="#tcp-dsack-boolean"></a>tcp_dsack - BOOLEAN</h3><p>开启 DSACK(duplicate SACK).</p><ul><li>默认值：1 开启</li></ul><p>注：SACK 指的是 selective ACK，允许在 ACK 时通过 TCP 选项指定接收到了哪些乱序包，这样发送方能更有针对性的重传可能丢失的包。基本的 SACK 没有指定接收到重复报文时做何处理，DSACK 就是这基础上的扩展，它允许发送包含小于或等于累积 ACK 的SACK 块，这样重复块的信息也可以通过 SACK 传递。当然 DSACK 也有自己的一些问题，这里不展开。</p><h3 id="tcp-early-retrans-integer"><a class="header-anchor" href="#tcp-early-retrans-integer"></a>tcp_early_retrans - INTEGER</h3><p>是否开启 TLP(Tail loss probe) 机制。注意 TLP 机制需要 RACK 机制才能正常工作（参见下文的 <a href="#tcp-recovery-integer">tcp_recovery</a>）。</p><ul><li>默认值：3</li><li>可选值：<ul><li>0：关闭</li><li>3 或 4：开启</li></ul></li></ul><p>注：默认情况下，TCP 在检测到 3 次重复 ACK（dupack，和 DSACK 是两个事）后触发快速重传，即不等超时就重传某个包。当接收方在接到失序报文会对已有的包 ACK 发送重复的 ACK（如收到 #1 发送 ACK-1，收到 #3 会发送 ACK-1，对 #1 ACK 了两次）。但是对于尾包丢失，由于后面没有其它包，则无法触发重复 ACK，也无法触发快速重传。</p><p>注<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>：TLP 会发送一个 loss probe 包，来产生足够的 SACK/FACK 的信息来触发 fastrecovery。根据 Google 的测试，TLP 能够有效的避免较长的 RTO 超时，进而提高TCP性能。</p><h3 id="tcp-ecn-integer"><a class="header-anchor" href="#tcp-ecn-integer"></a>tcp_ecn - INTEGER</h3><p>用来控制 TCP 使用的 Explicit Congestion Notification (ECN) 机制。ECN 只有在TCP 连接双方协商支持时才启用。这个功能允许路由在丢包之前就通知有拥塞的存在，以此来减少因为真正拥塞导致的丢包。</p><ul><li>可选值：<ul><li>0: 关闭 ECN，不主动开启也不被动响应</li><li>1: 开启 ECN，主动开启，被动响应</li><li>2: 开启 ECN，不主动开启，被动响应</li></ul></li><li>默认值：2</li></ul><p>注<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>：ECN 需要 TCP 和 IP 的支持，TCP 连接建立时协商是否使用 ECN。如果开启，则当中间路由遇到拥塞时，会修改 IP 头中的 TOS 字段的最右两位，置为拥塞。接收方需要使用 TCP 头中的 ECE 标记回传这个拥塞信息。当某一方接收到 TCP 报文带有 ECE 位时，会减少拥塞窗口，同时设置 CWR 位来确认阻塞指示。当然还有一些其它机制来保证安全性。</p><h3 id="tcp-ecn-fallback-boolean"><a class="header-anchor" href="#tcp-ecn-fallback-boolean"></a>tcp_ecn_fallback - BOOLEAN</h3><p>如果内核检测到 ECN 连接工作不正常，则会回退到非 ECN 模式。当前该选项实现了RFC3168 第 6.1.1.1. 节中的内容，但不排除未来也会在该选项下实现其它检测算法的可能性。如果 <a href="#tcp-ecn-integer">tcp_ecn</a> 选项或单个路由的 ECN 功能关闭时该选项不生效。</p><ul><li>默认值：1 开启回退</li></ul><h3 id="tcp-fack-boolean"><a class="header-anchor" href="#tcp-fack-boolean"></a>tcp_fack - BOOLEAN</h3><p>开启 TCP FACK(Forward Acknowledgement) 支持。选项废弃了，新版内核不再生效。</p><p>注<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>：FACK 是拥塞控制中快速恢复（Fast Recovery）阶段相关的机制，它主要解决有多个报文丢失的情况下，通过准确估计（当前连接）还在网络中传输的报文大小，在恢复阶段做出精确的拥塞控制。计算的方式如下：</p><ul><li>记录 SACK 的最大序号数为 <code>snd.fack</code></li><li>定义 awnd 代表正在网络中传输的数据：<code>awnd = snd.nxt - snd.fack</code>，这里假设了不存在乱序报文</li><li>在重传时，awnd 要加上重传的数据：<code>awnd = snd.nxt - snd.fack + retran_data</code></li></ul><p>于是在拥塞时，cwnd 会根据算法改变，此时为了充分利用带宽，可以使用如下方法控制包的发送：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while (awnd &lt; cwnd)</span><br><span class="line">    sendsomething()</span><br></pre></td></tr></table></figure><p>该方法比起 Reno 通过接收到的 dupack 数量来调整 cwnd 值更为精确。对于快速恢复的触发也有变化：</p><p>正常 Reno 算法会在 <code>dupacks == 3</code> 时触发快速恢复，如果丢失多个包，则 ACK 数量也随之减少，导致等待重传的时间变长，而 FACK 额外增加了一个触发条件：<code>(snd.fack – snd.una) &gt; (3*MSS)</code>，即假设没有乱序包的情况下，如果该条件成立，则说明网络中丢失了 3 个包，等价于 <code>dupacks == 3</code>，可以触发重传和快速恢复。</p><p>注：在 Linux 4.15<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup> 中移除了 FACK 的支持，使用 RACK 机制替代。</p><h3 id="tcp-fin-timeout-integer"><a class="header-anchor" href="#tcp-fin-timeout-integer"></a>tcp_fin_timeout - INTEGER</h3><p>孤儿连接（orphaned connection，指不再被任何应用使用的连接）在 <code>FIN_WAIT_2</code> 状态中等待的时间，超时后在本地会被丢弃。虽然 <code>FIN_WAIT_2</code> 完全是合法的 TCP 状态，但如果另一端已经挂了，如果没有超时机制，则会永远等待下去。</p><ul><li>默认值：60 秒</li></ul><p>注：TCP 四次挥手包含两轮协商，分别包含双方的 FIN+ACK，本地的 FIN+ACK 结束后即进入 FIN_WAIT_2，等待另一方的 FIN。不能永远等待另一方的 FIN。</p><h3 id="tcp-frto-integer"><a class="header-anchor" href="#tcp-frto-integer"></a>tcp_frto - INTEGER</h3><p>开启 F-RTO (Forward RTO-Recovery) 支持。F-RTO 在 RFC5682 中定义，它是 TCP 重传超时的一个增强算法，能更好地处理 RTT 经常波动的情况（如无线网）。F-RTO 仅需要发送端做修改，不需要接收端的任何支持。</p><ul><li>0: 关闭 F-RTO</li><li>1: 开启 F-RTO 的基础算法</li><li>2: 如果一条流使用了 SACK，则开启 SACK 增强的 F-RTO 算法。默认值。</li></ul><p>注<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup>：RTO 解决的是虚假重传的问题，由于链路的 RTT 波动太大，导致发送方还没来得及接收 ACK 就触发了 RTO 超时重传。F-RTO 是一种发送端的无效 RTO 超时重传检测方法。在 RTO 超时重传了第一个数据包之后，F-RTO 会检测之后收到的 ACK 报文来判断刚刚的超时重传是否是虚假重传，然后根据判断结果决定是接着进行重传还是发送新的未发送数据。</p><h3 id="tcp-fwmark-accept-boolean"><a class="header-anchor" href="#tcp-fwmark-accept-boolean"></a>tcp_fwmark_accept - BOOLEAN</h3><p>开启选项时，如果连接某个 listening socket 的连接没有设置 socket mark，则会将accepting socket 的 mark 设置成传入的 SYN 报文的 mark。这会导致该连接的后续所有报文（从 SYNACK 开始）都会被打上对应的 fwmark。当然 listening socket 的 mark保持不变。同时如果 listening socket 已经通过 <code>setsockopt(SOL_SOCKET, SO_MARK, ...)</code> 设置了 mark，则不受该选项影响。</p><ul><li>默认值：0 不开启</li></ul><p>注：基础知识：Server 端有两种 socket，一种是诸如 80 端口这样的监听端口(listening socket)，客户端会连接服务端的 listening socket，当服务端 accept 时，会在在服务端为该连接赋予一个 accepting socket，后续连接通过 accepting socket通信。</p><p>注：fwmark 相关内容在 <a href="#fwmark-reflect-boolean">fwmark_reflect</a> 中有介绍，<code>tcp_fwmark_accept</code> 用来实现“哪来回哪去”的功能。</p><h3 id="tcp-invalid-ratelimit-integer"><a class="header-anchor" href="#tcp-invalid-ratelimit-integer"></a>tcp_invalid_ratelimit - INTEGER</h3><p>限制响应无效报文的重复 ACK 的最大速率，报文无效的判定：</p><ol><li>序列号在当前窗口范围之外</li><li>ACK 号在当前窗口范围之外</li><li>PAWS（序号回绕检查：Protection Against Wrapped Sequence numbers）检查失败</li></ol><p>这个选项有助于缓解简单的 “ack loop” 的 DoS 攻击，一些怀有恶意的中间设备会尝试以某些方式修改 TCP 报文头，让连接的某一方认为另一方在发送错误的 TCP 报文，导致为这些错误报文无止境地发送重复 ACK。</p><ul><li>0: 关闭速率限制，其它值代表两次无效报文重复 ACK 间的间隔（毫秒）</li><li>默认值：500 毫秒</li></ul><h3 id="tcp-keepalive-time-integer"><a class="header-anchor" href="#tcp-keepalive-time-integer"></a>tcp_keepalive_time - INTEGER</h3><p>当 keepalive 开启时，等待多长时间开始发送 keepalive 消息</p><ul><li>默认：7200（2 小时）</li></ul><p>注<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>：keepalive 是 TCP 的保活机制，严格来说并不是 TCP 规范中的内容。这个机制一般是为服务器的应用程序提供，希望知道客户主机是否崩溃或离开。保活探测报文为一个空报文段（或只包含一个字节），它的序列号等于对方主机发送的 ACK 报文的最大序号减1, 因为这一序号的数据已经被成功接收，因此对接收方没有影响，而返回的响应可以确定连接是否还正常工作。</p><h3 id="tcp-keepalive-probes-integer"><a class="header-anchor" href="#tcp-keepalive-probes-integer"></a>tcp_keepalive_probes - INTEGER</h3><p>判定连接失效前，发送的保活探测报文的数量，默认值为 9.</p><h3 id="tcp-keepalive-intvl-integer"><a class="header-anchor" href="#tcp-keepalive-intvl-integer"></a>tcp_keepalive_intvl - INTEGER</h3><p>保活探测报文发送间隔。乘于 <code>tcp_keepalive_probes</code> 就等于探测触发到关闭连接之间的时间。</p><ul><li>默认值：75（秒），即链接会在重试约 11 分钟后被关闭</li></ul><h3 id="tcp-l3mdev-accept-boolean"><a class="header-anchor" href="#tcp-l3mdev-accept-boolean"></a>tcp_l3mdev_accept - BOOLEAN</h3><p>开启该选项允许子 socket 继承 L3 master device 的索引号。即允许有一个“全局”的listen socket，能监听所有的 L3 master 域（即监听所有的 VRF 设备），通过该listen socket 建立的连接会被绑定在连接创建时使用的 L3 域上。只有当内核编译时加上 <code>CONFIG_NET_L3_MASTER_DEV</code> 选项才可用。</p><ul><li>默认值：0（关闭）</li></ul><p>注：L3 master device(L3mdev) 是内核为了支持 VRF(Virtual Routing Forwarding) 而添加的功能，但本身是独立于 VRF 存在的。L3 指的是网络栈第 3 层：网络层。可以把L3mdev 理解成虚拟的网卡，不过只在 L3 层生效，它有独立的路由表。</p><h3 id="tcp-low-latency-boolean"><a class="header-anchor" href="#tcp-low-latency-boolean"></a>tcp_low_latency - BOOLEAN</h3><p>如果开启该选项，则 TCP 做决定时会倾向于低延时而非高吞吐。如果关闭选项，则倾向高吞吐。Linux 4.14 开始，该选项依旧存在，但会被忽略。</p><h3 id="tcp-max-orphans-integer"><a class="header-anchor" href="#tcp-max-orphans-integer"></a>tcp_max_orphans - INTEGER</h3><p>最大的孤儿连接，孤儿连接指的是不与任何用户文件描述符绑定的 TCP socket 但仍归系统管理中。如果孤儿连接超过了该选项的值，则连接会被立马回收并打出警告信息。这个选项的目的是防止简单的 DoS 攻击，我们不应该去依赖这个行为或者人为减小该值。反之在默认值无法满足网络条件需要时增大它。注意每个孤儿连接会消耗约 64K 的不可swap的内存。</p><p>默认初始值等于内核参数 <code>NR_FILE</code>，默认值会随着系统内存调整。</p><h3 id="tcp-max-syn-backlog-integer"><a class="header-anchor" href="#tcp-max-syn-backlog-integer"></a>tcp_max_syn_backlog - INTEGER</h3><p>SYN 队列中允许的最大连接数，具体来说是处于 SYN_RECV 状态的连接，这个状态代表还没有收到三次握手中最后一个 ACK 的连接。这个限制是针对单个 listener 的。对内存少的机器默认值是 128, 对内存多的机器来说会对应增加。如果机器的负载比较大，可以尝试增大该值。同时也别忘了看看 <a href="#somaxconn-integer">somaxconn</a> 参数。另外一个SYN_RECV 状态的 socket 占用大概 304B 内存。</p><p>注：如果实际连接数超过了该值，内核就会开始丢弃连接。</p><h3 id="tcp-max-tw-buckets-integer"><a class="header-anchor" href="#tcp-max-tw-buckets-integer"></a>tcp_max_tw_buckets - INTEGER</h3><p>系统同时允许存在的处于 TIME_WAIT 状态的 socket 最大数量。如果实际数量超过了该值，则会立即回收 TIME_WAIT socket 并打印警告信息。和<a href="#tcp-max-orphans-integer">tcp_max_orphans</a> 一样，该参数也是用于防范一些简单的DoS 攻击，我们不应该去减少这个值，在网络需要的情况下可以适当增加该值。</p><p>注：和 TIME_WAIT 有关的还有个参数 <code>tcp_tw_recycle</code> 是用来快速回收处于TIME_WAIT 状态的连接的，在 Linux 4.11 之后也被废弃了。</p><h3 id="tcp-mem-vector-of-3-integers-min-pressure-max"><a class="header-anchor" href="#tcp-mem-vector-of-3-integers-min-pressure-max"></a>tcp_mem - vector of 3 INTEGERs: min, pressure, max</h3><p>包含 3 个值：</p><ul><li>min: 使用内存在 <code>min</code> 页之下时，TCP 不关心内存使用</li><li>pressure: 当 TCP 分配的内存超出了 <code>pressure</code> 页，则会减少它的内存占用，进入pressure 模式，直到分配的内存小于 <code>min</code> 时退出</li><li>max: 所有 TCP socket 队列允许使用的最大内存</li></ul><p>默认值在启动时根据系统的内存进行推断。</p><h3 id="tcp-min-rtt-wlen-integer"><a class="header-anchor" href="#tcp-min-rtt-wlen-integer"></a>tcp_min_rtt_wlen - INTEGER</h3><p>Linux 会用一个带窗口的 filter 去计算连接的最小 RTT，该参数控制窗口的大小。更小的窗口意味着对 RTT 变化更敏感，如果最小 RTT 在变大，更小的窗口能更快应用更大的最小 RTT。反之窗口超大，就更能抵抗短时间内的 RTT 膨胀，例如由拥塞引起的 RTT 变大。单位是秒。</p><ul><li>默认值：300 (5min)</li><li>可选值：0 ~ 86400 (1 day)</li></ul><p>注：这个算法的实现可以在这个讨论中找到：<a href="https://patchwork.ozlabs.org/project/netdev/patch/1445057867-32257-3-git-send-email-ycheng@google.com/" target="_blank" rel="noopener">tcp: track min RTT using windowedmin-filter</a></p><h3 id="tcp-moderate-rcvbuf-boolean"><a class="header-anchor" href="#tcp-moderate-rcvbuf-boolean"></a>tcp_moderate_rcvbuf - BOOLEAN</h3><p>如果开启，则 TCP 会自动调整接收缓存的大小，在不超过 <code>tcp_rmem[2]</code> 的前提下，尽量达到该连接满吞吐的要求。默认开启。</p><h3 id="tcp-mtu-probing-integer"><a class="header-anchor" href="#tcp-mtu-probing-integer"></a>tcp_mtu_probing - INTEGER</h3><p>是否开启 MTU 探测功能（即 PLPMTUD Packetization-Layer Path MTU Discovery）。</p><ul><li>0: 关闭（默认值）</li><li>1: 默认关闭，在检测到 IMCP 黑洞问题时开启</li><li>2: 始终开启，使用 <a href="#tcp-base-mss-integer">tcp_base_mss</a> 作为初始值</li></ul><p>注：PLPMTUD 机制在 <a href="#tcp-base-mss-integer">tcp_base_mss</a> 做了简单介绍</p><h3 id="tcp-probe-interval-unsigned-integer"><a class="header-anchor" href="#tcp-probe-interval-unsigned-integer"></a>tcp_probe_interval - UNSIGNED INTEGER</h3><p>控制开始 PLPMTUD 重新检测的时机，默认是每 10 分钟重新检测，由<a href="https://tools.ietf.org/html/rfc4821" target="_blank" rel="noopener">RFC4821</a> 规定。</p><h3 id="tcp-probe-threshold-integer"><a class="header-anchor" href="#tcp-probe-threshold-integer"></a>tcp_probe_threshold - INTEGER</h3><p>控制 PLPMTUD 何时停止探测，如果最终搜索范围的间隔小于某个数字时停止，默认值是8 字节。</p><h3 id="tcp-no-metrics-save-boolean"><a class="header-anchor" href="#tcp-no-metrics-save-boolean"></a>tcp_no_metrics_save - BOOLEAN</h3><p>默认情况下，当一个连接关闭时，TCP 会在 route cache 中记录一些连接相关的指标，这些指标在随后建立的新连接中可以被当作初始条件使用。通常这种做法会提高整体的性能，但有一些特殊情况下也可能会降低性能。如果这个开关开启，则关闭连接时<strong>不会</strong>记录指标。</p><h3 id="tcp-no-ssthresh-metrics-save-boolean"><a class="header-anchor" href="#tcp-no-ssthresh-metrics-save-boolean"></a>tcp_no_ssthresh_metrics_save - BOOLEAN</h3><p>控制 TCP 是否将 ssthresh 记录在 route cache 中，默认值是 1 代表不记录。</p><p>注：<code>ssthresh</code> 是拥塞控制中，慢启动的阈值，窗口超过阈值后进入拥塞避免。</p><h3 id="tcp-orphan-retries-integer"><a class="header-anchor" href="#tcp-orphan-retries-integer"></a>tcp_orphan_retries - INTEGER</h3><p>该值影响的是本地已关闭但超时重传还没有被 ACK 的 TCP 连接的超时。更多信息参考<a href="#tcp-retries2-integer">tcp_retries2</a>。</p><p>默认值是 8，如果你的机器是一个高负载的 WEB 服务器，可以考虑调低该值，因为这样的 socket 可能占用不少资源，同时参考<a href="#tcp-max-orphans-integer">tcp_max_orphans</a></p><h3 id="tcp-recovery-integer"><a class="header-anchor" href="#tcp-recovery-integer"></a>tcp_recovery - INTEGER</h3><p>这个值是一个 bitmap，用来开启一些还在实验的丢包恢复的功能</p><ul><li><code>0x1</code>，（默认）为丢包重传和丢尾包的情况开启 RACK 丢包检测，对 SACK 连接来说，它已经包含了 <a href="https://tools.ietf.org/html/rfc6675" target="_blank" rel="noopener">RFC6675</a> 的恢复并且禁用相关功能</li><li><code>0x2</code>，使用静态的 RACK 重排序窗口，置为 (min_rtt/4)</li><li><code>0x4</code>，不使用 RACK 的启发式 DUPACK 阈值</li></ul><p>注：RACK<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup> 全称 (Recent ACK)，作用是在快速发现并重传那些曾经重传后再次丢失的数据包，旨在替代 DUPACK 等重传机制。传统的一些重传机制依赖计算 ACK 包的数量，包括DUPACK，FACK 等，在很多情况下这个方法不可靠。于是 RACK 使用的是基于超时的算法（通过时间戳和 SACK 信息），RACK 会维护一个窗口，当 ACK 到来时，RACK 会将窗口中“过期”的包标记为“丢失”，进行重传，而对于“未过期”的包，有可能丢失也有可能是乱序，会等到超时后再处理。</p><h3 id="tcp-reordering-integer"><a class="header-anchor" href="#tcp-reordering-integer"></a>tcp_reordering - INTEGER</h3><p>TCP 重排序级别的初始值，TCP 协议栈会动态地在初始值和<a href="#tcp-max-reordering-integer">tcp_max_reordering</a> 之间做调整。一般不要改默认值。</p><ul><li>默认值：3</li></ul><p>注<sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup>：该参数的含义是告诉内核，重排序的情况有多严重，这样内核就会假设数据包发生了重排序而不是丢了。如果 TCP 认为丢包了，则会进入慢启动，因为它会认为包是因为链路上的拥塞而丢失的。同时如果内核在使用 FACK 算法，也会回退到普通算法。</p><h3 id="tcp-max-reordering-integer"><a class="header-anchor" href="#tcp-max-reordering-integer"></a>tcp_max_reordering - INTEGER</h3><p>TCP 数据流中最大的重排序级别。默认值为 300，是一个比较保守的值，如果链路使用了per packet 的负载均衡（例如 bounding rr 模式），则可以考虑增加该值的大小。</p><h3 id="tcp-retrans-collapse-boolean"><a class="header-anchor" href="#tcp-retrans-collapse-boolean"></a>tcp_retrans_collapse - BOOLEAN</h3><p>开启后，在重传时会试图发送满大小的包。这是对一些有 BUG 的打印机的绕过方式。</p><ul><li>默认：开启</li></ul><h3 id="tcp-retries1-integer"><a class="header-anchor" href="#tcp-retries1-integer"></a>tcp_retries1 - INTEGER</h3><p>该值决定了经过多少次 RTO 超时重传没被 ACK 后，TCP 向 IP 层传递“消极建议”（如重新评估当前的 IP 路径）。参考 <a href="#tcp-retries2-integer">tcp_retries2</a>。</p><p><a href="https://tools.ietf.org/html/rfc1122" target="_blank" rel="noopener">RFC1122</a> 推荐至少等待 3 次重传，这也是默认值。</p><h3 id="tcp-retries2-integer"><a class="header-anchor" href="#tcp-retries2-integer"></a>tcp_retries2 - INTEGER</h3><p>该值决定了在多少次 RTO 重传仍未得到 ACK 后，TCP 将放弃该连接。给定值为 N，假设TCP 使用的是指数回退机制，初始 RTO 为 <code>TCP_RTO_MIN</code>，则连接会重传 N 次，第(N+1) 次 RTO 时放弃连接。</p><p>默认值是 15，按上面的逻辑，关闭前会有 924.6s 的超时，它也是合理超时的一个下界。TCP 在超过该时间后的第一个 RTO 超时时放弃该连接。</p><p><a href="https://tools.ietf.org/html/rfc1122" target="_blank" rel="noopener">RFC1122</a> 推荐至少等待 100s，对应该值至少为 8.</p><p>注<sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup>：逻辑上来说，TCP 有两个值 R1 和 R2 来决定如何重传同一个报文。R1 表示 TCP 在向 IP 层传递“消极建议”（如重新评估当前的 IP 路径）之前，愿意重传的次数。R2（大于 R1）指示 TCP 应该放弃当前连接的时机。R1 对应的<a href="#tcp-retries1-integer">tcp_retries1</a>，R2 对应<a href="#tcp-retries2-integer">tcp_retries2</a>。</p><h3 id="tcp-rfc1337-boolean"><a class="header-anchor" href="#tcp-rfc1337-boolean"></a>tcp_rfc1337 - BOOLEAN</h3><p>如果开启了，则 TCP 协议栈的行为会符合<a href="https://tools.ietf.org/html/rfc1337" target="_blank" rel="noopener">RFC1337</a>，如果不开启，则行为不符合 RFC的描述，但依旧会防止暗杀 TIME_WAIT 的连接。</p><ul><li>默认值：0</li></ul><h3 id="tcp-rmem-vector-of-3-integers-min-default-max"><a class="header-anchor" href="#tcp-rmem-vector-of-3-integers-min-default-max"></a>tcp_rmem - vector of 3 INTEGERs: min, default, max</h3><p>这个选项包含 3 个值：</p><ul><li><p>min，默认 4K。代表 TCP socket 接收缓冲的最小值。即使在内存紧张的情况下也会得到保证</p></li><li><p>default，默认 87380B，TCP socket 接收缓冲的初始值，该参数会覆盖其它协议设置的 <code>net.core.rmem_default</code> 值。在<a href="#tcp-adv-win-scale-integer">tcp_adv_win_scale</a> 为默认值，<a href="#tcp-app-win-integer">tcp_app_win</a> 为 0 的设置下，87380B 能对应拥有大小为65535B 的 TCP窗口，默认 tcp_app_win 设置(31)下则会更小一些。</p></li><li><p>max，默认值在 87380B 到 6MB 之前，视内存而定。是系统自动调整接收缓冲的最大值，这个参数<strong>不会</strong>覆盖 <code>net.core.rmem_max</code>。如果使用 <code>setsockopt()</code> 设置了<code>SO_RCVBUF</code>，则会关闭自动调整接收缓冲大小的功能，因此该值不生效。另：具体的默认值公式：</p><p><code>max(87380, min(4 MB, tcp_mem[1]*PAGE_SIZE/128))</code></p></li></ul><p>注：接收缓冲划分的逻辑在 <a href="#tcp-adv-win-scale-integer">tcp_adv_win_scale</a> 和<a href="#tcp-app-win-integer">tcp_app_win</a> 有更详细的描述。</p><p>注意上面的描述说会得到 65535B 的窗口，是按 tcp_adv_win_scale = 2 来计算的，此时 TCP 窗口的大小为 bytes - overhead = 87380 - 87380/2^2 = 87380 - 21845 =65535。但是 <code>tcp_adv_win_scale</code> 最新的默认值已经是 <code>1</code> 了，所以实际的窗口只有43690B。</p><h3 id="tcp-sack-boolean"><a class="header-anchor" href="#tcp-sack-boolean"></a>tcp_sack - BOOLEAN</h3><p>开启 SACK（select acknowledgments）。</p><p>注：这个机制应该是比较常用的，接收方在返回 ACK 时，除了返回目前最大的累积 ACK序号，还可以在 TCP 选项中填写提前收到的“乱序”报文。这样发送方在接收到 SACK 时，就可以有针对性地重传缺失的包，提高传输效率。</p><h3 id="tcp-comp-sack-delay-ns-long-integer"><a class="header-anchor" href="#tcp-comp-sack-delay-ns-long-integer"></a>tcp_comp_sack_delay_ns - LONG INTEGER</h3><p>TCP 会尽量减少发送 SACK 的数量，默认会等待 5% SRTT 的时间，时间的下限是该选项的值，纳秒为单位。默认值为 1ms，与 TSO 自动调整大小的间隔相同。</p><p>注<sup class="footnote-ref"><a href="#fn22" id="fnref22">[22]</a></sup>：这个参数的大背景是要对 SACK 做压缩，因为 TCP 会在收到失序报文时立即发送SACK 报文，在诸如 wifi 环境或拥塞的网络情况下这并不是好的选择。</p><h3 id="tcp-comp-sack-nr-integer"><a class="header-anchor" href="#tcp-comp-sack-nr-integer"></a>tcp_comp_sack_nr - INTEGER</h3><p>允许被压缩的最大 SACK 报文数，设置为 0 代表关闭 SACK 压缩</p><ul><li>默认值：44</li></ul><h3 id="tcp-slow-start-after-idle-boolean"><a class="header-anchor" href="#tcp-slow-start-after-idle-boolean"></a>tcp_slow_start_after_idle - BOOLEAN</h3><p>如果开启了，则会实现 <a href="https://tools.ietf.org/html/rfc2861" target="_blank" rel="noopener">RFC2861</a> 的行为：在空闲超过一段时间之后，将拥塞窗口置为过期（重新慢启动过程）。“一段时间”定义为当前的 RTO。如果关闭选项，则拥塞窗口不会随着空闲时间过期。</p><ul><li>默认值：开启</li></ul><h3 id="tcp-stdurg-boolean"><a class="header-anchor" href="#tcp-stdurg-boolean"></a>tcp_stdurg - BOOLEAN</h3><p>对于 TCP 的 URG(Urgent pointer) 字段，是否使用 Host requirements 中的解释。多数主机使用的是更老的 BSD 解释，如果开启该选项，Linux 和这些 BSD 风格的主机可能就没法正常通信了。</p><p>注：<a href="https://tools.ietf.org/html/rfc1122" target="_blank" rel="noopener">Host Requirement</a> 对主机实现 TCP 规范有许多细节上的要求。</p><h3 id="tcp-synack-retries-integer"><a class="header-anchor" href="#tcp-synack-retries-integer"></a>tcp_synack_retries - INTEGER</h3><p>对于被动连接(passive connection)，允许重传 SYNACK 的最大次数。不能高于 255. 默认值为 5, 在当前初始 RTO 为 1s 的情况下，到最后一次重传共用时 31s。这样该连接最后一次超时发生在自尝试建立连接的 63s 之后。</p><p>注：TCP 的重传时间是每次翻倍，所以如果初始 RTO = 1s，则第 5 次重传发生在 <code>1＋2 ＋4＋8＋16=31</code>，最后一次超时为 32s，因此共为 63s。</p><h3 id="tcp-syncookies-integer"><a class="header-anchor" href="#tcp-syncookies-integer"></a>tcp_syncookies - INTEGER</h3><p>只在内核编译时加了 <code>CONFIG_SYN_COOKIES</code> 时生效。作用是当 SYN 队列(syn backlogqueue)溢出时，新连接不再存入 SYN 队列，而是直接发送 syncookies，作用是防止常见的 SYN 泛洪攻击（SYN flood attack）。</p><p>注意 syncookies 是一个 fallback 的机制，<strong>不应该</strong>被高负载主机用来作用承接合法连接流量的工具。如果在日志中收到 SYN 泛洪的警告，但是调研后发现这些连接都是佥的，只是流量太大了，那么此时应该考虑的是调整其它的参数直到日志中的警告消失：<a href="#tcp-max-syn-backlog-integer">tcp_max_syn_backlog</a>、<a href="#tcp-synack-retries-integer">tcp_synack_retries</a>、<a href="#tcp-abort-on-overflow-boolean">tcp_abort_on_overflow</a></p><p>syncookies 机制严重违背了 TCP 协议，它不允许使用 TCP 扩展，会导致一些其它服务的退化（如 SMTP 中继），这些影响都不是服务端可见的，而是由客户端、中继方发现并通知你的。你只能看到日志里的 SYN 泛洪警告，尽管你发现它们不是真正的泛洪，但你的服务器配置其实是有问题的。</p><p>如是你想测试 syncookies 对服务的影响，可以将选项设置成 2, 这样会无条件开启syncookies。</p><ul><li>0: 关闭</li><li>1: 仅当 syn backlog queue 溢出时发送 syncookies，默认值</li><li>2: 无条件发送 syncookies（从 Linux 3.12 开始支持）</li></ul><p>注：SYN 泛洪攻击指的是攻击者发送大量的 SYN 报文请求建立连接，服务端响应 SYNACK，但是攻击者并不处理，不真正建立连接，于是大量 SYN_RECV 状态的连接将服务端的SYN 队列占满，导致正常的请求无法被响应。</p><p>SYN 泛洪攻击的重点是服务端需要为 SYN_RECV 连接保存信息，syncookies 的思路是将连接的信息编码到 SYNACK 报文中，最后一个 ACK 时再由客户端将信息带回给服务端，这样服务就不需要为它保存任何信息，因此能正常接受连接且不需要保存任何信息。</p><p>有两个缺点<sup class="footnote-ref"><a href="#fn23" id="fnref23">[23]</a></sup>：一是服务器只能编码 8 种 MSS 值，因为有些位被占用了，另一方面服务器必须拒绝所有 TCP 选项，例如大窗口和时间戳。</p><h3 id="tcp-fastopen-integer"><a class="header-anchor" href="#tcp-fastopen-integer"></a>tcp_fastopen - INTEGER</h3><p>开启 TCP Fast Open (<a href="https://tools.ietf.org/html/rfc7413" target="_blank" rel="noopener">RFC7413</a>) 功能，在SYN 包中也能传输数据。需要客户端和服务器两端都开启支持。</p><p>客户端支持通过设置为 <code>0x1</code> 开启（默认打开）。要想在 SYN 时发送数据，客户端需要用加上 <code>MSG_FASTOPEN</code> 选项的 <code>sendmsg()</code> 或<code>sendto()</code> 方法建立连接，而不是用<code>connect()</code>。</p><p>服务端支持通过设置为 <code>0x2</code> 开启（默认关闭），之后要么通过另一个标志（<code>0x400</code>）来为所有的 listeners 开启该功能，要么通过为每个 listener 单独开启<code>TCP_FASTOPEN</code> 选项来支持。这个选项要带一个参数，代表 syn-data backlog 的长度。</p><p>这个选项的值是 bitmap，描述如下：</p><ul><li><code>0x1</code>：客户端，允许客户端在 SYN 中携带数据</li><li><code>0x2</code>: 服务端，开启服务端支持，允许在三次握手结束前接收数据并传递给应用程序</li><li><code>0x4</code>: 客户端，不管 FTO cookie 是否存在，都在 SYN 中发送数据，且不带 cookie选项</li><li><code>0x200</code>: 服务端，没有 cookie 选项时依旧接收 SYN 报文中的数据</li><li><code>0x400</code>: 服务端，为所有监听端口开启 FTO，不用为端口单独设置 TCP_FASTOPEN 选项</li><li>默认值为：<code>0x1</code></li></ul><p>注意后续的增强选项只有在开启了客户端或服务端支持（<code>0x1</code> 及 <code>0x2</code>）后才会生效。</p><p>注：TFO 通过在握手时传递数据，来减少三次握手对数据传输的延时影响，在诸如 HTTP这类协议，会不断创建新的 TCP 连接，因此影响会更大。</p><p>TFO 有个概念是 TFO cookie，客户端在创建连接时可以带上 cookie 选项，服务端认证通过时，就可以接收第一个 SYN 包中携带的数据，而不是等第三次握手的 ACK 后再接收数据<sup class="footnote-ref"><a href="#fn24" id="fnref24">[24]</a></sup>。</p><h3 id="tcp-fastopen-blackhole-timeout-sec-integer"><a class="header-anchor" href="#tcp-fastopen-blackhole-timeout-sec-integer"></a>tcp_fastopen_blackhole_timeout_sec - INTEGER</h3><p>发生 TFO 防火墙黑洞（TFO firewall blackhole）情况时，关闭活跃端口快速打开功能的持续时间（单位秒）初始值。如果快速打开功能重新启用后又遇到了黑洞问题，则关闭时间会指数级增长，如果黑洞问题消失，关闭时间会重新被设置为初始值。</p><ul><li>0: 关闭黑洞问题检测机制</li><li>默认为 1 小时</li></ul><p>注：TFO 防火墙黑洞会导致 client 端长时间连不上 server 端，其中的一些情形：</p><ul><li>防火墙可能会丢掉带数据的 SYN 包</li><li>防火墙可能会丢掉带数据的 SYNACK 包</li></ul><h3 id="tcp-fastopen-key-list-of-comma-separated-32-digit-hexadecimal-integers"><a class="header-anchor" href="#tcp-fastopen-key-list-of-comma-separated-32-digit-hexadecimal-integers"></a>tcp_fastopen_key - list of comma separated 32-digit hexadecimal INTEGERs</h3><p>该选项的值包含了一个列表，列表中包含了一个主 Key 和一个可选的备用 Key。主 Key被用于签发新 cookie 及验证已有 cookie，而备用 key 只会被用来验证 cookie。备用Key 是用来滚动更新 key 时轮换用的。</p><p>如果 <a href="#tcp-fastopen-integer">tcp_fastopen</a> 选项设置成了 <code>0x400</code>，或者端口设置了 <code>TCP_FASTOPEN</code> 选项，而之前并没有配置过 Key，则内核会随机生成一个 Key。如果端口事先使用了 <code>setsockopt</code> 配置了 <code>TCP_FASTOPEN_KEY</code> 选项，则该端口会选用配置的 Key 而不是 sysctl 设置的 Key。</p><p>Key 由 4 组数字构成，由字符 <code>-</code> 分隔，每组由 8 个 16 进制数字组成，如<code>xxxxxxxx-xxxxxxxx-xxxxxxxx-xxxxxxxx</code>，前导的 0 可以省略。主 Key 和备用 Key 之间用逗号分隔。如果只设置了一个 Key，则该 Key 被认为是主 Key，之前配置的备用Key 会被移除。</p><h3 id="tcp-syn-retries-integer"><a class="header-anchor" href="#tcp-syn-retries-integer"></a>tcp_syn_retries - INTEGER</h3><p>重传主动连接 SYN 报文的次数。不能高于 127。 默认值是 6, 在 RTO 为 1s 的情况下，从开始到最后一次重传之间的时间为 63s。从开始到最终的超时之间，过了 127s。</p><h3 id="tcp-timestamps-integer"><a class="header-anchor" href="#tcp-timestamps-integer"></a>tcp_timestamps - INTEGER</h3><p>开启 <a href="https://tools.ietf.org/html/rfc1323" target="_blank" rel="noopener">RFC1323</a> 中定义的时间戳功能</p><ul><li>0: 关闭</li><li>1: （默认）开启功能并为每个连接使用随机的 offset，而不仅是使用当前时间</li><li>2: 开启功能并仅使用当前时间（Linux 4.10 后生效）</li></ul><p>注：时间戳机制指的是在发送 TCP 报文时，加上时间戳选项，记录服务端的时间，接收方在 ACK 时需要将时间戳选项原封不动返回。这样服务端一方面可以用来精确计算 RTT，一方面可以用来防止序列号回绕（PAWS，传输大量数据时，ACK 序列溢出回绕，可能会和之前发送的报文有重合）。</p><p>出于安全上的考虑，时间戳并不是真正记录时间，而是会使用一些随机的内容，一般还是保证递增的。</p><h3 id="tcp-min-tso-segs-integer"><a class="header-anchor" href="#tcp-min-tso-segs-integer"></a>tcp_min_tso_segs - INTEGER</h3><p>每个 TSO 帧包含的报文段数量最小值。从 Linux-3.12 开始，TCP 就不再是填充一个64KB 的大 TSO 包，而是会根据当前的流量自动决定 TSO 帧的大小。如果有一些特殊的需求，还是可以强迫 TCP 构造大的 TSO 帧的。当然如果可用窗口太小，TCP 层还是有可能对大的 TSO 帧做拆分。</p><ul><li>默认值 2</li></ul><p>注：TSO(TCP segmentation offload) 机制的动机是 TCP 用户层的数据需要根据 MTU 进行分段，这个过程很固定但是消耗 CPU，于是改进的思路是将数据整体发往网络设备，由网络设备进行分段。这个机制能释放 CPU，但需要网络设备支持。</p><p>注<sup class="footnote-ref"><a href="#fn25" id="fnref25">[25]</a></sup>：TSO 机制有个问题是 TCP 经常会向下传递一个大包，网卡拆分后一次性注入网络，容易造成流量峰值。TSO autosizing 的目的是根据流量自动调整帧大小，进而将流量平稳地注入网络，“尽量每毫秒都发一个包，而不是每 100 毫秒发一个大包”。<code>tcp_min_tso_segs</code> 指定的是这个包的最小值。</p><h3 id="tcp-pacing-ss-ratio-integer"><a class="header-anchor" href="#tcp-pacing-ss-ratio-integer"></a>tcp_pacing_ss_ratio - INTEGER</h3><p>TCP 会根据当前速率乘于一个比例来设置 <code>sk-&gt;sk_pacing_rate</code> 值（当前速率<code>current_rate = cwnd * mss / srtt</code>）。如果 TCP 处于<strong>慢启动</strong>阶段，则会使用<code>tcp_pacing_ss_ratio</code> 这个比例来让 TCP 以更快的速度进行探测，这里会假设每个RTT时间里 cwnd 都可以翻倍。</p><ul><li>默认值：200</li></ul><p>注：和在 <a href="#tcp-min-tso-segs-integer">tcp_min_tso_segs</a> 中的注提到的类似，Pacing 机制的目标也是在某个 RTT 下能让窗口的包尽量“均匀”地发送，而不是在某一时刻扎堆发送。</p><h3 id="tcp-pacing-ca-ratio-integer"><a class="header-anchor" href="#tcp-pacing-ca-ratio-integer"></a>tcp_pacing_ca_ratio - INTEGER</h3><p>TCP 会根据当前速率乘于一个比例来设置 <code>sk-&gt;sk_pacing_rate</code> 值（当前速率<code>current_rate = cwnd * mss / srtt</code>）。如果 TCP 处于<strong>拥塞避免</strong>阶段，则会使用<code>tcp_pacing_ca_ratio</code> 这个比例来让 TCP 以保守的速度进行探测。</p><ul><li>默认值：120</li></ul><h3 id="tcp-tso-win-divisor-integer"><a class="header-anchor" href="#tcp-tso-win-divisor-integer"></a>tcp_tso_win_divisor - INTEGER</h3><p>该选项控制一个 TSO 帧的大小能占拥塞窗口的百分比。这个参数用来在减少峰值和构建大 TSO 帧之间做选择。</p><ul><li>默认值：3</li></ul><h3 id="tcp-tw-reuse-integer"><a class="header-anchor" href="#tcp-tw-reuse-integer"></a>tcp_tw_reuse - INTEGER</h3><p>允许新连接复用处于 TIME_WAIT 状态的端口。需要应用层协议自己判断这样做是否安全。</p><ul><li>0: 关闭</li><li>1: 全局开启</li><li>2: 只对环回的流量开启（默认值）</li></ul><p>除非有专家要求或建议，否则不建议修改。</p><p>注：实践中遇到 TIME_WAIT 端口太多导致端口不够用的问题，通常是因为开启了反向代理且没有开启 keepalive 长连接。在绝大多数情况下都不需要修改内核参数，并且修改了以后会造成很多偶发的预料之外的问题。</p><h3 id="tcp-window-scaling-boolean"><a class="header-anchor" href="#tcp-window-scaling-boolean"></a>tcp_window_scaling - BOOLEAN</h3><p>开启由<a href="https://tools.ietf.org/html/rfc1323" target="_blank" rel="noopener">RFC1323</a>中定义的窗口缩放（windowscaling）功能</p><ul><li>默认值：开启</li></ul><p>注：TCP 头中窗口大小字段是 16位的，所以最多表示 64K 大小的窗口，为了使用更大的窗口，“窗口缩放”会使用新增的 TCP 选项，指定窗口放大多少倍（实际上指定的是左移多少位）。这个选项需要连接双方都支持。</p><h3 id="tcp-wmem-vector-of-3-integers-min-default-max"><a class="header-anchor" href="#tcp-wmem-vector-of-3-integers-min-default-max"></a>tcp_wmem - vector of 3 INTEGERs: min, default, max</h3><p>这个选项包含 3 个值：</p><ul><li><p>min: 默认 4K。代表 TCP 发送缓存的预留大小。</p></li><li><p>default: 默认 16K。TCP 发送缓存的初始大小，该先期覆盖其它协议设置的<code>net.core.wmem_default</code>，并且通常比 <code>wmem_default</code> 的值小。</p></li><li><p>max，默认值在 4K 到 6MB 之前，视内存而定。是系统自动调整发送缓冲的最大值，这个参数<strong>不会</strong>覆盖 <code>net.core.wmem_max</code>。如果使用 <code>setsockopt()</code> 设置了<code>SO_SNDBUF</code>，则会禁用自动调整发送缓冲大小的功能，因此该值不生效。另：具体的默认值公式：</p><p><code>max(65536, min(4 MB, tcp_mem[1]*PAGE_SIZE/128))</code></p></li></ul><h3 id="tcp-notsent-lowat-unsigned-integer"><a class="header-anchor" href="#tcp-notsent-lowat-unsigned-integer"></a>tcp_notsent_lowat - UNSIGNED INTEGER</h3><p>TCP socket 通过 <code>TCP_NOTSENT_LOWAT</code> 选项可以控制它的写队列中未发送的字节数。如果队列未满且其中的未发送数据小于每个 socket 各自设置的下限值，则<code>poll()/select()/epoll()</code> 方法会返回 <code>POLLOUT</code> 事件。如果这个数据没有超过这个限制，<code>sendmsg()</code> 也不会新增缓存。</p><p>这个选项是一个全局的选项，给那些没有设置 <code>TCP_NOTSENT_LOWAT</code> 选项的 socket 使用。对这些端口来说，全局选项值的变化会即时生效。</p><ul><li>默认值：UINT_MAX (0xFFFFFFFF)</li></ul><p>注：原文的翻译可能比较怪，这个参数大意是用来控制内存使用的，当缓存队列中的未发送数据量小于该值时，内核认为发送缓存为空，因此可以发送，大于该值时停止发送<sup class="footnote-ref"><a href="#fn26" id="fnref26">[26]</a></sup>。</p><p>另：这是对应选项的 <a href="https://lwn.net/Articles/560082/" target="_blank" rel="noopener">commit</a>。</p><h3 id="tcp-workaround-signed-windows-boolean"><a class="header-anchor" href="#tcp-workaround-signed-windows-boolean"></a>tcp_workaround_signed_windows - BOOLEAN</h3><p>如果开启，则在没有接收到窗口缩放参数的情况下，假设对方的 TCP 实现有问题，本机需要把对方的窗口大小字段当作是“有符号”的 16 位整数。如果关闭，则在没有接收到窗口缩放参数时，认为对方的 TCP 实现也是正确的，把窗口大小解释成 16 位无符号整数。</p><ul><li>默认值：0</li></ul><h3 id="tcp-thin-linear-timeouts-boolean"><a class="header-anchor" href="#tcp-thin-linear-timeouts-boolean"></a>tcp_thin_linear_timeouts - BOOLEAN</h3><p>是否为 thin stream 开启线性超时重传。</p><p>如果开启了，则内核会动态检测数据流是不是 thin stream（在传的包数量小于 4），如果发现数据流的确是 thin stream，则在使用指数回退的超时重传时，至少会先尝试 6次线性超时重传。对于一些对依赖低延时的小流量数据流（如游戏）来说，可以减小重传的延时。关于 thin stream，可以参数<a href="https://www.kernel.org/doc/Documentation/networking/tcp-thin.txt" target="_blank" rel="noopener">Documentation/networking/tcp-thin.txt</a></p><ul><li>默认值：0（关闭）</li></ul><p>注：tcp-thin.txt 里基本说得比较详细了</p><h3 id="tcp-limit-output-bytes-integer"><a class="header-anchor" href="#tcp-limit-output-bytes-integer"></a>tcp_limit_output_bytes - INTEGER</h3><p>对每个 socket 控制 TCP 的 Small Queue 大小。TCP 批量发送数据时，倾向于不断发送直到收到 TCP 丢包的通知，加上自动调整 SNDBUF 的功能，会导致在本地有大量的包在排队（在 qdisc, CPU backlog 或设备中），会损害其它连接(flow)的性能，起码对于典型的 pfifo_fast qdiscs 来说是这样。<code>tcp_limit_output_bytes</code> 用来限制允许存储在qdisc 或设备中的字节数来减少 RTT/cwnd 差异导致的不公平，减少 bufferbloat。</p><ul><li>默认值：1048576 (16 * 65536)</li></ul><p>注：可以参考 <a href="https://lwn.net/Articles/507065/" target="_blank" rel="noopener">TCP small queues</a> 中的说明</p><p>注：bufferbloat 译为“缓冲膨胀”，指的是由于缓冲了太多数据导致延迟增高的现象。</p><h3 id="tcp-challenge-ack-limit-integer"><a class="header-anchor" href="#tcp-challenge-ack-limit-integer"></a>tcp_challenge_ack_limit - INTEGER</h3><p>限制每秒钟送送的 Challenge ACK 的数量，这是 RFC 5961(Improving TCP’sRobustness to Blind In-Window Attacks) 中推荐的。</p><ul><li>默认值：1000</li></ul><p>注<sup class="footnote-ref"><a href="#fn27" id="fnref27">[27]</a></sup>：Challenge ACK 指的是，当接接收到 RST 报文时，如果序列号不符合预期，但是在合理的窗口区间里 <code>RCV.NXT &lt; SEG.SEQ &lt; RCV.NXT+RCV.WND</code>，则 TCP 需要返回一个 ACK，即为 Challenge ACK。</p><p>注：“Blind” 应该指的是第三方，因为它对真实的连接信息一无所知，“In-Window” 指的是攻击者去猜测序列号，伪造的报文在合法的窗口内。这类攻击可能伪造 SYN、RST、或其它报文来进行攻击。</p><h3 id="tcp-rx-skb-cache-boolean"><a class="header-anchor" href="#tcp-rx-skb-cache-boolean"></a>tcp_rx_skb_cache - BOOLEAN</h3><p>开启时，会为每 SKB 维护一个 TCP socket 级别的缓存，在某些情况下会提高性能。要注意在有很多 TCP socket 的机器上开启这个选项是非常危险的，因为它会消耗很多内存。</p><ul><li>默认值：0（关闭）</li></ul><h2 id="后记"><a class="header-anchor" href="#后记"></a>后记</h2><p>最近在学习《TCP/IP 详解卷一》，好不容易把 TCP/IP 的部分看完了，合起书来几乎是什么也不记得，因此才想从 Linux 相关参数入手，去联系书里的知识。实际翻译和注释后，发现很多内容并不是书里得来的，而是网上搜索，文章、博客、RFC、邮件等。</p><p>网卡有许多讲 Linux 参数调整的，经常是只列出参数，对我这种外行来说，不知道参数影响什么机制，因此也不知道为什么要这么设置，这篇文章里我对几乎每个参数的机制都做了调查，并以自己的理解写了简单的注解，希望对读者有用。</p><p>最后感慨 TCP/IP 是非常复杂的，很多机制都有漏洞，对漏洞又有很多算法来修补，修补后又有边缘的 case，可谓是无穷无尽；另一方面有许多不同算法解决不同问题，而算法之间有可能相互影响，很难有全局的掌握；具体实现上还会需要在性能上做一些妥协。因此虽然对 sysctl 中的选项有些了解，还是觉得自己对 TCP 一窍不通，还需要不断学习。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://flylib.com/books/en/2.783.1.50/1/" target="_blank" rel="noopener">https://flylib.com/books/en/2.783.1.50/1/</a> 介绍了基于 TOS 和 fwmark 的路由方案</li><li><a href="https://blog.csdn.net/sinat_20184565/article/details/112253946" target="_blank" rel="noopener">https://blog.csdn.net/sinat_20184565/article/details/112253946</a> 代码层面描述了 fib_multipath_use_neigh 的作用</li><li><a href="https://www.ruijie.com.cn/fa/xw-hlw/82104/" target="_blank" rel="noopener">https://www.ruijie.com.cn/fa/xw-hlw/82104/</a> ECMP 选下一跳的算法</li><li><a href="https://www.cnblogs.com/danxi/p/6709373.html" target="_blank" rel="noopener">Linux TCP协议使用的变量</a> 跟本文类似，对 TCP 变量做了翻译</li><li><a href="https://netdevconf.info/1.2/papers/ahern-what-is-l3mdev-paper.pdf" target="_blank" rel="noopener">What is an L3 Master Device</a>介绍了 L3 master device 的机制</li><li><a href="https://www.kernel.org/doc/Documentation/networking/vrf.txt" target="_blank" rel="noopener">Virtual Routing and Forwarding (VRF)</a>内核文档，介绍 VRF 机制</li><li><a href="https://blog.csdn.net/dog250/article/details/78069964" target="_blank" rel="noopener">Linux VRF(Virtual Routing Forwarding)的原理和实现</a>对 VRF 的使用场景、实现原理有很好的讲解</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://packetlife.net/blog/2008/aug/18/path-mtu-discovery/" target="_blank" rel="noopener">https://packetlife.net/blog/2008/aug/18/path-mtu-discovery/</a> 介绍了路径 MTU 的发现方法 <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/dog250/article/details/78301259" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/78301259</a> 详细介绍了 fwmark_reflect 解决的问题 <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p><a href="http://arthurchiao.art/blog/intro-to-modern-lb-and-proxy-zh/" target="_blank" rel="noopener">[译] 现代网络负载均衡与代理导论（2017）</a> <a href="#fnref3" class="footnote-backref">↩</a></p></li><li id="fn4" class="footnote-item"><p><a href="https://www.cs.unh.edu/cnrg/people/gherrin/linux-net.html#tth_sEc8.2.1" target="_blank" rel="noopener">https://www.cs.unh.edu/cnrg/people/gherrin/linux-net.html#tth_sEc8.2.1</a> 邻居表结构 <a href="#fnref4" class="footnote-backref">↩</a></p></li><li id="fn5" class="footnote-item"><p><a href="https://lwz322.github.io/2019/11/03/ECMP.html" target="_blank" rel="noopener">https://lwz322.github.io/2019/11/03/ECMP.html</a> 简单描述了 ECMP 的哈希方式 <a href="#fnref5" class="footnote-backref">↩</a></p></li><li id="fn6" class="footnote-item"><p><a href="https://www.kernel.org/doc/Documentation/RCU/whatisRCU.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/RCU/whatisRCU.txt</a> 介绍了内核 RCU 的概念 <a href="#fnref6" class="footnote-backref">↩</a></p></li><li id="fn7" class="footnote-item"><p><a href="https://en.wikipedia.org/wiki/Type_of_service" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Type_of_service</a> <a href="#fnref7" class="footnote-backref">↩</a></p></li><li id="fn8" class="footnote-item"><p>参考书 Understading Linux Network Internal 第 23 章 <a href="#fnref8" class="footnote-backref">↩</a></p></li><li id="fn9" class="footnote-item"><p><a href="http://veithen.io/2014/01/01/how-tcp-backlog-works-in-linux.html" target="_blank" rel="noopener">How TCP backlog works inLinux</a> 详细描述了 Linux backlog 的机制 <a href="#fnref9" class="footnote-backref">↩</a></p></li><li id="fn10" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/p/299513070" target="_blank" rel="noopener">关于Linux TCP接收缓存以及接收窗口的一个细节解析</a> 有对 tcp_adv_win_scale 机制的详细描述，强推 <a href="#fnref10" class="footnote-backref">↩</a></p></li><li id="fn11" class="footnote-item"><p><a href="http://cxd2014.github.io/2016/08/16/linux-network-stack/" target="_blank" rel="noopener">Linux网络栈中的队列</a> <a href="#fnref11" class="footnote-backref">↩</a></p></li><li id="fn12" class="footnote-item"><p><a href="https://blog.cloudflare.com/ip-fragmentation-is-broken/" target="_blank" rel="noopener">Broken packets: IP fragmentation is flawed</a> 介绍了四种 PMTU 失效的情形 <a href="#fnref12" class="footnote-backref">↩</a></p></li><li id="fn13" class="footnote-item"><p><a href="http://perthcharles.github.io/2015/10/31/wiki-network-tcp-tlp/" target="_blank" rel="noopener">TCP Tail LossProbe(TLP)</a>文章对 TLP RFC 有详细解读 <a href="#fnref13" class="footnote-backref">↩</a></p></li><li id="fn14" class="footnote-item"><p><a href="https://zh.wikipedia.org/wiki/%E6%98%BE%E5%BC%8F%E6%8B%A5%E5%A1%9E%E9%80%9A%E7%9F%A5" target="_blank" rel="noopener">Wiki: 显式拥塞通知</a> <a href="#fnref14" class="footnote-backref">↩</a></p></li><li id="fn15" class="footnote-item"><p><a href="http://conferences.sigcomm.org/sigcomm/1996/papers/mathis.pdf" target="_blank" rel="noopener">http://conferences.sigcomm.org/sigcomm/1996/papers/mathis.pdf</a>FACK 论文 <a href="#fnref15" class="footnote-backref">↩</a></p></li><li id="fn16" class="footnote-item"><p><a href="https://kernelnewbies.org/Linux_4.15" target="_blank" rel="noopener">https://kernelnewbies.org/Linux_4.15</a> <a href="#fnref16" class="footnote-backref">↩</a></p></li><li id="fn17" class="footnote-item"><p><a href="https://www.cnblogs.com/lshs/p/6038603.html" target="_blank" rel="noopener">TCP系列24—重传—14、F-RTO虚假重传探测</a> 大佬的博客有很多 TCP 相关的内容，值得深挖，这篇讲的是 F-RTO <a href="#fnref17" class="footnote-backref">↩</a></p></li><li id="fn18" class="footnote-item"><p>参考《TCP/IP 详解卷一》的第 17 章 <a href="#fnref18" class="footnote-backref">↩</a></p></li><li id="fn19" class="footnote-item"><p>RFC: <a href="https://tools.ietf.org/html/draft-tcpm-rack-00" target="_blank" rel="noopener">https://tools.ietf.org/html/draft-tcpm-rack-00</a> <a href="#fnref19" class="footnote-backref">↩</a></p></li><li id="fn20" class="footnote-item"><p><a href="https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html" target="_blank" rel="noopener">TCPVariables</a>中对 tcp_reordering 的含义做了更详细的解释 <a href="#fnref20" class="footnote-backref">↩</a></p></li><li id="fn21" class="footnote-item"><p>参考《TCP/IP 详解卷一》的第 14.2 章 <a href="#fnref21" class="footnote-backref">↩</a></p></li><li id="fn22" class="footnote-item"><p><a href="https://www.spinics.net/lists/netdev/msg503106.html" target="_blank" rel="noopener">tcp: implement SACKcompression</a> SACK 压缩的 patch，其中有解释动机 <a href="#fnref22" class="footnote-backref">↩</a></p></li><li id="fn23" class="footnote-item"><p><a href="https://zh.wikipedia.org/wiki/SYN_cookie" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/SYN_cookie</a> <a href="#fnref23" class="footnote-backref">↩</a></p></li><li id="fn24" class="footnote-item"><p><a href="https://zh.wikipedia.org/wiki/TCP%E5%BF%AB%E9%80%9F%E6%89%93%E5%BC%80" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/TCP快速打开</a> <a href="#fnref24" class="footnote-backref">↩</a></p></li><li id="fn25" class="footnote-item"><p><a href="https://lwn.net/Articles/564978/" target="_blank" rel="noopener">TSO sizing and the FQ scheduler</a> 讲解了 TSO和 FQ 机制的一些小细节 <a href="#fnref25" class="footnote-backref">↩</a></p></li><li id="fn26" class="footnote-item"><p><a href="https://redwingz.blog.csdn.net/article/details/89104763" target="_blank" rel="noopener">TCP发送缓存控制tcp_notsent_lowat </a> <a href="#fnref26" class="footnote-backref">↩</a></p></li><li id="fn27" class="footnote-item"><p><a href="https://tools.ietf.org/html/rfc5961" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc5961</a> <a href="#fnref27" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文对
&lt;a href=&quot;https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ip-sysctl.txt&lt;/a&gt;
中关于 IP 和
      
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="tcp" scheme="https://lotabout.me/tags/tcp/"/>
    
      <category term="ip" scheme="https://lotabout.me/tags/ip/"/>
    
      <category term="sysctl" scheme="https://lotabout.me/tags/sysctl/"/>
    
  </entry>
  
  <entry>
    <title>QQA: Spring Bean 如何开启懒加载</title>
    <link href="https://lotabout.me/2021/QQA-how-to-lazy-initialize-spring-beans/"/>
    <id>https://lotabout.me/2021/QQA-how-to-lazy-initialize-spring-beans/</id>
    <published>2021-01-31T21:28:39.000Z</published>
    <updated>2021-05-22T10:33:50.853Z</updated>
    
    <content type="html"><![CDATA[<p>有些 Bean 依赖外部环境，如 Repository 通常依赖数据库连接。一些单元测试中用不到它们，因此希望在测试中不初始化这些 Bean。除此之外，在测试中开启懒加载/延迟初始化(lazy-init)，由于跳过了不用的 Bean，还能加快测试运行的速度。</p><h2 id="spring-2-2-之后"><a class="header-anchor" href="#spring-2-2-之后"></a>Spring 2.2 之后</h2><p>在 Spring 2.2 之后，最直接的方式是在 <code>test/resources/application.yml</code> 配置文件中加入如下参数：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring.main.lazy-initialization:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>内部原理是在 <code>SpringApplication</code> 中，如果检测到该参数为真，则会创建一个BeanFactoryPostProcessor，用于将“所有” BeanDefinition 的 lazyInit 属性置为真。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.lazyInitialization) &#123;</span><br><span class="line">    context.addBeanFactoryPostProcessor(<span class="keyword">new</span> LazyInitializationBeanFactoryPostProcessor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="spring-2-2-之前"><a class="header-anchor" href="#spring-2-2-之前"></a>Spring 2.2 之前</h2><p>参考<a href="https://www.jhipster.tech/tips/027_tip_lazy_init_test_beans.html" target="_blank" rel="noopener">这篇文章</a>，本质上与Spring 2.2 的方法一样，需要在测试包中自定义 BeanFactoryPostProcessor，用于将“所有” BeanDefinition 的 lazyInit 属性置为真：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Profile</span>(<span class="string">"!"</span> + TestLazyBeanInitConfiguration.EAGER_BEAN_INIT)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLazyBeanInitConfiguration</span> <span class="keyword">implements</span> <span class="title">BeanFactoryPostProcessor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String EAGER_BEAN_INIT = <span class="string">"eager-bean-init"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        Arrays.stream(beanFactory.getBeanDefinitionNames())</span><br><span class="line">            .map(beanFactory::getBeanDefinition)</span><br><span class="line">            .forEach(beanDefinition -&gt; beanDefinition.setLazyInit(<span class="keyword">true</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果某个测试不需要懒加载，则通过注解 <code>@ActiveProfiles(TestLazyBeanInitConfiguration.EAGER_BEAN_INIT)</code> 关闭。</p><h2 id="componentscan-lazyinit-true-有坑"><a class="header-anchor" href="#componentscan-lazyinit-true-有坑"></a>@ComponentScan(lazyInit = true) 有坑</h2><p>通常我会在测试包中创建一个 <code>TestApplication</code> 类，并注解为<code>@SpringBootApplication</code> 来完成 Bean 的自动扫描。尝试过下面的方式：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@ComponentScan</span>(lazyInit = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestApplication</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法对于自动创建的 Bean（即标记为 <code>@Component</code>, <code>@Service</code> 等的类）是有效的。但对于 <code>Configuration</code> 类中通过 <code>@Bean</code> 方式创建的 Bean 无效。毕竟<code>@ComponentScan</code> 本身控制的就是扫描 Bean 的行为。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;有些 Bean 依赖外部环境，如 Repository 通常依赖数据库连接。一些单元测试中用不到它们，因此希望在测试中不初始化这些 Bean。除此之外，在测试中开启懒加载/延迟初始化(lazy-init)，由于跳过了不用的 Bean，还能加快测试运行的速度。&lt;/p&gt;
&lt;h2
      
    
    </summary>
    
      <category term="QQA" scheme="https://lotabout.me/categories/QQA/"/>
    
    
      <category term="java" scheme="https://lotabout.me/tags/java/"/>
    
      <category term="spring" scheme="https://lotabout.me/tags/spring/"/>
    
      <category term="QQA" scheme="https://lotabout.me/tags/QQA/"/>
    
  </entry>
  
  <entry>
    <title>如何理解 Explicit is Better than Implicit?</title>
    <link href="https://lotabout.me/2021/Explicit-is-Better-than-implicit/"/>
    <id>https://lotabout.me/2021/Explicit-is-Better-than-implicit/</id>
    <published>2021-01-25T22:24:00.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>“Explicit is better than implicit” 是 <a href="https://www.python.org/dev/peps/pep-0020/" target="_blank" rel="noopener">The Zen ofPython</a> 中的一句格言。长久以来都觉得挺在理，直到有天有人用这句话为基础，提出了一个我不甚赞同的观点，才发现从来就没有真正理解过它。</p><p>神奇的是在搜索过程中，发现讨论这句格言的并没有多少，不同的讨论中对 &quot;explicit&quot;含义的理解差别也很大，最终发现最好的讨论来自 Elixer 社区：<a href="https://elixirforum.com/t/on-explicit-is-better-than-implicit/22076/17" target="_blank" rel="noopener">On ‘Explicit isbetter than Implicit’</a>。本文尝试列举见过的一些观点，以及自己的理解。</p><h2 id="explicit-是什么含义？"><a class="header-anchor" href="#explicit-是什么含义？"></a>Explicit 是什么含义？</h2><p>Explicit 这个单词释义为：</p><blockquote><p>stated clearly and in detail, leaving no room for confusion or doubt</p></blockquote><p>“清楚详细地陈述，不容混淆或怀疑”。翻译成中文有“显式的”、“精密”、“不含糊”、“明确的”等多种翻译。在代码的语境下，什么样的代码才能称得上是 “explicit” 呢？网上看到了不同角度的观点。</p><h2 id="一些观点"><a class="header-anchor" href="#一些观点"></a>一些观点</h2><h3 id="把代码显式写出来"><a class="header-anchor" href="#把代码显式写出来"></a>把代码显式写出来</h3><p>显式地写出代码，也可以有多种理解方式，<a href="https://eng.libretexts.org/Bookshelves/Computer_Science/Book%3A_Making_Games_with_Python_and_Pygame_(Sweigart)/06%3A_Simulate/6.21%3A_Explicit_is_Better_Than_Implicit" target="_blank" rel="noopener">Making Games with Python andPygame</a>中举了一个示例：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getButtonClicked</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> YELLOWRECT.collidepoint( (x, y) ):</span><br><span class="line">        <span class="keyword">return</span> YELLOW</span><br><span class="line">    <span class="keyword">elif</span> BLUERECT.collidepoint( (x, y) ):</span><br><span class="line">        <span class="keyword">return</span> BLUE</span><br><span class="line">    <span class="keyword">elif</span> REDRECT.collidepoint( (x, y) ):</span><br><span class="line">        <span class="keyword">return</span> RED</span><br><span class="line">    <span class="keyword">elif</span> GREENRECT.collidepoint( (x, y) ):</span><br><span class="line">        <span class="keyword">return</span> GREEN</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span> <span class="comment"># 这里显式地返回了 None</span></span><br></pre></td></tr></table></figure><p>书中提到最后一行显式写 <code>return None</code> 能让读者更直接理解代码的用途。</p><p>思考：这个样例容易理解，也很赞同，但是如何推而广之呢？Explicit 在上面的例子中体现在哪呢？</p><p>我理解它的重点在于，当所有的 <code>if</code> 语句都不命中时，默认的行为是未知的，而显示写出的 <code>return None</code> 则清楚地描述了默认的情形，即使 Python 的默认行为发生变化，该方法的行为也不会发生变化。</p><h3 id="要具体-要特化"><a class="header-anchor" href="#要具体-要特化"></a>要具体、要特化</h3><p><a href="https://miguelgfierro.com/blog/2018/python-pro-tips-understanding-explicit-is-better-than-implicit/" target="_blank" rel="noopener">这篇文章</a>明确表达了自己对“Explicit is Better than Implicit”的理解：</p><blockquote><p>Being explicit means being concrete and specific instead of abstract andgeneral. It also means not to hide the behavior of a function.</p></blockquote><p>Explicit 意味着要具体、特化，不要抽象、通用。同时不要隐藏函数的行为。</p><p>对于要具体、特化，文章中举例如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Explicit                               |  # Implicit</span></span><br><span class="line"><span class="keyword">import</span> requests                          |  <span class="keyword">from</span> requests <span class="keyword">import</span> *</span><br><span class="line">r = requests.get(<span class="string">"https://lotabout.me"</span>)  |  r = get(<span class="string">"https://lotabout.me"</span>)</span><br></pre></td></tr></table></figure><p>对这个例子也是比较认同的。但我认为重点不在于 <code>requests.get</code> 怎么好，而在于<code>import *</code> 不好。因为这样的话 <code>get</code> 方法的来源就不明确了，容易混淆，需要靠猜。相对的，下面的代码我认为也是好的：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> get</span><br><span class="line">r = get(<span class="string">"https://lotabout.me"</span>)</span><br></pre></td></tr></table></figure><p>这里我的理解是，代码执行的逻辑，从溯源的角度上没有二义。如果用了 <code>import *</code>，同时两个模块中都有 <code>get</code> 方法，则容易混淆，不知道真正执行的是哪个方法。</p><h3 id="不要隐藏函数行为"><a class="header-anchor" href="#不要隐藏函数行为"></a>不要隐藏函数行为</h3><p>同样来自<a href="https://miguelgfierro.com/blog/2018/python-pro-tips-understanding-explicit-is-better-than-implicit/" target="_blank" rel="noopener">上面提到的文章</a>，示例如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Explicit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># code for reading a csv</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_json</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># code for reading a json</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Implicit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># code for reading a csv or json</span></span><br><span class="line">    <span class="comment"># depending on the file extension</span></span><br></pre></td></tr></table></figure><p>这个示例我不认同。从观念上，它与 OOP 中提到的封装的思想；从使用上，文件类型的判断的要求并没有消失，只是丢给用户自己实现了；进而从结果上，只要有多种文件类型存在，在某个层级上一定会有一个 <code>read</code> 方法的。</p><p>举例说，如果说不要隐藏函数的行为，那么我们在写 Web 服务的时候，在我们访问 DB时，我们会希望直接处理 TCP 连接吗？Spring 框架选择隐藏这些行为，可以说是错误吗？</p><p>关键在于“预期”，与预期相符就是“Explicit”的，正如<a href="https://elixirforum.com/t/on-explicit-is-better-than-implicit/22076/14" target="_blank" rel="noopener">Elixer 社区的讨论</a>：“Don’t surprise me”。于是 Explicit 的要求演变成如何给用户正确的预期？我的回答是：良好命名，遵循 common sense，除此之外需要教育。</p><h3 id="no-magic"><a class="header-anchor" href="#no-magic"></a>No Magic</h3><p>Django 的 <a href="https://docs.djangoproject.com/en/3.1/misc/design-philosophies/#explicit-is-better-than-implicit" target="_blank" rel="noopener">Designphilosophies</a>中有如下描述：</p><blockquote><p>Magic shouldn’t happen unless there’s a really good reason for it. Magic isworth using only if it creates a huge convenience unattainable in otherways, and it isn’t implemented in a way that confuses developers who aretrying to learn how to use the feature.</p></blockquote><p>这里指的是不要用复杂的语言特性（大家常把元编程称作 Magic）。</p><p>这个观点的持保留意见，我认为重点还是在于知识、背景是否匹配。例如当我熟悉Decorator 时，就会觉得用 decorator 来指定一个 REST API 的路由很直观，很容易理解。但对于不熟悉的人可能就完全不能理解数据的路径(data path)，不知道为什么一个注解是怎么真正完成 URL 到函数的绑定的。</p><h3 id="含义更直接"><a class="header-anchor" href="#含义更直接"></a>含义更直接</h3><p>还有一些讨论会指向同一段逻辑的不同写法，例如<a href="https://stackoverflow.com/q/64070128" target="_blank" rel="noopener">SO 上的讨论</a> 举的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># ① my understanding is that this is implicit</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> a:</span><br><span class="line">   print(<span class="string">"list is empty"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ② my understanding is that this is explicit</span></span><br><span class="line"><span class="keyword">if</span> len(a) == <span class="number">0</span>:</span><br><span class="line">   print(<span class="string">"list is empty"</span>)</span><br></pre></td></tr></table></figure><p>这是一个“矛盾”的讨论，题主认为 ② 是 explicit，下面的回答则指出写成 ① 的方式能应对更多的情形，如 <code>a</code> 不是列表的情形。我能理解 ① 的作用，但同时也赞同题主的观点，从阅读的角度来说 ② 是更直接的。</p><p>还有 <a href="https://elixirforum.com/t/on-explicit-is-better-than-implicit/22076/17" target="_blank" rel="noopener">Elixer 社区的讨论</a>，例子一方面说明什么是语义上的“直接”，也间接反驳“不要隐藏函数行为”的观点：</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (person.sex === <span class="number">1</span> and person.children.length &gt; <span class="number">0</span>) &#123; ...do something... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (person.isFemale() and person.hasChildren()) &#123; ...do something... &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (person.isFemaleParent()) &#123; ...do something... &#125;</span><br></pre></td></tr></table></figure><p>从阅读代码的角度，明显上最后一种最容易阅读，更符合语言习惯，不容易有歧义。</p><h2 id="我所理解的-explicit"><a class="header-anchor" href="#我所理解的-explicit"></a>我所理解的 Explicit</h2><p>上面我们看到，“Explicit is Better than Implicit”这句话本身就是 implicit 的，有很多歧义的理解。</p><p>我自己的总结是：<strong>Minimal Knowledge, No Surprise</strong>。</p><p>对于阅读者/使用者而言，需要最少的知识去理解它，在我们隐藏复杂度的过程中，要保证函数/API/…行为符合预期，没有意外。</p><p>例如对于函数最后加上 <code>return None</code> 比不加要好，因为加上后，我们就不需要了解Python 函数的默认返回值是什么。类似的，显式引用会更好：<code>from requests import get</code>，因为读者不需要去找 <code>get</code> 方法的来源，以及有重名时是哪个函数生效。</p><p>对于“不要隐藏函数行为”的做法，就有一定的反对意见。例如 <code>read_csv</code> 和<code>read_json</code> 是否优于 <code>read</code> 方法？我认为此时 No Surprise 很重要。对于 csv,json 等文件格式我认为 <code>read</code> 更优，因为根据扩展名判断类型是一个共识，并不会有surprise 发生。而如果读取的是 HDFS 上的文件，由于很多文件保存时并不会按扩展名保存，我认为此时 <code>read</code> 就容易有 Surprise，因此是不合适的。</p><p>对于 Magic，如果做法不是 common sense，则需要我们额外学习 Magic 的含义，就是属于&quot;Implicit&quot; 的，此时用来是不用，就要看它能给我们带来多大的好处了。同样的还有语言中的语法糖，经常需要额外学习知识才能看懂/自己使用。</p><p>最后对于“含义更直接”，认为在 No Surprise 的前提下，越接近“共识”越好，因为需要更少的知识。</p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>关于 “Explicit is Better than Implicit?” 的理解，文章罗列了网上搜索的一些观点：</p><ul><li>把代码显式写出来，如显式加上 <code>return None</code></li><li>要具体、要特化，如显式 import：<code>from requests import get</code></li><li>不要隐藏函数行为，如实现 <code>read_csv</code> 与 <code>read_json</code> 要好于只实现 <code>read</code></li><li>No Magic，如非必要，不要使用元编程</li><li>含义更直接，如用 <code>len(a) == 0</code> 判断列表为空而不是 <code>not a</code></li></ul><p>最后总结并说明了自己对 “explicit” 含义的理解：<strong>Minimal Knowledge, No Surprise</strong></p><p>当然，我们会发现 Minimal Knowledge 或者说“共识”对于不同的群体，在不同上下文之下是不同的。这也是我们需要经验去理解，需要花时间去沟通的内容了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;“Explicit is better than implicit” 是 &lt;a href=&quot;https://www.python.org/dev/peps/pep-0020/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Zen of
Python
      
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="Python" scheme="https://lotabout.me/tags/Python/"/>
    
      <category term="Zen" scheme="https://lotabout.me/tags/Zen/"/>
    
  </entry>
  
  <entry>
    <title>Spring Bean 生命周期介绍</title>
    <link href="https://lotabout.me/2021/Spring-Bean-LifeCycle/"/>
    <id>https://lotabout.me/2021/Spring-Bean-LifeCycle/</id>
    <published>2021-01-24T14:34:06.000Z</published>
    <updated>2021-05-22T10:33:50.857Z</updated>
    
    <content type="html"><![CDATA[<p>Bean 是 Spring 对组件的抽象，Bean 的创建、销毁都由 Spring 控制。使用过程中我们会希望定制创建、销毁过程中的部分逻辑，于是作为框架的 Spring 需要提供相应的机制。我们关心 Bean 的生命周期，就在于需要了解可以定制的部分。</p><h2 id="bean-创建过程"><a class="header-anchor" href="#bean-创建过程"></a>Bean 创建过程</h2><p>Bean 的创建过程如下，这些阶段 Spring 都提供了定制的手段：</p><img src="/2021/Spring-Bean-LifeCycle/Spring-Bean-Creation.svg" class="" title="Spring Bean 创建过程"><p>上图中需要注意下面几点：</p><ul><li>① 中已经完成依赖注入。</li><li>②、③、④ 为代表的这些 <code>Aware</code> 接口，一般用于向 Bean 中注入 Spring 的组件。个人常用的是 ④，注入 <code>ApplicationContext</code> 后续用来获取 Prototype Scope 的 Bean。除了图中画的，还有<a href="https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#aware-list" target="_blank" rel="noopener">其它的 Aware 接口</a>。</li><li>⑥、⑦、⑧ 可以为 Bean 指定初始化方法，当前建议只用 <code>@PostConstruct</code>。如果同时使用不同手段指定同一个方法作为 Bean 的初始化方法，则该方法只会被调用一次。</li><li>与其它阶段不同，⑤ 与 ⑨ 是 <code>BeanFactory</code> 级别的定制，其它阶段则是 Bean 级别的。</li></ul><p>上面列出的是单个 Bean 创建时各个阶段的顺序，那不同 Bean 创建的相对顺序呢？</p><p>一个 Bean 在 Populate Properties 时就完成了依赖注入，如果 Bean X 依赖 Bean Y，那么在 X 的依赖注入时 Y 就需要处于 Ready 状态。换句话说被依赖的 Bean Y 走完了所有流程后Bean X 才开始创建。但如果两个 Bean 间没有依赖关系，则没有这个保证。</p><h2 id="bean-的销毁过程"><a class="header-anchor" href="#bean-的销毁过程"></a>Bean 的销毁过程</h2><p>Bean 的销毁过程如下，推荐使用 <code>@PreDestroy</code> 的方式。另外注意：对于 PrototypeScope 的 Bean，Spring 是不负责销毁的。</p><img src="/2021/Spring-Bean-LifeCycle/Spring-Bean-Destroy.svg" class="" title="Spring Bean 销毁过程"><p>不同 Bean 之间的销毁顺序又是怎么样的呢？<a href="https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-dependson" target="_blank" rel="noopener">文档</a>里说，如果 Bean X 依赖 Bean Y，创建时是 Bean Y 先创建，销毁时则是反过来，BeanX 先销毁。</p><h2 id="附加题：如何等待所有-bean-初始化完成？"><a class="header-anchor" href="#附加题：如何等待所有-bean-初始化完成？"></a>附加题：如何等待所有 Bean 初始化完成？</h2><p>有时候我们需要在所有 Bean 都初始化后做一些操作，要怎么做？上面提到的机制都是在单个 Bean 中完成，无法顾及多个 Bean 之间的操作。这时可以利用<code>ApplicationContext</code> 的<a href="https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#context-functionality-events" target="_blank" rel="noopener">Event 机制</a>。</p><p>在 <code>ApplicationContext</code> 初始化完成或刷新时，会发送 <code>ContextRefreshedEvent</code> 事件，我们只需要让某个 Bean 监听该事件即可。当然要注意这个事件可能会被发送多次（因为刷新时也会再发送该事件），需要酌情忽略后续事件。监听示例代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InitService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;InitBean&gt; beansToInitialize;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span>(required = <span class="keyword">false</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">InitService</span><span class="params">(List&lt;InitBean&gt; beansToInitialize)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.beansToInitialize = beansToInitialize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@EventListener</span>(ContextRefreshedEvent<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">    <span class="title">public</span> <span class="title">void</span> <span class="title">onApplicationEvent</span>(<span class="title">ContextRefreshedEvent</span> <span class="title">event</span>) </span>&#123;</span><br><span class="line">        event.getApplicationContext().getBean(InitService<span class="class">.<span class="keyword">class</span>).<span class="title">initialize</span>()</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        beansToInitialize.forEach(InitBean::init);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-nature" target="_blank" rel="noopener">Customizing the Nature of a Bean</a> Spring 参考文档，内容比较全但不直观</li><li><a href="https://jstobigdata.com/spring/spring-bean-lifecycle-callbacks/" target="_blank" rel="noopener">Spring bean Lifecycle Callbacks</a> 介绍了 Hack Bean 生命周期的几种方法，本文的图在其基础上补充完成</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Bean 是 Spring 对组件的抽象，Bean 的创建、销毁都由 Spring 控制。使用过程中我们会希望定制创建、销毁过程中的部分逻辑，于是作为框架的 Spring 需要提供相应的机制。我们关心 Bean 的生命周期，就在于需要了解可以定制的部分。&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="Spring" scheme="https://lotabout.me/tags/Spring/"/>
    
      <category term="Bean" scheme="https://lotabout.me/tags/Bean/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 加锁机制验证记录</title>
    <link href="https://lotabout.me/2020/God-Damn-MySQL-Locks/"/>
    <id>https://lotabout.me/2020/God-Damn-MySQL-Locks/</id>
    <published>2020-12-13T09:46:28.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">官方文档</a>给出了不同类型语句的加锁情形，但我觉得<a href="https://www.jianshu.com/p/13f5777966dd" target="_blank" rel="noopener">这个总结</a>更到位，因此想结合文章的几种情形，结合 InnoDB Monitor Output 做分析。</p><p>文章是验证过程的记录，全文比较长，建议结合目录查看感兴趣的部分。</p><h2 id="开启-innodb-monitor"><a class="header-anchor" href="#开启-innodb-monitor"></a>开启 InnoDB Monitor</h2><p>参考：<a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-enabling-monitors.html" target="_blank" rel="noopener">官方文档</a></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_status_output=<span class="keyword">ON</span>; <span class="comment">-- 开启输出</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_status_output_locks=<span class="keyword">ON</span>; <span class="comment">-- 开启锁信息输出</span></span><br></pre></td></tr></table></figure><p>注意这些选项在 mysql 重启后会恢复默认值。接下来使用命令查看信息：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">ENGINE</span> <span class="keyword">INNODB</span> <span class="keyword">STATUS</span>\G</span><br></pre></td></tr></table></figure><p>样例输出，我们只关心锁相关的内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929632, ACTIVE 27 sec</span><br><span class="line">2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 1</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9179 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_pk_rc&#96; trx id 929632 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1813 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_pk_rc&#96; trx id 929632 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 4; compact format; info bits 32</span><br><span class="line"> 0: len 4; hex 80000005; asc     ;;</span><br><span class="line"> 1: len 6; hex 0000000e2f60; asc     &#x2F;&#96;;;</span><br><span class="line"> 2: len 7; hex 4c000002222e83; asc L   &quot;. ;;</span><br><span class="line"> 3: len 1; hex 63; asc c;;</span><br></pre></td></tr></table></figure><ul><li>“page no 3 n bits 72” 代表在第 3 页的记录上，lock bitmap 共 72 位</li><li>“index PRIMARY of …” 代表锁在某个索引上，PRIMARY 代表锁在主键上</li><li>“lock_mode X” 锁模式，X 代表互斥，锁模式可以参数官方文档 <a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-locking.html" target="_blank" rel="noopener">InnoDBLocking</a></li><li>“locks rec but not gap” 代表记录锁，“locks gap before rec” 代表间隙锁，没有说明则代表 Next Key Lock</li><li>“heap no 4” 代表记录的序号，0 代表 infimum 记录、1 代表 supremum 记录，用户记录从 2 开始</li><li>PHYSICAL RECORD 后面的内容是索引记录的内存结构，通常没办法直接阅读</li></ul><p>这个记录里没法直接看出锁住了哪些记录。一种方法是通过 <code>select * from information_schema.innodb_locks \G;</code> 查看抢锁没抢到的信息，为了查看记录，在测试时可以另开一个会话，用诸如 <code>SELECT * FROM ... WHERE ... FOR UPDATE</code> 来抢锁，这样就可以看出锁在哪个记录上了。样例输出：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lock_id     | 929771:1817:4:4</span><br><span class="line">lock_trx_id | 929771</span><br><span class="line">lock_mode   | X</span><br><span class="line">lock_type   | RECORD</span><br><span class="line">lock_table  | &#96;test&#96;.&#96;id_si_rc&#96;</span><br><span class="line">lock_index  | id_si</span><br><span class="line">lock_space  | 1817</span><br><span class="line">lock_page   | 4</span><br><span class="line">lock_rec    | 4</span><br><span class="line">lock_data   | 5, 3 -- 注意这里是数据标识</span><br></pre></td></tr></table></figure><p>还有一个工具好用的工具<a href="https://github.com/jeremycole/innodb_ruby" target="_blank" rel="noopener">innodb_ruby</a> 可以用来解析 MySQL 的静态文件。Monitor 日志里我们知道是哪个页的哪条记录，可以使用innodb_ruby 来找到对应的记录。（不过不建议在生产上使用）</p><h2 id="不同情形下加锁验证"><a class="header-anchor" href="#不同情形下加锁验证"></a>不同情形下加锁验证</h2><p>我们会考查 <code>DELETE FROM t1 WHERE id = 5</code> 语句在不同情形下的加锁情况，通过构造数据、执行语句、查看 Monitor 日志来验证加锁的机制。</p><h3 id="主键-rc"><a class="header-anchor" href="#主键-rc"></a>主键 + RC</h3><p>结论：只对 ID = 5 这条记录加 Record Lock</p><img src="/2020/God-Damn-MySQL-Locks/id_pk_rc.svg" class="" title="主键加锁"><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_pk_rc(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_pk_rc <span class="keyword">values</span>(<span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_pk_rc <span class="keyword">values</span>(<span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_pk_rc <span class="keyword">values</span>(<span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_pk_rc <span class="keyword">values</span>(<span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_pk_rc <span class="keyword">values</span>(<span class="number">9</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_pk_rc <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929632, ACTIVE 27 sec</span><br><span class="line">2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 1</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9179 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_pk_rc&#96; trx id 929632 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1813 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_pk_rc&#96; trx id 929632 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 4; compact format; info bits 32</span><br><span class="line"> 0: len 4; hex 80000005; asc     ;;</span><br><span class="line"> 1: len 6; hex 0000000e2f60; asc     &#x2F;&#96;;;</span><br><span class="line"> 2: len 7; hex 4c000002222e83; asc L   &quot;. ;;</span><br><span class="line"> 3: len 1; hex 63; asc c;;</span><br></pre></td></tr></table></figure><p>看到输出里有 <code>lock_mode X locks rec but not gap</code>，可以确定持有的是记录锁。</p><h3 id="唯一索引-rc"><a class="header-anchor" href="#唯一索引-rc"></a>唯一索引 + RC</h3><p>结论：索引和聚簇索引/主键中都对 ID = 5 加 Record Lock</p><img src="/2020/God-Damn-MySQL-Locks/id_ui_rc.svg" class="" title="唯一索引会对索引与主键加锁"><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_ui_rc(pk <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">UNIQUE</span> <span class="keyword">INDEX</span> id_ui <span class="keyword">ON</span> id_ui_rc(<span class="keyword">id</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ui_rc <span class="keyword">values</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ui_rc <span class="keyword">values</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ui_rc <span class="keyword">values</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ui_rc <span class="keyword">values</span>(<span class="number">4</span>, <span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ui_rc <span class="keyword">values</span>(<span class="number">5</span>, <span class="number">9</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_ui_rc <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929694, ACTIVE 6 sec</span><br><span class="line">3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9241 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_ui_rc&#96; trx id 929694 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1815 page no 4 n bits 72 index id_ui of table &#96;test&#96;.&#96;id_ui_rc&#96; trx id 929694 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 32</span><br><span class="line"> 0: len 4; hex 80000005; asc     ;;</span><br><span class="line"> 1: len 4; hex 80000003; asc     ;;</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 1815 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_ui_rc&#96; trx id 929694 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> 0: len 4; hex 80000003; asc     ;;</span><br><span class="line"> 1: len 6; hex 0000000e2f9e; asc     &#x2F; ;;</span><br><span class="line"> 2: len 7; hex 7a0000059525c9; asc z    % ;;</span><br><span class="line"> 3: len 4; hex 80000005; asc     ;;</span><br><span class="line"> 4: len 1; hex 63; asc c;;</span><br></pre></td></tr></table></figure><p>可以看到分别对 <code>index id_ui</code> 和 <code>index PRIMARY</code> 加了 Record Lock。</p><h3 id="非唯一索引-rc"><a class="header-anchor" href="#非唯一索引-rc"></a>非唯一索引 + RC</h3><p>结论：会对所有 ID = 5 的索引记录加 Record Lock，同时对主键加 Record Lock。</p><img src="/2020/God-Damn-MySQL-Locks/id_si_rc.svg" class="" title="非唯一索引会对多条记录加锁"><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_si_rc(pk <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> id_si <span class="keyword">ON</span> id_si_rc(<span class="keyword">id</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rc <span class="keyword">values</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rc <span class="keyword">values</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rc <span class="keyword">values</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rc <span class="keyword">values</span>(<span class="number">4</span>, <span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rc <span class="keyword">values</span>(<span class="number">5</span>, <span class="number">5</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_si_rc <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志（省略了 PHYSICAL RECORD 的内容）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929779, ACTIVE 3 sec</span><br><span class="line">3 lock struct(s), heap size 1136, 4 row lock(s), undo log entries 2</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9325 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_si_rc&#96; trx id 929779 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1817 page no 4 n bits 72 index id_si of table &#96;test&#96;.&#96;id_si_rc&#96; trx id 929779 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 1817 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_si_rc&#96; trx id 929779 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><p>可以看到一共有 4 条记录，首先可以看到索引 <code>id_si</code> 和 <code>PRIMARY</code> 分别锁住了两条记录，加的锁都是 X Record Lock No Gap，也就是记录锁。我们通过 <code>select * from information_schema.innodb_locks \G;</code> 查看是锁住了 <code>3, 5</code> 这两条记录。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lock_id     | 929779:1817:4:4</span><br><span class="line">lock_trx_id | 929779</span><br><span class="line">lock_mode   | X</span><br><span class="line">lock_type   | RECORD</span><br><span class="line">lock_table  | &#96;test&#96;.&#96;id_si_rc&#96;</span><br><span class="line">lock_index  | id_si</span><br><span class="line">lock_space  | 1817</span><br><span class="line">lock_page   | 4</span><br><span class="line">lock_rec    | 4</span><br><span class="line">lock_data   | 5, 3  &lt;- 注意这里</span><br></pre></td></tr></table></figure><h3 id="无索引-rc"><a class="header-anchor" href="#无索引-rc"></a>无索引 + RC</h3><p>结论：对所有记录加 Record Lock 再释放不匹配的记录锁</p><img src="/2020/God-Damn-MySQL-Locks/id_ni_rc.svg" class="" title="无索引会对所有记录加 Record Lock"><p>这个情形比较特殊，涉及两个<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">知识点</a></p><ol><li>MySQL 加锁时是对处理过程中“扫描”到的记录加锁，不管这条记录最终是不是通过WHERE 语句剔除了</li><li>对于 READ COMMITTED，MySQL 在扫描结束后，会违反 #1，释放 WHERE 条件不满足的记录锁</li></ol><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_ni_rc(pk <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rc <span class="keyword">values</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rc <span class="keyword">values</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rc <span class="keyword">values</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rc <span class="keyword">values</span>(<span class="number">4</span>, <span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rc <span class="keyword">values</span>(<span class="number">5</span>, <span class="number">5</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_ni_rc <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志（省略了 PHYSICAL RECORD 的内容）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 1446, ACTIVE 17 sec</span><br><span class="line">2 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 2</span><br><span class="line">MySQL thread id 7, OS thread handle 123145446559744, query id 267 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_ni_rc&#96; trx id 1446 lock mode IX</span><br><span class="line">RECORD LOCKS space id 27 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_ni_rc&#96; trx id 1446 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><p>看到 TABLE LOCK 的状态是 <code>IX</code> 说明没有加表锁。同时看到最终锁住的只有heap_no =4 和 6 的两条记录。</p><h3 id="主键-rr"><a class="header-anchor" href="#主键-rr"></a>主键 + RR</h3><p>当 ID 为主键时，在 RR 隔离级别下，加锁情况与 <a href="#%E4%B8%BB%E9%94%AE-rc">主键 + RC</a> 一致，都是对主键记录加 Record Lock。</p><h3 id="唯一索引-rr"><a class="header-anchor" href="#唯一索引-rr"></a>唯一索引 + RR</h3><p>当 ID 为唯一索引时，在 RR 隔离级别下，加锁情况与 <a href="#%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95-rc">唯一索引 + RC</a>一致，都是对索引记录和聚簇索引/主键 Record Lock。</p><h3 id="非唯一索引-rr"><a class="header-anchor" href="#非唯一索引-rr"></a>非唯一索引 + RR</h3><p>结论：对索引记录 Next Key Lock，末尾加 Gap Lock，同时对主键加 Record Lock</p><img src="/2020/God-Damn-MySQL-Locks/id_si_rr.svg" class="" title="对索引记录 Next Key Lock，末尾加 Gap Lock，同时对主键加 Record Lock"><p>Repeatable Read 和 Read Committed 隔离级别的主要区别是 RR 要防止幻读。幻读指的是执行同一个 SQL 两次得到的结果不同。考虑下面的场景：</p><ol><li>事务 A 执行 <code>SELECT count(*) FROM t WHERE id = 5 FOR UPDATE</code> 返回 2 个元素</li><li>事务 B 插入一条 <code>id = 5</code> 的记录</li><li>事务 A 再次执行 <code>SELECT count(*) FROM t WHERE id = 5 FOR UPDATE</code> 返回 3 个元素</li></ol><p>为了要避免这种情况，在 RR 隔离级别下，在 #1 执行时不仅要锁住现有的 ID=5 的索引，还需要阻止 ID = 5 的记录插入（即 #2）。而 Gap Lock 就是实现这个目的的一种手段。</p><p>考虑到索引是有序的，因此如果索引里有 <code>[3, 5, 5, 7]</code> 这几个元素，则可以通过锁住<code>(3, 5)</code>、<code>(5, 7)</code> 这几个区间，加上 <code>[5]</code> 这几个已经存在的元素，就可以阻止 ID= 5 的记录插入。Gap Lock（间隙锁）的含义是锁住区间，而如果加上右边的闭区间，如<code>(3, 5]</code> 就称为记录 5 的 Next-Key Lock。</p><p>InnoDB 在扫描行时会为扫到的行加上 Next-Key Lock，对于上面的数据，扫到记录 5 时，会加上 <code>(3, 5]</code> 锁，同时，还会对下一个记录加上 Gap Lock，即 <code>(5, 7)</code>，造成<code>(3, 7)</code> 都无法插入的现象，验证 MySQL 实现如下：</p><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_si_rr(pk <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> id_si <span class="keyword">ON</span> id_si_rr(<span class="keyword">id</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rr <span class="keyword">values</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rr <span class="keyword">values</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rr <span class="keyword">values</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rr <span class="keyword">values</span>(<span class="number">4</span>, <span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_si_rr <span class="keyword">values</span>(<span class="number">5</span>, <span class="number">5</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> REPEATABLE <span class="keyword">READ</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_si_rr <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志（省略 PHYSICAL RECORD 的内容）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929891, ACTIVE 6 sec</span><br><span class="line">4 lock struct(s), heap size 1136, 5 row lock(s), undo log entries 2</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9442 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_si_rr&#96; trx id 929891 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1820 page no 4 n bits 72 index id_si of table &#96;test&#96;.&#96;id_si_rr&#96; trx id 929891 lock_mode X</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 1820 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_si_rr&#96; trx id 929891 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 1820 page no 4 n bits 72 index id_si of table &#96;test&#96;.&#96;id_si_rr&#96; trx id 929891 lock_mode X locks gap before rec</span><br><span class="line">Record lock, heap no 5 PHYSICAL RECORD: n_fields 2; compact format; info bits 0</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><p>首先我们看到：</p><ul><li>对索引 <code>id_si</code> 有两条 Next-Key Lock 记录</li><li>对主键有两条 Record Lock 记录</li><li>最后对索引 <code>id_si</code> 还有一条 Gap Lock (heap_no = 5 对应 pk = 4 这条记录)</li></ul><p>为什么唯一索引 + RR 就不需要 Gap Lock 呢？是因为我们的核心目的是不让其它事务插入 <code>ID = 5</code> 的记录，如果 ID 是唯一索引，锁住记录本身就能够满足要求了，不再需要Gap Lock。</p><h3 id="无索引-rr"><a class="header-anchor" href="#无索引-rr"></a>无索引 + RR</h3><p>结论：对所有行都加记录锁，且索引前后都要加 Gap Lock</p><img src="/2020/God-Damn-MySQL-Locks/id_ni_rr.svg" class="" title="对所有行都加记录锁，且索引前后都要加 Gap Lock"><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_ni_rr(pk <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rr <span class="keyword">values</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rr <span class="keyword">values</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="string">'b'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rr <span class="keyword">values</span>(<span class="number">3</span>, <span class="number">5</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rr <span class="keyword">values</span>(<span class="number">4</span>, <span class="number">7</span>, <span class="string">'c'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> id_ni_rr <span class="keyword">values</span>(<span class="number">5</span>, <span class="number">5</span>, <span class="string">'b'</span>);</span><br></pre></td></tr></table></figure><p>执行语句：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置为 RC 隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> REPEATABLE <span class="keyword">READ</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>; <span class="comment">-- 开启事务</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> id_ni_rr <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 先不结束事务，验证 Monitor Output 再用 ROLLBACK; 回滚</span></span><br></pre></td></tr></table></figure><p>Monitor 输出日志（省略了部分信息）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---TRANSACTION 929980, ACTIVE 5 sec</span><br><span class="line">2 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 2</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9529 localhost root</span><br><span class="line">TABLE LOCK table &#96;test&#96;.&#96;id_ni_rr&#96; trx id 929980 lock mode IX</span><br><span class="line">RECORD LOCKS space id 1822 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;id_ni_rr&#96; trx id 929980 lock_mode X</span><br><span class="line">Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 73757072656d756d; asc supremum;;</span><br><span class="line"></span><br><span class="line">Record lock, heap no 2 PHYSICAL RECORD: n_fields 5; compact format; info bits 0</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 3 PHYSICAL RECORD: n_fields 5; compact format; info bits 0</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 4 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0</span><br><span class="line"> ...</span><br><span class="line">Record lock, heap no 6 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><p>首先看到 TABLE LOCK 的状态是 <code>IX</code> 说明没有加表锁。同时看到锁住了 heap no 2~6的记录，对应数据库中的 5 条记录。另外这里的锁是 Next Key Lock，加上 heap no 为 1的 “supremum” 记录的 gap lock，锁住了所有已经存在和不存在的行。因此如果执行<code>SELECT * FROM id_ni_rc WHERE id = 0 FOR UPDATE</code> 也会阻塞，尽管 <code>0</code> 记录不在数据库中。</p><h2 id="死锁验证"><a class="header-anchor" href="#死锁验证"></a>死锁验证</h2><p>死锁与获取锁的顺序有关，一条语句（如 INSERT、DELETE）中对不同行、不同索引的加锁存在先后，因此不同事务内的语句执行时，有可能产生死锁。常见死锁原因（摘自<a href="https://tanquan.me/2016/05/31/MySQL-InnoDB-Lock/" target="_blank" rel="noopener">MySQL InnoDB锁和死锁</a>）：</p><ul><li>同一索引上，两个session相反的顺序加锁多行记录</li><li>UPDATE/DELETE 通过不同的二级索引更新多条记录，可能造成在 Primary key 上不同的加锁顺序</li><li>Primary key 和 Secondary index，通过 primary key 找到记录，更新 Secondaryindex 字段与通过 Secondary index 更新记录</li></ul><p>样例情形：</p><img src="/2020/God-Damn-MySQL-Locks/id_si_rc_deadlock.svg" class="" title="死锁"><p>首先建表准备数据：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> deadlock(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>, <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">32</span>), reg <span class="built_in">int</span>);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> deadlock_name <span class="keyword">ON</span> deadlock(<span class="keyword">name</span>);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> deadlock_reg <span class="keyword">ON</span> deadlock(reg);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 准备数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> deadlock <span class="keyword">values</span>(<span class="number">1</span>, <span class="string">'x'</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> deadlock <span class="keyword">values</span>(<span class="number">2</span>, <span class="string">'b'</span>, <span class="number">4</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> deadlock <span class="keyword">values</span>(<span class="number">3</span>, <span class="string">'x'</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> deadlock <span class="keyword">values</span>(<span class="number">4</span>, <span class="string">'d'</span>, <span class="number">2</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> deadlock <span class="keyword">values</span>(<span class="number">5</span>, <span class="string">'e'</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>两个事务分别“同时”执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- Transaction A                       | -- Transaction B</span><br><span class="line">DELETE FROM deadlock WHERE name &#x3D; &#39;x&#39;; | DELETE FROM deadlock WHERE reg &gt;&#x3D; 2;</span><br></pre></td></tr></table></figure><p>其中一个事务可能会检测到死锁而出错。Monitor 日志里找到 “LATEST DETECTEDDEADLOCK” 可以看到记录的死锁原因（这个示例复现出的问题与上图不直接一致）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">------------------------</span><br><span class="line">LATEST DETECTED DEADLOCK</span><br><span class="line">------------------------</span><br><span class="line">2020-12-13 15:59:40 0x700007a56000</span><br><span class="line">*** (1) TRANSACTION:</span><br><span class="line">TRANSACTION 930064, ACTIVE 0 sec starting index read</span><br><span class="line">mysql tables in use 1, locked 1</span><br><span class="line">LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s)</span><br><span class="line">MySQL thread id 1309, OS thread handle 123145430310912, query id 9616 localhost root updating</span><br><span class="line">DELETE FROM deadlock WHERE name &#x3D; &#39;x&#39;</span><br><span class="line">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line">RECORD LOCKS space id 1825 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;deadlock&#96; trx id 930064 lock_mode X locks rec but not gap waiting</span><br><span class="line">Record lock, heap no 2 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">*** (2) TRANSACTION:</span><br><span class="line">TRANSACTION 930063, ACTIVE 0 sec updating or deleting</span><br><span class="line">mysql tables in use 1, locked 1</span><br><span class="line">3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1</span><br><span class="line">MySQL thread id 1308, OS thread handle 123145430589440, query id 9615 localhost root updating</span><br><span class="line">DELETE FROM deadlock WHERE reg &gt;&#x3D; 2</span><br><span class="line">*** (2) HOLDS THE LOCK(S):</span><br><span class="line">RECORD LOCKS space id 1825 page no 3 n bits 72 index PRIMARY of table &#96;test&#96;.&#96;deadlock&#96; trx id 930063 lock_mode X</span><br><span class="line">Record lock, heap no 2 PHYSICAL RECORD: n_fields 5; compact format; info bits 32</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line">RECORD LOCKS space id 1825 page no 4 n bits 72 index deadlock_name of table &#96;test&#96;.&#96;deadlock&#96; trx id 930063 lock_mode X locks rec but not gap waiting</span><br><span class="line">Record lock, heap no 2 PHYSICAL RECORD: n_fields 2; compact format; info bits 0</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line">*** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></table></figure><p>我们看到：</p><ol><li>第一个事务在等待 PRIMARY 索引上 heap_no = 2 的记录的 Record Lock</li><li>第二个事务已经取得 PRIMARY 索引上 heap_no = 2 的 Next Key Lock</li><li>同时第二个事务在等待 deadlock_name 索引上 heap_no = 2 的 Record Lock</li><li>MySQL 选择回滚第一个事务</li></ol><p>更新操作如 UPDATE/DELETE 加锁的顺序为：<code>查询索引 &gt; 主键索引 &gt; 其它二级索引</code>。如上例中，第二个事务已经锁住了主键索引，准备锁住另一个二级索引 <code>deadlock_name</code>，而第一个已经锁住了 <code>deadlock_name</code>，准备锁主键索引，造成死锁。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://www.jianshu.com/p/13f5777966dd" target="_blank" rel="noopener">mysql 索引加锁分析</a> 本文内容的主要参考对象，详细分析了各种情形下的加锁原理</li><li><a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">Locks Set by Different SQL Statements inInnoDB</a> 官方文档，介绍了不同语句的加锁方式</li><li><a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-locking.html" target="_blank" rel="noopener">InnoDBLocking</a> 官方文档，介绍了 InnoDB 的不同类型的锁</li><li><a href="https://www.slideshare.net/valeriikravchuk1/understanding-innodb-locks-and-deadlocks" target="_blank" rel="noopener">Understanding innodb locks anddeadlocks</a>PPT 解释了 InnoDB 内部的一些数据结构</li><li><a href="https://www.cnblogs.com/xiaoboluo768/p/5171425.html" target="_blank" rel="noopener">mysql之show engine innodb status解读</a> 详细介绍了 SHOWENGINE INNODB STATUS 输出的内容，也是在这篇文章里认识到人肉看 PHYSICALRECORD 的内容不太可能</li><li><a href="https://github.com/jeremycole/innodb_ruby" target="_blank" rel="noopener">innodb_ruby</a> InnoDB 文件探查工具，学习 InnoDB 利器，会用它来确认 heap_no 对应的记录</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MySQL &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方文档
&lt;/a&gt;给出了不同类型语句的加锁情形，但我觉得
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="isolation level" scheme="https://lotabout.me/tags/isolation-level/"/>
    
      <category term="MySQL" scheme="https://lotabout.me/tags/MySQL/"/>
    
      <category term="lock" scheme="https://lotabout.me/tags/lock/"/>
    
  </entry>
  
  <entry>
    <title>Optional 不管用的日子</title>
    <link href="https://lotabout.me/2020/When-Monad-Fails/"/>
    <id>https://lotabout.me/2020/When-Monad-Fails/</id>
    <published>2020-12-12T18:13:05.000Z</published>
    <updated>2021-05-22T10:33:50.877Z</updated>
    
    <content type="html"><![CDATA[<p>Java <code>Optional</code> 类代表的是 <a href="https://en.wikipedia.org/wiki/Monad_(functional_programming)" target="_blank" rel="noopener">Monad/单子</a> 的概念，在使用时通常会写成链式调用的代码，但实际使用时会发现：有很多场景无法用链式调用表示。</p><h2 id="optional-的蜜月期"><a class="header-anchor" href="#optional-的蜜月期"></a>Optional 的蜜月期</h2><p><code>Optional</code> 提提供了 <code>map</code>, <code>filter</code>, <code>flatMap</code> 等方法来链式调用，例如下面代码：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Report <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  User user = findUserByUserId(userId);</span><br><span class="line">  <span class="keyword">if</span> (user == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  String content = findReportContentById(user.getReportId());</span><br><span class="line">  <span class="keyword">return</span> JsonUtil.fromJson(content, Report<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 <code>findUserByUserId</code> 返回 <code>Optional&lt;User&gt;</code>，其它方法也都返回 <code>Optional</code>，则可以用链式调用表示，代码会简洁很多：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Optional&lt;Report&gt; <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> findUserByUserId(userId)      <span class="comment">// ①</span></span><br><span class="line">      .map(User::getReportId)          <span class="comment">// ②</span></span><br><span class="line">      .flatMap(findReportContentById); <span class="comment">// ③</span></span><br><span class="line">      .flatMap(content -&gt; JsonUtil::fromJson(content, Report<span class="class">.<span class="keyword">class</span>))</span>; <span class="comment">// ④</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>能这么做的原因是 <code>map</code> 和 <code>flatMap</code> 隐式地处理了方法返回 <code>Optional::empty</code> 的情况，例如当 ① 返回为 <code>empty</code> 时，<code>map</code> 会短路，跳过 ② 的执行，同理跳过 ③、④的执行。因此 ②、③、④ 的方法调用中就不需要关心 <code>user</code> 返回为空的情形，使代码变得简单。</p><p>P.S. 下文会把 <code>map</code> 或 <code>flatMap</code> 里的逻辑称为“模块”。</p><h2 id="链式调用的-短视"><a class="header-anchor" href="#链式调用的-短视"></a>链式调用的“短视”</h2><p>链式调用有一个局限：一个模块中只能看到模块的输入，无法感知其它模块的信息。这点限制在写业务代码时容易成为掣肘，一个常见的需求是：输出日志时需要全局信息，例如：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Report <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  User user = findUserByUserId(userId);</span><br><span class="line">  <span class="keyword">if</span> (user == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> reportId = user.getReportId();</span><br><span class="line">  String content = findReportContentById(reportId);</span><br><span class="line">  Report report = JsonUtil.fromJson(content, Report<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">  <span class="keyword">if</span> (report == <span class="keyword">null</span>) &#123;</span><br><span class="line">    log.error(<span class="string">"Failed to deserialize report, userId: &#123;&#125;, reportId: &#123;&#125;"</span>, userId, reportId);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> report;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的 <code>log</code> 需要 <code>userId</code> 和 <code>reportId</code>。<code>userId</code> 是方法的入参，方便获得，但<code>reportId</code> 是中间输出结果，用链式调用就很难写。</p><p>其中一个方法是将链式分段，这样能引用其它模块的输出：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Optional&lt;Report&gt; <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  Optional&lt;Long&gt; oReportId = findUserByUserId(userId)</span><br><span class="line">      .map(User::getReportId);</span><br><span class="line"></span><br><span class="line">  Optional&lt;Report&gt; oReport = oReportId</span><br><span class="line">      .flatMap(findReportContentById);</span><br><span class="line">      .flatMap(content -&gt; JsonUtil::fromJson(content, Report<span class="class">.<span class="keyword">class</span>))</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!oReport.isPresent()) &#123;</span><br><span class="line">    log.error(<span class="string">"Failed to deserialize report, userId: &#123;&#125;, reportId: &#123;&#125;"</span>,</span><br><span class="line">        userId, oReportId.get());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> oReport;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以用线程安全的变量存储。还可以用包装类（如 Guava 里的 <code>Pair</code>）将结果一路传到底，但这样中间的所有模块都需要处理这个额外的状态。</p><p>但不管是哪一类，都让代码显得不再“简洁”。</p><h2 id="monad-生态隔离"><a class="header-anchor" href="#monad-生态隔离"></a>Monad 生态隔离</h2><p>一个 Monad 代表一个生态，不同生态间是不能“平滑”互通的，需要显式转换。“Monad”这个概念对于不了解Category Theory 的同学会很陌生，这里也不想强行理论化。</p><p>举个例子，Java 中的 <code>Optional</code> 和 <code>Stream</code> 都提供了 <code>empty</code>, <code>map</code>, <code>flatMap</code>等方法，概念上它们就是 Monad。对于 <code>Optional</code> 或 <code>Stream</code> 可以方便地链式调用，但是一条链里没有办法同时处理 <code>Optional</code> 和 <code>Stream</code>。</p><p>例如对于下面的代码，没有用 <code>Optional</code> 和 <code>Stream</code>：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Report <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  User user = findUserByUserId(userId);</span><br><span class="line">  <span class="keyword">if</span> (user == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;Report&gt; reports = findReports(user.getCategory());</span><br><span class="line">  <span class="keyword">if</span> (reports.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  reports.sort(Comparator.comparing(Report::getCreateTime).reversed());</span><br><span class="line">  <span class="keyword">return</span> reports.get(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而如果用 <code>Optional</code> 和 <code>Stream</code> 可以这样实现：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Optional&lt;Report&gt; <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> findUserByUserId(userId)</span><br><span class="line">    .flatMap(user -&gt; findReports(user.getCategory)</span><br><span class="line">         .stream()      <span class="comment">// ①</span></span><br><span class="line">         .sorted(Comparator.comparing(Report::getCreateTime).reversed())</span><br><span class="line">         .findFirst()); <span class="comment">// ②</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这份代码看着还是比不用链式调用简洁。但要注意两点：</p><ol><li>① 处创建了 <code>Stream</code> 并且 Stream 的链式调用实际上都在 Optional 的同一个<code>flatMap</code> 调用中</li><li><code>Stream</code> 能与 <code>Optional</code> 互通，多亏了 ② 中的 <code>findFirst</code> 方法创建了一个<code>Optional</code> 对象</li></ol><p>上面代码中的 <code>Stream</code> 生态，主动知晓了 <code>Optional</code> 生态，并提供了适配的方法（<code>findFirst</code> 返回了 <code>Optional</code>）。生态互通依赖主动适配，意味着自建的 Monad 实际上不容易融合到已有的生态中。</p><p>而理想的链式调用应该是“单层”：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Optional&lt;Report&gt; <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> findUserByUserId(userId)</span><br><span class="line">    .getStream(user -&gt; findReports(user.getCategory).stream())  <span class="comment">// getStream 方法实际不存在</span></span><br><span class="line">    .sorted(Comparator.comparing(Report::getCreateTime).reversed())</span><br><span class="line">    .findFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分支条件无法化简"><a class="header-anchor" href="#分支条件无法化简"></a>分支条件无法化简</h2><p>如果逻辑里出现分支条件，那么即使提供链式的机制，分支也不可避免要存在于链式的模块里。例如：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Report <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  User user = findUserByUserId(userId);</span><br><span class="line">  <span class="keyword">if</span> (user == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> user.getAge() &gt; <span class="number">50</span></span><br><span class="line">        ? getReportFromOldSystem(user.getReportId())</span><br><span class="line">        : getReportFromNewSystem(user.getReportId())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码要如何“化简”成链式调用？也许只能化简 <code>user == null</code> 的部分了：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Optional&lt;Report&gt; <span class="title">getUsersLatestReport</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> findUserByUserId(userId)</span><br><span class="line">      .flatMap(user -&gt; user.getAge() &gt; <span class="number">50</span></span><br><span class="line">        ? getReportFromOldSystem(user.getReportId())</span><br><span class="line">        : getReportFromNewSystem(user.getReportId())</span><br><span class="line">      );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而当分支条件多的时候，或者说链式调用里模块的逻辑复杂的时候，代码也不再“简洁”了。</p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>Java 中的 <code>Optional</code> 不仅仅是 <code>null</code> 的另一个实现，它与 <code>Stream</code> 一样在概念上是 <code>Monad</code>，<code>Monad</code> 最直观的作用是允许我们通过 <code>map</code>, <code>flatMap</code> 等方法做链式调用，但在一些特定的情况下却并不好用，例如：</p><ul><li>某个模块依赖多个输入，而某些输入依赖其它模块的输出时</li><li>当你需要创建自己的 Monad，处理多个 Monad 的生态互通时</li><li>模块逻辑中含有分支条件时</li></ul><p>许多“理想”的模式在实践中会有不少问题。例如笔者尝试用 WebFlux 写反应式编程，发现很长的链式调用可读性会降低，因为很难追踪中间操作的含义；遇到需要多输入，需要中间变量的操作时，很难组装成链式调用；在写 Rust 时发现用 <code>Result</code> 处理错误，不同的错误类型间的转换非常繁琐……</p><p>在了解了 <a href="https://lotabout.me/2018/Thoughts-on-Expression-Problem/">ExpressionProblem</a> 受限于代码的编写维度后，就在想有些困难是不是受限于一些无法解决的客观事实。例如 Rust 里的错误处理总是让人诟病，应该是由于 Monad 生态隔离，导致需要很多手工的适配。而用Monad 又是为了使用它的链式调用来让代码变得“简洁”。我们会觉得链式调用“简洁”，是不是因为它是线性的代码？而人比较难理解分支的逻辑。而这是不是又受限于人的短期记忆（比如只能记住7样事物）？毕竟很长的链式调用其实也很难理解。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Java &lt;code&gt;Optional&lt;/code&gt; 类代表的是 &lt;a href=&quot;https://en.wikipedia.org/wiki/Monad_(functional_programming)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mo
      
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="java" scheme="https://lotabout.me/tags/java/"/>
    
      <category term="Optional" scheme="https://lotabout.me/tags/Optional/"/>
    
      <category term="Monad" scheme="https://lotabout.me/tags/Monad/"/>
    
  </entry>
  
  <entry>
    <title>Ansible 入门介绍</title>
    <link href="https://lotabout.me/2020/Ansible-Introduction/"/>
    <id>https://lotabout.me/2020/Ansible-Introduction/</id>
    <published>2020-10-09T09:54:53.000Z</published>
    <updated>2021-05-22T10:33:50.821Z</updated>
    
    <content type="html"><![CDATA[<p>Ansible 是一个 IT 自动化工具，主要用来做自动化部署、自动化配置等。也许是因为它发展太快，官方的文档经常看得云里雾里，不易上手，本文结合博主自身的经验，介绍一些入门的概念。由于不是专业 DevOps ，水平有限，点到为止。</p><h2 id="什么是-ansible"><a class="header-anchor" href="#什么是-ansible"></a>什么是 Ansible</h2><p>如果管理一台机器，最快的操作方式是 ssh 到这台机器上直接执行命令。</p><p>如果管理几台机器，笨办法是一台台操作，不过这样容易出错。命令行高手可能会用tmux的 <code>synchronize-panes</code> 或 SecureCrt 的 “Send chat to all tabs” 等功能来多屏操作。</p><p>如果管理的机器有十几台或几十台，或者部署、更新操作很频繁，最好的方式就是写成脚本，这样方便重用，同时减少出错的可能性。</p><p>当部署的操作比较复杂时，如需要部署多个模块，每个模块的配置相互关联，部署有许多步骤时，裸写脚本会让脚本变得十分复杂。这种情形下， Ansible 提供的一些功能能方便我们管理、定制部署的内容。</p><h2 id="ansible-的基本概念"><a class="header-anchor" href="#ansible-的基本概念"></a>Ansible 的基本概念</h2><h3 id="nodes"><a class="header-anchor" href="#nodes"></a>Nodes</h3><p>Ansible 允许我们在一台机器上控制多台机器，如下图：</p><img src="/2020/Ansible-Introduction/Ansible-Nodes.svg" class="" title="Control Node and Managed Node"><p>执行 Ansible 命令的机器称作控制节点（Control Node），这台机器上需要安装ansible，其它机器称作受管节点（Managed Node），不需要安装 ansible。</p><p>Ansible 要求控制节点到受管节点之间要配置 ssh 免密登录，侧面说明 ansible 在执行时就是 ssh 到受管节点上再执行相应的命令。也因此在执行命令时需要受管节点本身安装好相应的命令（如解压 zip 包需要安装 unzip 命令）。</p><h3 id="inventory"><a class="header-anchor" href="#inventory"></a>Inventory</h3><p>Inventory 可以翻译成“清单”，Ansible 要管理许多机器，那这些机器的 IP 在哪里存储、获取呢？Ansible 定义了 <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#inventory-basics-formats-hosts-and-groups" target="_blank" rel="noopener">inventory 格式</a>，我们只需要把要管理的机器按格式保存成文件即可（一般会命名为 <code>hosts</code>）。如 ini的格式如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mail.example.com</span><br><span class="line"></span><br><span class="line">[webservers]</span><br><span class="line">foo.example.com</span><br><span class="line">bar.example.com</span><br><span class="line"></span><br><span class="line">[dbservers]</span><br><span class="line">one.example.com</span><br><span class="line">two.example.com</span><br><span class="line">three.example.com</span><br></pre></td></tr></table></figure><p>其中的 <code>[webservers]</code> 是“组”，之后在需要填写机器的地方写的都是“组名”（当然还有其它写法）。</p><p>如果你管理的机器很多，ansible 还支持这样一些语法，来代表范围（具体的格式可以查阅文档）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[webservers]</span><br><span class="line">www[01:50].example.com</span><br><span class="line"></span><br><span class="line">[databases]</span><br><span class="line">db-[a:f].example.com</span><br></pre></td></tr></table></figure><h3 id="module"><a class="header-anchor" href="#module"></a>Module</h3><p>我们说过，ansible 的作用相当于 ssh 到目标机器上执行脚本。有些任务用脚本写起来会比较麻烦，Ansible 就把这些任务抽象成一个方便配置的模块，就是 module，它是Ansible 执行的最小代码单元。</p><p>例如部署时我们常需要把安装包 scp 到目标机器，再解压。压缩格式不同还需要调用不同的解压命令，而 ansible 把这个功能抽象成 <code>unarchive</code> module，只需要简单配置就可以实现功能。例如将控制节点上的 JDK 解压到受管节点中，只需要指定路径即可：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">and</span> <span class="string">unzip</span> <span class="string">jdk</span></span><br><span class="line">  <span class="attr">unarchive:</span> <span class="string">src=&#123;&#123;jdk_local_file_path&#125;&#125;</span> <span class="string">dest=&#123;&#123;jdk_install_path&#125;&#125;</span></span><br></pre></td></tr></table></figure><h3 id="task-tag"><a class="header-anchor" href="#task-tag"></a>Task &amp; Tag</h3><p>Task 即任务，如果说 module 对应于脚本中的一个命令，task 就是命令加参数，用来实现一个具体的操作。</p><p>例如上面的解压 JDK 示例其实就是一个 task。其中的 <code>unarchive</code> 是 module，而<code>src</code>, <code>dest</code> 是具体的参数，加上 <code>name</code> 这个额外的标记信息，整体描述了一个具体的操作。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">and</span> <span class="string">unzip</span> <span class="string">jdk</span></span><br><span class="line">  <span class="attr">unarchive:</span> <span class="string">src=&#123;&#123;jdk_local_file_path&#125;&#125;</span> <span class="string">dest=&#123;&#123;jdk_install_path&#125;&#125;</span></span><br><span class="line">  <span class="attr">tag:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">install</span></span><br></pre></td></tr></table></figure><p>Task 描述了具体的操作，那么如何控制操作的执行时机呢？例如解压 JDK 的操作只希望在安装的时候执行，而后续更新服务时不希望执行。</p><p>Ansible 中提供的一种机制是 Tag（标签）。在后续执行时，可以指定一个或多个标签，只有标签匹配的任务才会被执行。这个机制使得 ansible 比自制脚本更加灵活。</p><h3 id="playbook"><a class="header-anchor" href="#playbook"></a>Playbook</h3><p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html" target="_blank" rel="noopener">Playbook</a>翻译为“剧本”，如果把 task 看作一个个动作，剧本的作用就是串联这些动作，来实现全局的目的。一个剧本可以包含多场“戏”（Play），每场戏至少需要定义两个要素：</p><ul><li>目标机器，通过 <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html#intro-patterns" target="_blank" rel="noopener">pattern</a> 语法指定</li><li>至少一个 task</li></ul><p>下例的第一场戏中，ansible 在 webservers 上执行任务，第二场戏中在databases上执行任务：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">update</span> <span class="string">web</span> <span class="string">servers</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ensure</span> <span class="string">apache</span> <span class="string">is</span> <span class="string">at</span> <span class="string">the</span> <span class="string">latest</span> <span class="string">version</span></span><br><span class="line">    <span class="attr">yum:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">      <span class="attr">state:</span> <span class="string">latest</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">write</span> <span class="string">the</span> <span class="string">apache</span> <span class="string">config</span> <span class="string">file</span></span><br><span class="line">    <span class="attr">template:</span></span><br><span class="line">      <span class="attr">src:</span> <span class="string">/srv/httpd.j2</span></span><br><span class="line">      <span class="attr">dest:</span> <span class="string">/etc/httpd.conf</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">update</span> <span class="string">db</span> <span class="string">servers</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">databases</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ensure</span> <span class="string">postgresql</span> <span class="string">is</span> <span class="string">at</span> <span class="string">the</span> <span class="string">latest</span> <span class="string">version</span></span><br><span class="line">    <span class="attr">yum:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">postgresql</span></span><br><span class="line">      <span class="attr">state:</span> <span class="string">latest</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ensure</span> <span class="string">that</span> <span class="string">postgresql</span> <span class="string">is</span> <span class="string">started</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">postgresql</span></span><br><span class="line">      <span class="attr">state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure><p>默认情况下，ansible 会按剧本里的任务一项项顺序执行，每项任务都会在指定的所有目标机器上执行。如果有一台机器上执行失败，则这台机器将不再参与该剧本后续任务的执行。当然，执行的策略也是可以改的，参考：<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_strategies.html#playbooks-strategies" target="_blank" rel="noopener">strategies</a>。</p><h3 id="role"><a class="header-anchor" href="#role"></a>Role</h3><p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html" target="_blank" rel="noopener">Role</a>翻译成“角色”，它是 ansible 的一个组织上的概念。有时候我们可能会有许多剧本，而不同剧本可能只是组织的顺序不同，任务本身是一样的，于是我们把它们组织成一个个“角色”，一个剧本可以直接邀请角色，一个角色可以出演多个剧本，组织更清晰，也方便复用。</p><p>实际上，ansible 中要完成一项任务，还会使用到许多概念，比如需要读取设置变量；定义文件模板；自定义 module 等等。于是 ansible 要求我们按指定的目录格式来组织：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># playbooks</span><br><span class="line">site.yml</span><br><span class="line">webservers.yml</span><br><span class="line">fooservers.yml</span><br><span class="line">roles&#x2F;</span><br><span class="line">    common&#x2F;</span><br><span class="line">        tasks&#x2F;     # main.yml 执行的 task</span><br><span class="line">        handlers&#x2F;  # main.yml handlers，可在本角色或角色外使用</span><br><span class="line">        library&#x2F;   # my_module.yml 本角色中可使用的自定义 module</span><br><span class="line">        files&#x2F;     # main.yml 部署的文件</span><br><span class="line">        templates&#x2F; # main.yml 部署的模板</span><br><span class="line">        defaults&#x2F;  # main.yml 使用有默认值的变量，可以被覆盖，最低优先级</span><br><span class="line">        vars&#x2F;      # main.yml 的其它变量</span><br><span class="line">        meta&#x2F;      # main.yml meta 信息，如角色的依赖关系</span><br><span class="line">    webservers&#x2F;</span><br><span class="line">        tasks&#x2F;</span><br><span class="line">        defaults&#x2F;</span><br><span class="line">        meta&#x2F;</span><br></pre></td></tr></table></figure><ul><li>每个角色都要放在 <code>roles</code> 目录下，且单独成目录，如 <code>roles/common/</code></li><li>每个“功能”独自成目录（如 <code>tasks/</code>），且默认生效的配置为目录下的 <code>main.yml</code>文件</li></ul><p>定义了 role 后就可以在 play 中使用：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">roles:</span>             <span class="comment"># 通过 roles 指定引入的角色</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">common</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">webservers</span></span><br></pre></td></tr></table></figure><p>还有复杂的用法：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">common</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">foo_app_instance</span></span><br><span class="line">      <span class="attr">vars:</span>                   <span class="comment"># 覆盖变量</span></span><br><span class="line">        <span class="attr">dir:</span> <span class="string">'/opt/a'</span></span><br><span class="line">        <span class="attr">app_port:</span> <span class="number">5000</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">typeA</span>             <span class="comment"># 给 role 里的所有 task 添加 tag</span></span><br></pre></td></tr></table></figure><h3 id="其它"><a class="header-anchor" href="#其它"></a>其它</h3><p>这里只介绍一些组织上的概念，在实际编写 ansible 时，还需要许多变量上的操作，如<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html" target="_blank" rel="noopener">条件判断</a>、<a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html" target="_blank" rel="noopener">循环</a>等，以及一些<a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/" target="_blank" rel="noopener">内置的module</a>，麻烦读者在使用时查阅相关文档。</p><h2 id="示例：部署-spring-boot-服务"><a class="header-anchor" href="#示例：部署-spring-boot-服务"></a>示例：部署 Spring Boot 服务</h2><p>下面我们写一个简单的 ansible 工程，用于安装、部署、启停 spring boot 任务。目的是对 ansible 的工程结构及脚本有大概的认识。这里会贴出所有的代码，比较长，不想了解细节可以先跳过。</p><figure class="highlight plain"><figcaption><span>目录结构</span></figcaption><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── hosts                   # inventory</span><br><span class="line">├── roles</span><br><span class="line">│   ├── jdk</span><br><span class="line">│   │   └── tasks</span><br><span class="line">│   │       └── main.yml    # 部署步骤</span><br><span class="line">│   └── webapp</span><br><span class="line">│       ├── files</span><br><span class="line">│       │   └── webapp.jar  # 服务 jar 包</span><br><span class="line">│       ├── tasks</span><br><span class="line">│       │   └── main.yml    # 部署步骤</span><br><span class="line">│       ├── templates</span><br><span class="line">│       │   └── application.properties.j2  # spring boot 配置文件模板</span><br><span class="line">│       └── vars</span><br><span class="line">│           └── main.yml    # 部署参数</span><br><span class="line">├── vars.yml                # 全局参数</span><br><span class="line">└── webapp.yml              # playbook</span><br></pre></td></tr></table></figure><p>在编写 ansible 脚本时，通常会这么做：</p><ol><li>编写 <code>hosts</code> 和 <code>vars.yaml</code>，存储机器信息和变量信息。环境变化时，一般只修改这两个文件即可</li><li>将目标分解成多个角色，如例子中将 jdk 和 webapp 分开</li><li>为每个角色编写脚本，一般在 task 只会增加 tag 来分组，有些 task 可以共用</li><li>编写 playbook，包含一到多个角色，串连完成目标</li><li>将经常执行的命令写成脚本，这点在样例中没有体现</li></ol><p>当然 ansible 只提供机制，部署的脚本不只一种，这里描述的是博主的习惯。具体的文件内容如下：</p><figure class="highlight"><figcaption><span>hosts</span><a href="/downloads/code/ansible-playground/hosts">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">[webservers]</span></span><br><span class="line">192.168.1.10</span><br></pre></td></tr></table></figure><figure class="highlight yml"><figcaption><span>vars.yml</span><a href="/downloads/code/ansible-playground/vars.yml">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">webapp_port:</span> <span class="number">9191</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><figcaption><span>webapp.yml</span><a href="/downloads/code/ansible-playground/webapp.yml">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">webservers</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">jdk</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">webapp</span></span><br><span class="line">  <span class="attr">vars_files:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">vars.yml</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><figcaption><span>roles/jdk/tasks/main.yml</span><a href="/downloads/code/ansible-playground/roles/jdk/tasks/main.yml">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">"Install JDK 1.8"</span></span><br><span class="line">  <span class="attr">apt:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">openjdk-8-jdk</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">yes</span> <span class="comment"># apt 需要 sudo 权限</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><figcaption><span>roles/webapp/tasks/main.yml</span><a href="/downloads/code/ansible-playground/roles/webapp/tasks/main.yml">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">web</span> <span class="string">app</span></span><br><span class="line">  <span class="attr">block:</span> <span class="comment"># block 可以组合多个 task</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ensure</span> <span class="string">path</span> <span class="string">exists</span></span><br><span class="line">      <span class="attr">file:</span> <span class="string">dest={{install_path}}</span> <span class="string">mode=0755</span> <span class="string">state=directory</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">jar</span> <span class="string">file</span></span><br><span class="line">      <span class="attr">copy:</span> <span class="string">src=webapp.jar</span> <span class="string">dest={{install_path}}</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">generate</span> <span class="string">application</span> <span class="string">properties</span></span><br><span class="line">      <span class="attr">template:</span> <span class="string">src=application.properties.j2</span> <span class="string">dest={{install_path}}/application.properties</span> <span class="string">force=true</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install</span> <span class="comment"># 注意整个脚本的 task 打了几组不同的 tag 用于分组</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">check</span> <span class="string">if</span> <span class="string">webapp's</span> <span class="string">port</span> <span class="string">had</span> <span class="string">already</span> <span class="string">stopped</span></span><br><span class="line">  <span class="attr">wait_for:</span> <span class="comment"># wait for 等待端口不可访问</span></span><br><span class="line">    <span class="attr">port:</span> <span class="string">"<span class="template-variable">{{server_port}}</span>"</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">stopped</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">"<span class="template-variable">{{check_stop_timeout | default(3)}}</span>"</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">"Port <span class="template-variable">{{server_port}}</span> is accessible, <span class="template-variable">{{role_name}}</span> not stopped"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">start</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">check-stop</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> <span class="string">webapp</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="comment"># 执行 start</span></span><br><span class="line">    <span class="attr">chdir:</span> <span class="string">"<span class="template-variable">{{install_path}}</span>"</span></span><br><span class="line">    <span class="attr">cmd:</span> <span class="string">"nohup java -jar webapp.jar &amp;&gt; nohup.out &amp;"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">start</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">check</span> <span class="string">if</span> <span class="string">port</span> <span class="string">is</span> <span class="string">accessible</span></span><br><span class="line">  <span class="attr">wait_for:</span> <span class="comment"># 等待，直到端口可访问</span></span><br><span class="line">    <span class="attr">port:</span> <span class="string">"<span class="template-variable">{{server_port}}</span>"</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">"<span class="template-variable">{{check_start_timeout | default(10000)}}</span>"</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">"Port <span class="template-variable">{{server_port}}</span> is not accessible, <span class="template-variable">{{role_name}}</span> not started"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">start</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">check-start</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">check</span> <span class="string">if</span> <span class="string">port</span> <span class="string">is</span> <span class="string">accessible</span></span><br><span class="line">  <span class="attr">wait_for:</span> <span class="comment"># 停止前确保端口可访问</span></span><br><span class="line">    <span class="attr">port:</span> <span class="string">"<span class="template-variable">{{server_port}}</span>"</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">"<span class="template-variable">{{check_start_timeout | default(3)}}</span>"</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">"Port <span class="template-variable">{{server_port}}</span> is not accessible, <span class="template-variable">{{role_name}}</span> not started"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">stop</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stop</span> <span class="string">webapp</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="comment"># kill 进程</span></span><br><span class="line">    <span class="attr">chdir:</span> <span class="string">"<span class="template-variable">{{install_path}}</span>"</span></span><br><span class="line">    <span class="attr">cmd:</span> <span class="string">"ps aux|grep webapp.jar| grep -v grep| awk '{print $2}'|xargs kill"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">stop</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">check</span> <span class="string">if</span> <span class="string">webapp's</span> <span class="string">port</span> <span class="string">had</span> <span class="string">already</span> <span class="string">stopped</span></span><br><span class="line">  <span class="attr">wait_for:</span> <span class="comment"># kill 后确认端口不可访问</span></span><br><span class="line">    <span class="attr">port:</span> <span class="string">"<span class="template-variable">{{server_port}}</span>"</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">stopped</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="string">"<span class="template-variable">{{check_stop_timeout | default(300)}}</span>"</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">"Port <span class="template-variable">{{server_port}}</span> is accessible, <span class="template-variable">{{role_name}}</span> not stopped"</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">stop</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">check-stop</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><figcaption><span>roles/webapp/templates/application.properties.j2</span><a href="/downloads/code/ansible-playground/roles/webapp/templates/application.properties.j2">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line">server.port&#x3D;{{server_port}}</span><br></pre></td></tr></table></figure><figure class="highlight yml"><figcaption><span>roles/webapp/vars/main.yml</span><a href="/downloads/code/ansible-playground/roles/webapp/vars/main.yml">view raw</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">server_port:</span> <span class="string">"<span class="template-variable">{{webapp_port}}</span>"</span></span><br><span class="line"><span class="attr">install_path:</span> <span class="string">/home/jinzhouz/tmp/ansible</span></span><br></pre></td></tr></table></figure><p>有了这些部署脚本后，可以通过如下命令来安装、部署：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装, -K 在执行时会提示输入 sudo 密码，安装 JDK 时使用</span></span><br><span class="line"><span class="comment"># 由于 playbook 中包含了 jdk 与 webapp，会先后执行 jdk 与 webapp 带 install tag 的任务</span></span><br><span class="line">ansible-playbook webapp.yml -i hosts --tags install -K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动，jdk 中没有启动步骤，只会执行 webapp 中带 start tag 的任务</span></span><br><span class="line">ansible-playbook webapp.yml -i hosts --tags start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">ansible-playbook webapp.yml -i hosts --tags stop</span><br></pre></td></tr></table></figure><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>当你想写脚本部署服务时，可以考虑使用 Ansible 来替代。对于初次接触的同学，需要先了解一些 ansible 的组织概念，文中介绍了主要的一些概念：</p><ul><li>Node：节点/机器，包括控制节点(Control Node)和受管节点(Managed Node)，通过SSH 免密通信</li><li>Inventory：配置文件，记录节点信息</li><li>Module：最小的代码单元，是 ansible 对常用命令做的抽象</li><li>Task：单个操作，可以认为是 Module 加上具体的参数</li><li>Tag：对 Task 做标记/分组，在执行时可以指定一个或多个 tag</li><li>Playbook：剧本，顺序组织多个 task，来完成具体目标，可以包含多场“戏”</li><li>Role：对 Task 的结构化组织，需要遵守特定的目录结构</li></ul><p>了解这些概念后，我们就知道 Ansible 脚本“从何写起”了。最后我们给了一个具体的示例，来安装，部署一个 Spring Boot 的 Web 服务。</p><p>Ansible 的功能远不止这些，本文只是抛砖引玉，更多的功能可以查阅官方文档。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Ansible 是一个 IT 自动化工具，主要用来做自动化部署、自动化配置等。也许是因为它发展太快，官方的文档经常看得云里雾里，不易上手，本文结合博主自身的经验，介绍一些入门的概念。由于不是专业 DevOps ，水平有限，点到为止。&lt;/p&gt;
&lt;h2 id=&quot;什么是-ansi
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="Ansible" scheme="https://lotabout.me/tags/Ansible/"/>
    
      <category term="DepOps" scheme="https://lotabout.me/tags/DepOps/"/>
    
  </entry>
  
  <entry>
    <title>Deprecated. Java 并发（零）- 原子性</title>
    <link href="https://lotabout.me/2020/Java-Concurrency-0-Shared-Mutable-State/"/>
    <id>https://lotabout.me/2020/Java-Concurrency-0-Shared-Mutable-State/</id>
    <published>2020-06-14T10:24:05.000Z</published>
    <updated>2021-05-22T10:33:50.829Z</updated>
    
    <content type="html"><![CDATA[<p>Deprecated. 这篇文章写得太仓促了，急切地想表达原子性的重要性，但内容组织得不太好，感觉文章比较乱，另一方面也不是一个好的系列开篇。不建议阅读。不过为了完整性还是保留，有兴趣的也可以看看写得有多烂哈。</p><p>并发问题主要有三个根源：原子性、可见性及有序性。作为 Java 并发系列的开篇，我们先来谈谈原子性，以及引发原子性问题的 Shared Mutable State(共享可变状态)。</p><h2 id="多个线程多十倍烦恼"><a class="header-anchor" href="#多个线程多十倍烦恼"></a>多个线程多十倍烦恼</h2><p>没有多线程就不存在并发问题<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，一旦有多个线程，情况就复杂了起来。下例中我们起了两个线程，分别尝试对全局变量 <code>counter</code> 做<code>++</code>操作，最终输出的结果会是多少呢？</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicTest</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    Thread th1 = <span class="keyword">new</span> Thread(AtomicTest::increase);</span><br><span class="line">    Thread th2 = <span class="keyword">new</span> Thread(AtomicTest::increase);</span><br><span class="line">    th1.start();</span><br><span class="line">    th2.start();</span><br><span class="line">    th1.join();</span><br><span class="line">    th2.join();</span><br><span class="line">    System.out.println(counter);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">      counter++;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们预期它永远输出 <code>20000</code>，但实际运行可能输出任意值。仅仅两个线程就让简单的<code>++</code> 操作不再正确。</p><p>当代码逻辑在多线程环境下运行结果不符合预期时，我们会称代码是不是“线程安全”的，有时候也说“有并发问题”。上例中的 <code>increase</code> 函数就不是“线程安全”，也可以说是“线程不安全的”。为了达到线程安全，我们需要原子操作。</p><h2 id="原子是不可分割的"><a class="header-anchor" href="#原子是不可分割的"></a>原子是不可分割的</h2><p>物理上“原子”是“不可分割的粒子”。编程中借用了这个概念，我们说一个操作是“原子的”代表这个操作在执行的过程中是不可分割的。一个操作在真正执行时可能需要执行底层的粒度更细的多个指令，如果这些指令的执行结果表现成一个整体，则认为操作是原子的。</p><p>例如上面的 <code>counter++</code> 操作是 Java 层面的，在执行时需要多个底层的 Java 字节码指令来完成，可以理解成下面的伪代码：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reg0 &#x3D; counter</span><br><span class="line">reg0 &#x3D; reg0 + 1</span><br><span class="line">counter &#x3D; reg0</span><br></pre></td></tr></table></figure><p>当有两个线程同时执行 <code>counter++</code> 时，JVM 可能会交替执行两个线程的指令<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>，实际执行的顺序可能会是（序号代表实际执行顺序）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">------- Thread 1 ------+------ Thread 2 --------</span><br><span class="line">1. reg0 &#x3D; counter (0)  |</span><br><span class="line">                       | 2. reg1 &#x3D; counter (0)</span><br><span class="line">3. reg0 &#x3D; reg0 + 1 (1) |</span><br><span class="line">                       | 4. reg1 &#x3D; reg1 + 1; (1)</span><br><span class="line">5. counter &#x3D; reg0 (1)  |</span><br><span class="line">                       | 6. counter &#x3D; reg1 (1)</span><br></pre></td></tr></table></figure><p>我们预期结果 <code>counter = 2</code>，但实际结果为 <code>counter = 1</code>，这是由于 <code>++</code> 操作的底层指令在执行时并不是一个整体，而是被另一个线程的指令“分割”了。换言之，<code>++</code> 操作不是“原子的”。</p><h2 id="原子能力最终依赖于底层"><a class="header-anchor" href="#原子能力最终依赖于底层"></a>原子能力最终依赖于底层</h2><p>实现原子性，意味着多个操作在执行时作为一个不可分割的整体。通常情况下，编程语言会提供一些原子的能力让我们实现原子性，将多个操作作为整体执行。Java 中常见的有<code>synchronized</code> 代表的锁、<code>ReentrantLock</code>代表的显示锁及 <code>AtomicInteger</code> 代表的原子类等。</p><p>而 Java 类库和 JVM 在实现这些机制时，需要依赖操作系统提供的原子能力。如<code>synchronized</code> 通常是利用操作系统的<code>mutex</code> 机制实现的，而操作系统的 <code>mutex</code> 实现又依赖 CPU 提供的原子指令，如 x86 提供的<a href="https://c9x.me/x86/html/file_module_x86_id_41.html" target="_blank" rel="noopener">CMPXCHG</a> 指令<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。</p><p>那么如果 CPU 不提供 CAS 的原子，JVM 有办法实现锁机制吗？答案是有，但依旧需要依赖其它的原子能力。例如早期的一些互斥锁(Mutual exclusion)算法<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>不依赖 CAS 指令，但要求对某个变量(寄存器/内存)的读写是原子的（通常情况下也是成立的）。</p><h2 id="万恶之源：shared-mutable-state"><a class="header-anchor" href="#万恶之源：shared-mutable-state"></a>万恶之源：Shared Mutable State</h2><p>前文提到了原子性是逻辑作为一个整体被执行，不被分割。那么什么情况下才可能出现被分割呢？要有多线程。多线程就一定破坏原子性吗？只有在它们 <strong>Shared MutableState</strong>(共享可变状态) 的时候。</p><p>这个概念非常重要，也是后续文章中会经常出现的概念。一共三个词：</p><ul><li>State(状态)，存储下来的都是“状态”，比如存在寄存器、内存的变量；存在文件、数据库的内容等。</li><li>Shared(共享)，有多个参与者，“同时”访问某个状态。如多个线程访问同一个变量，多个进程访问同一个数据库等。</li><li>Mutable(可变)，访问分为“读”和“写”，可变指的是写。至少有一个参与者想要写入新的状态。</li></ul><p>只有同时满足 “Shared” 和 “Mutable” 才造成并发问题。如果没有共享，也就不存在操作被分割的问题，原子性是成立的。如果“不可变”，则虽然实际操作可能被分割，但由于操作不改变状态，操作的结果最终“看起来”<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>也是原子性的。</p><p>在一些语言中，为了保证线程安全，会尝试打破其中一个。例如 Clojure 中所有的对象都是 Immutable（不可变）的；Java 中其实也鼓励多用不可变的对象；Rust 中则是尝试阻止 Share，一个对象只能两种情况：要么只有一个引用，它可以是可变的，要么可以有多个引用，但所有引用都是不可变的。</p><p>Java 中的“锁”也可以认为是阻止 Share 的机制。</p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>本章探讨了原子性，原子性指的是操作的执行作为一个整体不可分割，它（通常）是我们编码时预期的行为。在多线程的环境下，代码的执行通常不具备原子性，从而导致了并发问题。</p><p>编程语言层面提供了一些机制来让我们实现原子性，从而避免并发问题，达到线程安全。这些机制的实现又依赖更底层提供的原子能力。</p><p>而从编码的角度，并发问题的产生，是由于代码里有共享的可变的状态，为了达到线程安全，我们需要合理地使用原子机制（如锁）来阻止状态的共享。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li>“Java Concurrency in Practice”，中译《Java 并发编程实战》，学习并发一定要看的书</li><li><a href="https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/" target="_blank" rel="noopener">还在疑惑并发和并行？</a> 并发不等于并行，本文可以作为了解的开始，讨论也挺深</li><li><a href="https://nofluffjuststuff.com/magazine/2016/07/a_gentle_introduction_to_java_concurrency" target="_blank" rel="noopener">A Gentle Introduction to Java Concurrency</a> Java 并发的概念的细致讲解，包括原子性、可见性、顺序等</li><li><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/threads-sema.pdf" target="_blank" rel="noopener">Operating Systems: Three Easy Pieces</a> 第 31 章，操作系统关于信号量(Semaphore)的实现</li><li><a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/" target="_blank" rel="noopener">Atomic vs. Non-Atomic Operations</a> 讲解了一些 CPU 读写指令的原子性</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>并发的含义比较广，像协程这种一个线程处理多个任务的模式也会产生并发问题。并发的核心是<strong>逻辑</strong>时间上的重叠。Java 中我们简单地认为并发等于多线程。 <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p>虽然还没讲到，但这里不涉及“顺序性”问题。另外这里也可以隐含着并发问题本身不需要多线程参与，只要出现了交替执行（如协程）就有可能出问题。 <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p>CMPXCHG 指令代表的是 CAS(compare and swap) 机制，AtomicInteger和 ReentrantLock 等的实现依赖了 CAS 机制，后续章节会介绍。 <a href="#fnref3" class="footnote-backref">↩</a></p></li><li id="fn4" class="footnote-item"><p><a href="https://en.wikipedia.org/wiki/Mutual_exclusion#Software_solutions" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Mutual_exclusion#Software_solutions</a> <a href="#fnref4" class="footnote-backref">↩</a></p></li><li id="fn5" class="footnote-item"><p>其实我们并不关心是不是真的作为一个整体执行，我们关心的是执行的结果是不是等价于作为整体执行，换句话说，是不是符合原子性的预期。 <a href="#fnref5" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Deprecated. 这篇文章写得太仓促了，急切地想表达原子性的重要性，但内容组织得不太好，感觉文章比较乱，另一方面也不是一个好的系列开篇。不建议阅读。不过为了完整性还是保留，有兴趣的也可以看看写得有多烂哈。&lt;/p&gt;
&lt;p&gt;并发问题主要有三个根源：原子性、可见性及有序性。
      
    
    </summary>
    
      <category term="Project" scheme="https://lotabout.me/categories/Project/"/>
    
    
      <category term="Java Concurrency" scheme="https://lotabout.me/tags/Java-Concurrency/"/>
    
  </entry>
  
  <entry>
    <title>QQA: MySQL 竟然无法区分大小写？</title>
    <link href="https://lotabout.me/2020/QQA-MySQL-collate/"/>
    <id>https://lotabout.me/2020/QQA-MySQL-collate/</id>
    <published>2020-05-09T18:31:42.000Z</published>
    <updated>2021-05-22T10:33:50.853Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL 执行 <code>select 'a' = 'A';</code> 得到的结果竟然是真(<code>1</code>)？同学，<code>collation</code> 了解一下。</p><p>究其原因，是因为默认的 Collation 设置为 <code>utf8mb4_general_ci</code>（不同机器/字符编码下不同），任何的字符串比较都会忽略大小写。解法：</p><ul><li>可以在建库或表时指定其它的 collation，如 <code>utf8mb4_bin</code>，不推荐</li><li>也可以在 SQL 语句里指定 collation，如：<ul><li><code>select 'a' = 'A' COLLATE utf8mb4_bin;</code></li><li><code>SELECT BINARY 'a' = 'A';</code><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></li></ul></li></ul><h2 id="什么是-collation"><a class="header-anchor" href="#什么是-collation"></a>什么是 Collation</h2><p>例如我们有 4 个字符 <code>A, B, a, b</code>，我们为每个字符赋一个数值，如 <code>A=0, B=1, a=2, b=3</code>，则 <code>A</code> 是符号(symbol)；<code>0</code> 是它的编码(encoding)；符号与编码的集合就叫作字符集(character set)<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p><p>如果要比较两个字符，最简单的方式是比较它们的编码。如 <code>A=0</code>, <code>B=1</code>，由于 <code>0 &lt; 1</code>，则认为 <code>A &lt; B</code>。Collation（翻译为“校对”）就是如何比较字符的规则。这个例子里，我们只用了一个简单的规则：比较字符的编码。</p><p>如果我们希望比较时忽略字符大小写呢？那我们就至少需要两个规则：</p><ol><li>将大小写字母一视同仁，<code>a = A</code>, <code>b = B</code></li><li>在此基础上再比较两个字符的编码</li></ol><p>MySQL 会根据字符集来存储字符串，会根据 Collation 来对比字符串。</p><h2 id="mysql-中的-collation"><a class="header-anchor" href="#mysql-中的-collation"></a>MySQL 中的 Collation</h2><p>可以通过 <code>show character set;</code> 来查看所有的字符集，通过 <code>show collation;</code> 来查看所有 collation。</p><p>通常，字符集与 Collation 的关系是一对多。每个字符集有一个默认的 collation，每一个 collation 只能跟一个字符集绑定。</p><p>Collation 的命名规则<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>通常是 <code>&lt;char-set&gt;_&lt;lang&gt;_&lt;case&gt;</code> 例如 <code>gb2312_chinese_ci</code>对应字符集 <code>gb2312</code>，语言是中文 <code>chinese</code>，大小写是忽略大小写 <code>ci</code>，如果是<code>cs</code> 则是区分大小写，如果是 <code>bin</code> 则是直接使用编码，也区分大小写。</p><h2 id="collation-可以应用在不同级别"><a class="header-anchor" href="#collation-可以应用在不同级别"></a>Collation 可以应用在不同级别</h2><p>可以在数据库级别指定默认 Collation<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>:</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> db_name</span><br><span class="line">    [[<span class="keyword">DEFAULT</span>] <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> charset_name]</span><br><span class="line">    [[<span class="keyword">DEFAULT</span>] <span class="keyword">COLLATE</span> collation_name]</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> db_name <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> latin1 <span class="keyword">COLLATE</span> latin1_swedish_ci;</span><br></pre></td></tr></table></figure><p>可以在表级别指定默认 Collation <sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tbl_name (column_list)</span><br><span class="line">    [[<span class="keyword">DEFAULT</span>] <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> charset_name]</span><br><span class="line">    [<span class="keyword">COLLATE</span> collation_name]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1 ( ... ) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> latin1 <span class="keyword">COLLATE</span> latin1_danish_ci;</span><br></pre></td></tr></table></figure><p>可以在列级别指定默认 Collation <sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">col_name &#123;CHAR | VARCHAR | TEXT&#125; (col_length)</span><br><span class="line">    [CHARACTER <span class="keyword">SET</span> charset_name]</span><br><span class="line">    [<span class="keyword">COLLATE</span> collation_name]</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1( col1 <span class="built_in">VARCHAR</span>(<span class="number">5</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> latin1 <span class="keyword">COLLATE</span> latin1_german1_ci);</span><br></pre></td></tr></table></figure><p>可以在查询的字符串中指定 Collation<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">[_charset_name]'string' [COLLATE collation_name]</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">'abc'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> _latin1<span class="string">'abc'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> _binary<span class="string">'abc'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> _utf8mb4<span class="string">'abc'</span> <span class="keyword">COLLATE</span> utf8mb4_danish_ci;</span><br></pre></td></tr></table></figure><h2 id="背后的故事"><a class="header-anchor" href="#背后的故事"></a>背后的故事</h2><p>数据库中有个字段是 <code>code</code>，存储了随机生成并哈希后的全局唯一 ID，但不是主键。今天突然发现 Hibernate 在 <code>findByCode</code> 的时候说返回的结果不唯一。查了很久后怀疑是哈希冲突，但最终发现哈希的结果并不一致，有一个字母的大小写是不同的，才发现MySQL 在 <code>=</code>，<code>like</code> 时并不区分大小写，最终学习到了 <code>collation</code> 的知识。</p><p>该问题最终通过修改哈希生成的逻辑，只生成大写字母的 code 解决。了解它的影响很重要。在写入主键时，也是不区分大小写的，所以如果生成的主键仅有大小写不同，是可能写入失败的。标记为 unique 的字段也是如此。</p><p>另外稍微查了下，Oracle 应该也有类似的机制，但具体的影响没有验证过。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/5.7/en/cast-functions.html#operator_binary" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/cast-functions.html#operator_binary</a> <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p>翻译自 MySQL 文档：<a href="https://dev.mysql.com/doc/refman/8.0/en/charset-general.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-general.html</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/8.0/en/charset-collation-names.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-collation-names.html</a> <a href="#fnref3" class="footnote-backref">↩</a></p></li><li id="fn4" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/8.0/en/charset-database.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-database.html</a> <a href="#fnref4" class="footnote-backref">↩</a></p></li><li id="fn5" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/8.0/en/charset-table.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-table.html</a> <a href="#fnref5" class="footnote-backref">↩</a></p></li><li id="fn6" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/8.0/en/charset-column.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-column.html</a> <a href="#fnref6" class="footnote-backref">↩</a></p></li><li id="fn7" class="footnote-item"><p><a href="https://dev.mysql.com/doc/refman/8.0/en/charset-literal.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/charset-literal.html</a> <a href="#fnref7" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MySQL 执行 &lt;code&gt;select &#39;a&#39; = &#39;A&#39;;&lt;/code&gt; 得到的结果竟然是真(&lt;code&gt;1&lt;/code&gt;)？同学，&lt;code&gt;collation&lt;/code&gt; 了解一下。&lt;/p&gt;
&lt;p&gt;究其原因，是因为默认的 Collation 设置为 &lt;code&gt;
      
    
    </summary>
    
      <category term="QQA" scheme="https://lotabout.me/categories/QQA/"/>
    
    
      <category term="MySQL" scheme="https://lotabout.me/tags/MySQL/"/>
    
      <category term="collation" scheme="https://lotabout.me/tags/collation/"/>
    
      <category term="charset" scheme="https://lotabout.me/tags/charset/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 快速入门</title>
    <link href="https://lotabout.me/2020/Kubernetes-Introduction/"/>
    <id>https://lotabout.me/2020/Kubernetes-Introduction/</id>
    <published>2020-05-07T21:04:05.000Z</published>
    <updated>2021-05-22T10:33:50.833Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes(简称 k8s<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>) 是一个容器编排系统，本文会实用的角度，讲解一些基本概念，基本操作。</p><h2 id="概述"><a class="header-anchor" href="#概述"></a>概述</h2><p>Kubernetes 是希腊语，含义是“舵手”，容器 (container) 也有“集装箱”的含义，k8s 是容器编排系统，就像舵手在开着一艘货轮，轮船上叠满了集装箱，可以说十分贴切。</p><p>k8s 在概念上主要分为资源对象和控制对象。资源对象包括容器、应用、配置、网络、存储等；控制对象则是方便管理这些资源而抽象的控制层，如 ReplicaSet 管理多副本，Deployment 管理版本的升级等。</p><h2 id="容器-container"><a class="header-anchor" href="#容器-container"></a>容器(Container)</h2><p>容器是最小的隔离单位，可以理解成一台虚拟机，一般上面只跑着一个(核心的)程序。也可以直接理解成一个容器就是一个 docker 实例。</p><p>实际上 k8s 定义了容器需要实现的接口(<a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md" target="_blank" rel="noopener">CRI</a>)，理论上可以有多种实现，如 docker, containerd, CRI-O 等<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>，但上手使用并不需要知道这些。</p><h2 id="pod"><a class="header-anchor" href="#pod"></a>Pod</h2><p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pod</a> 在 k8s的语境下一般不翻译。它的英文含义是“豆荚”，想像一个 container 是一个豆子，一个豆荚里有一到多个豆子，并组装成一个“豆角”。对应地，一个 pod 可以包含一个或多个container（实际中我还没见多对应多个container 的情形）。</p><p>对于我们使用来说，对 pod 最需要了解的有两点：</p><ol><li>它是 k8s 最小的调度单位</li><li>每个 pod 都有自己的 IP，且 k8s 要保证 pod 间通过这个 IP 可以互相访问</li></ol><img src="/2020/Kubernetes-Introduction/k8s-pod.svg" class="" title="Kubernetes Pod Network"><p>如上图，k8s 需要保证能在 Pod 1 里直接 ping 通 <code>10.1.20.2</code> 这个 IP(Pod 3)，尽管它们属于不同物理机。至于如何实现，与容器类似，也有<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">多种实现方式</a>，普通用户不需要了解。</p><p>跟 pod 相关的指令是平时用得最多的，例如：</p><ul><li><code>kubectl get pods</code> 列出当前 namespace 下的所有 pod (namespace 后面讨论)</li><li><code>kubectl get pod my-pod -o yaml</code> 列出 <code>my-pod</code> 的配置</li><li><code>kubectl log my-pod</code> 列出 <code>my-pod</code> 的所有日志</li><li><code>kubectl log -f --since=10m my-pod</code> 列出 <code>my-pod</code> 近 10 分钟的日志并持续监控</li><li><code>kubectl describe pods my-pod</code> 查看 <code>my-pod</code> 的状态（如重启，上次失败原因等）</li><li><code>kubectl exec -it my-pod bash</code> “登录” my-pod 并执行 bash</li></ul><h2 id="replicaset"><a class="header-anchor" href="#replicaset"></a>ReplicaSet</h2><p>一般在部署(微)服务时，我们会部署多个副本，一方面水平扩展，能承受更高的压力；另一方面可以防止单点故障影响服务整体的高可用。</p><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener">ReplicaSet</a>(RS)就是这种需求的一种抽象概念，一个 ReplicaSet 相当于是一个副本的集合，它是一个控制器(controller)。例如当一个目标为 3 副本的 ReplicaSet 管理的pod 挂了，则这个ReplicaSet 会启动新的/重启 pod 来满足副本数的需求。</p><p>一般我们不会直接和 ReplicaSet 打交道，而是通过 deployment 来做控制。</p><h2 id="deployment"><a class="header-anchor" href="#deployment"></a>Deployment</h2><p>ReplicaSet 可以控制 pod 的副本数，在实际部署中我们还会有更新、回溯等的需求，例如要将pod 更新到新的版本，希望能滚动升级(rolling update)，希望先停止一个旧版本的 pod 并启动新版本的 pod，直到所有的 pod 都是新版本的。期间作为一个整体对外的服务(service)不中断。</p><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a>也是一个 controller 概念，通过 yaml 文件的配置让我们很方便控制 pod：部署、更新、回滚、扩展、收缩等等。下面是示例配置文件：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span>           <span class="comment">#</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>              <span class="comment">#</span></span><br><span class="line"><span class="attr">metadata:</span>                     <span class="comment">#</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span>      <span class="comment">#</span></span><br><span class="line">  <span class="attr">labels:</span>                     <span class="comment">#</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span>                <span class="comment">#</span></span><br><span class="line"><span class="attr">spec:</span>                         <span class="comment">#</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span>                 <span class="comment">#--. 相当于 ReplicaSet 的定义</span></span><br><span class="line">  <span class="attr">selector:</span>                   <span class="comment">#  |</span></span><br><span class="line">    <span class="attr">matchLabels:</span>              <span class="comment">#  |</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span>              <span class="comment">#--'</span></span><br><span class="line">  <span class="attr">template:</span>                   <span class="comment">#--. 相当于单个 pod 的定义</span></span><br><span class="line">    <span class="attr">metadata:</span>                 <span class="comment">#  |</span></span><br><span class="line">      <span class="attr">labels:</span>                 <span class="comment">#  |</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span>            <span class="comment">#  |</span></span><br><span class="line">    <span class="attr">spec:</span>                     <span class="comment">#  |</span></span><br><span class="line">      <span class="attr">containers:</span>             <span class="comment">#  |</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>           <span class="comment">#  |</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.14.2</span>   <span class="comment">#  |</span></span><br><span class="line">        <span class="attr">ports:</span>                <span class="comment">#  |</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>   <span class="comment">#--'</span></span><br></pre></td></tr></table></figure><p>通过 <code>kubectl apply -f deployment.yml</code> 可以应用这个配置，k8s 会为我们创建一个Deployment，一个 ReplicaSet，同时会为我们启动 3 个 pod。可以通过如下命令查看相关状态：</p><ul><li><code>kubectl get deploy</code> 获取当前 namespace 下所有 deployments</li><li><code>kubectl get deploy my-deployment -o yaml</code> 获取 my-deployment 的配置 yaml</li><li><code>kubectl describe deploy my-describe</code> 获取 my-deployment 的一些详细状态</li><li><code>kubectl get rs</code> 获取当前 namespace 下的所有 ReplicaSet，一般用不着</li></ul><p>如果要更新 pod 版本，或是改变副本的数量，直接修改之前的 yaml 配置文件，再重新执行 <code>kubectl apply -f deployment.yml</code> 即可。k8s 会自动做出调整，滚动升级或回退。</p><h2 id="service"><a class="header-anchor" href="#service"></a>Service</h2><p>我们知道每个 pod 有自己的 IP，在更新版本或增减副本数时，一些 pod 可能被杀死，新的 pod 会被启动，那么其它服务如何决定连接到哪个 pod 呢？</p><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">Service</a> 就是针对这种需求创建的抽象，对使用方屏蔽内部 pod 变化。使用方将流量发到 Service，而 Service 需要将流量转发到底层的 pod，于是衍生出下面几个问题：</p><ol><li>使用方如何定位到 Service？</li><li>Service 如何找到目标的 Pod?</li><li>流量如何转发？</li></ol><p>下面是一个 Service 配置的示例：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span>            <span class="comment"># 通过标签选择目标 Pod</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># Service 暴露的端口</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span>    <span class="comment"># 转发到 pod 对应的端口</span></span><br></pre></td></tr></table></figure><p>对着配置先回答第二个问题：Service 是通过 <code>selector</code> 配置项指定标签，如果Deployment 里的 pod 的 <code>labels</code> 字段包含了 Service 中 <code>selector</code> 的标签，则会被选中。</p><p>流量转发方式比较多比较复杂，这里不做介绍。剩下的就是 Service 如何定位了。</p><h3 id="内部访问"><a class="header-anchor" href="#内部访问"></a>内部访问</h3><p>首先，我们注意到配置文件里有 <code>name</code> 字段，这是 Service 的名字。其次，在部署Service 后 k8s 会为 Service 分配一个虚拟 IP<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，称作<code>Cluster IP</code>。</p><p>在集群的 pod 里可以尝试 <code>telnet &lt;service name&gt; &lt;port&gt;</code> 或 <code>telnet &lt;cluster ip&gt; &lt;port&gt;</code> 来访问对应的 Service。注意的是这个虚拟 IP 是 ping 不通的，因为它是 iptables 实现的（也有其它实现方式）。</p><p>这里附上一个原理图（当然还有其它实现方式可选择），对细节没兴趣的话可直接跳过：</p><img src="/2020/Kubernetes-Introduction/k8s-service-clusterIP.svg" class="" title="Kubernetes ClusterIP"><p>当 Pod A 发起的网络请求会被 iptables 重定向到 kube-proxy，而它会监控集群内 Pod的变化，并将流量转发到对应的 Pod 里，默认转发的方式是 round-robin。</p><h3 id="外部访问"><a class="header-anchor" href="#外部访问"></a>外部访问</h3><p>很明显 ClusterIP 只在集群内部有办法访问，那集群外要如何访问 Service？</p><p>对外暴露 Service 有多种方式，这里只说 NodePort 的方式：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment"># 类型为 NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30336</span> <span class="comment"># 指定 NodePort 端口号</span></span><br></pre></td></tr></table></figure><p>当指定 NodePort 时，k8s 会在集群所有节点(物理机)上开相应的端口，集群外的流量通过这个端口转发到 kube-proxy，再由 kube-proxy 转发到后台的 pod 中，如下图：</p><img src="/2020/Kubernetes-Introduction/k8s-service-node-port.svg" class="" title="Kubernetes Service NodePort"><p>因此在 NodePort 模式下，集群外可以通过 <code>&lt;node_ip&gt;:&lt;node_port&gt;</code> 访问服务。</p><h3 id="常用命令"><a class="header-anchor" href="#常用命令"></a>常用命令</h3><p>Service 一般我们只关心它的 NodePort，用下面的命令查询：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get svc</span><br><span class="line">NAME              TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">my-svc            ClusterIP   10.42.51.51   &lt;none&gt;        80&#x2F;TCP,81&#x2F;TCP   10m</span><br><span class="line">my-svc-external   NodePort    10.42.51.52   &lt;none&gt;        80:30336&#x2F;TCP    10m</span><br></pre></td></tr></table></figure><p>上面的 <code>30336</code> 就是 NodePort。</p><h2 id="configmap"><a class="header-anchor" href="#configmap"></a>ConfigMap</h2><p>有了 Deployment 和 Service，部署服务已经不在话下，那么如何管理服务的配置信息呢？</p><p><a href="https://kubernetes.io/docs/concepts/configuration/configmap/" target="_blank" rel="noopener">ConfigMap</a> 就是对配置文件的抽象，也是使用 yaml 配置，也可以类似 pod 一样部署/更新，不过ConfigMap更新后需要重启 pod 才能应用新的配置。下面是配置示例（取自官方文档）：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">game-demo</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="comment"># property-like keys; each key maps to a simple value</span></span><br><span class="line">  <span class="attr">player_initial_lives:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">ui_properties_file_name:</span> <span class="string">"user-interface.properties"</span></span><br><span class="line">  <span class="comment"># file-like keys</span></span><br><span class="line">  <span class="attr">game.properties:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">enemy.types=aliens,monsters</span></span><br><span class="line">    <span class="string">player.maximum-lives=5</span></span><br><span class="line">  <span class="attr">user-interface.properties:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">color.good=purple</span></span><br><span class="line">    <span class="string">color.bad=yellow</span></span><br><span class="line">    <span class="string">allow.textmode=true</span></span><br></pre></td></tr></table></figure><p>注意：配置里的 “file-like” 的配置项其实只是用 yaml 的多行语法写了配置的内容，ConfigMap 本身不区分 “property-like” 还是 “file-like”，是由使用方决定的。</p><p>通过 <code>kubectl apply -f configmap.yaml</code> 部署，部署后可通过 <code>kubectl get cm -o yaml</code> 查看详情。</p><p>那么部署后的 ConfigMap 要如何在 Pod 里引用呢？</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configmap-demo-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">game.example/demo-game</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="comment"># Define the environment variable</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PLAYER_INITIAL_LIVES</span> <span class="comment"># Notice that the case is different here from the key name in the ConfigMap.</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">game-demo</span>           <span class="comment"># The ConfigMap this value comes from.</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">player_initial_lives</span> <span class="comment"># The key to fetch.</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">UI_PROPERTIES_FILE_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">game-demo</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">ui_properties_file_name</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">"/config"</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="comment"># You set volumes at the Pod level, then mount them into containers inside that Pod</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">      <span class="attr">configMap:</span></span><br><span class="line">        <span class="comment"># Provide the name of the ConfigMap you want to mount.</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">game-demo</span></span><br></pre></td></tr></table></figure><p>可以看到，有几种引用方式：</p><ul><li>通过 <code>valueFrom</code> 和 <code>configMapKeyRef</code> 引用单个配置项</li><li>通过 Pod 层的 <code>volumes</code> 和 container 层的 <code>volumeMounts</code> 将每个配置项挂载成Pod 里一个单独的文件。</li></ul><h2 id="namespace"><a class="header-anchor" href="#namespace"></a>Namespace</h2><p>命名空间(<a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/" target="_blank" rel="noopener">Namespace</a>)的作用是将隔离各种资源，像虚拟机一样虚拟一个集群。一般情况下不同 namespace 间的资源是不共享的，如 Pod 只能引用同一个 namespace 下的 ConfigMap。</p><p>在配置 Deployment、Service 及 ConfigMap 等资源时，可以通过 <code>namespace</code> 字段指定命名空间(需要提前创建)，如下例：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">load-balance</span>  <span class="comment">#&lt;-- load-balance 为提前创建好的 namespace</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="comment">#...</span></span><br></pre></td></tr></table></figure><p>常用的命令：</p><ul><li><code>kubectl get ns</code> 列出所有的 namespace</li><li><code>kubectl -n &lt;my-ns&gt; ...</code> 在执行其它命令时通过 <code>-n</code> 指定作用于某个 namespace</li><li><code>kubectl --all-namespaces ...</code> 在执行其它命令时指定作用于所有 namespace</li></ul><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>文章对 k8s 的一些基本概念做了简单的讲解：</p><ul><li>container 可以理解成一个 docker 实例，里面跑着一个程序/服务</li><li>pod 是 container 的抽象，有自己的 IP，不同 pod 网络互通，与 container 可以是一对一，也可以一对多</li><li>ReplicaSet 是对多副本 Pod 的抽象，会自动启动、停止 Pod 来达到目标副本数，一般不直接使用</li><li>Deployment 是一个控制概念，会创建、更新 ReplicaSet 从而实现 Pod 的部署、升级、回退、扩缩容等</li><li>Service 屏蔽 Pod 细节，提供了统一的、稳定的接口，有自己的虚拟 IP(ClusterIP)和端口，外部访问需要单独暴露接口（如 NodePort）</li><li>ConfigMap 是对配置文件的管理，实现配置项和 Pod 的解耦，配置更新后需要重启Pod</li><li>namespace 是对 k8s 集群的资源做一个隔离</li></ul><p>K8s 的概念很多、功能也很丰富，本文是从基础使用的角度做一个介绍，尽量达到“不了解细节，但工作够用”的程度。一些其它的概念(如 volumn)因为博主接触不多，这里也不介绍了。</p><p>最后：本人非 k8s 专业人士，文中如果有错误，请在评论里指出，我会进行修正。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://kubernetes.io/docs/concepts/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/</a> 官方教程</li><li><a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what?</a> Service 对外暴露的方法区别</li><li><a href="https://jiayi.space/post/kubernetescong-ru-men-dao-fang-qi-3-wang-luo-yuan-li" target="_blank" rel="noopener">kubernetes从入门到放弃3–(网络原理)</a> 相对底层的网络原理</li><li><a href="http://omerio.com/2015/12/18/learn-the-kubernetes-key-concepts-in-10-minutes/" target="_blank" rel="noopener">Learn the Kubernetes Key Concepts in 10 Minutes</a> 图文并茂，推荐</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>首尾字母之间有 8 个字母，所以称为 k8s，类似的还有 i18n(internationalization)。 <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p><a href="https://kubernetes.io/docs/concepts/overview/components/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/overview/components/</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p>严格来说，ExternalName 类型下不会分配 <a href="#fnref3" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Kubernetes(简称 k8s&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn1&quot; id=&quot;fnref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;) 是一个容器编排系统，本文会实用的角度，讲解一些基本概念，基本操作。&lt;/p&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="Kubernetes" scheme="https://lotabout.me/tags/Kubernetes/"/>
    
      <category term="k8s" scheme="https://lotabout.me/tags/k8s/"/>
    
      <category term="introduction" scheme="https://lotabout.me/tags/introduction/"/>
    
  </entry>
  
  <entry>
    <title>声明式(declarative) vs 命令式(imperative)</title>
    <link href="https://lotabout.me/2020/Declarative-vs-Imperative-language/"/>
    <id>https://lotabout.me/2020/Declarative-vs-Imperative-language/</id>
    <published>2020-05-06T16:38:20.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>声明式(declarative)是结果导向的，命令式(imperative)是过程导向的。它们都有自己适用的场景和局限，于是现实中的编程语言常常都有两者的身影。</p><h2 id="命令式-vs-声明式"><a class="header-anchor" href="#命令式-vs-声明式"></a>命令式 vs 声明式</h2><blockquote><p><strong>Declarative programming</strong> is a programming paradigm … that expresses thelogic of a computation without describing its controlflow<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p></blockquote><blockquote><p><strong>Imperative programming</strong> is a programming paradigm that uses statements thatchange a program’s state<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p></blockquote><p>例如我们有一个用户列表，用 python 查找手机号为 <code>183</code> 开头的用户，可能会这么写：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_users</span><span class="params">()</span>:</span></span><br><span class="line">    ret = []</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> users:</span><br><span class="line">        <span class="keyword">if</span> user[<span class="string">'phone'</span>].startswith(<span class="string">'183'</span>):</span><br><span class="line">            ret.append(user)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure><p>这是命令式的作法，给出通向目标的每个指令；而声明式语言则直接描述目标，如 SQL 可能会这么写：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">users</span> <span class="keyword">where</span> phone <span class="keyword">like</span> <span class="string">'183%'</span>;</span><br></pre></td></tr></table></figure><p>显然，声明式语言对用户更友好，用户可以关心更少的细节。更重要的是：它允许多种底层实现方式，保持目标不变的同时不断优化，如上例中 SQL 的实现既可以遍历所有的用户，也可以使用索引来加速查找。</p><p>而命令式的好处自然是它的表达能力了，图灵完备的语言可以表达任何的可计算问题。</p><h2 id="声明式不是万能的"><a class="header-anchor" href="#声明式不是万能的"></a>声明式不是万能的</h2><p>声明式语言直接描述目标，那怎么才能清晰地描述目标呢？有时候也需要命令式的帮助。</p><p>考虑下面的命令式的伪代码要如何用 SQL 实现：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">goods &#x3D; (SELECT * from goods)</span><br><span class="line">for g in goods:</span><br><span class="line">    #&gt;&gt; 注意在内层循环中可以引用外层表 goods 的字段</span><br><span class="line">    evaluations &#x3D; (SELECT * from evaluations e where e.good_id &#x3D;&#x3D; g.id)</span><br><span class="line">    if len(evaluations) &gt; 3:</span><br><span class="line">        print(g, len(evaluations))</span><br></pre></td></tr></table></figure><p>会发现使用常规的 <code>JOIN</code> 语义，很难实现上述目标。子查询里是无法引用其它查询的字段的，这本身是一种优势，数据库内部可以对 JOIN 的实现进行优化，但同时也限制了对复杂 JOIN 语义的表达。</p><p>后来 SQL 里加了个关键字：<code>LATERAL</code><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，用来表达子查询的先后顺序，上例可以写成：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> g.*, e.num <span class="keyword">FROM</span> goods <span class="keyword">as</span> g</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> <span class="keyword">LATERAL</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(ev.id) <span class="keyword">as</span> <span class="keyword">num</span> <span class="keyword">FROM</span>  evaluation <span class="keyword">AS</span> ev <span class="keyword">WHERE</span> ev.goods_id=g.id</span><br><span class="line">) <span class="keyword">AS</span> e <span class="keyword">ON</span> <span class="literal">TRUE</span> <span class="keyword">WHERE</span> <span class="keyword">num</span> &gt; <span class="number">3</span></span><br></pre></td></tr></table></figure><p>有了 <code>LATERAL</code>，在 LATERAL 后的子查询就可以引用前面子查询的变量。那么<code>LATERAL</code>算是声明式还是命令式？似乎变得模糊了，一方面它依旧是表达目标，是声明式；另一方面它似乎指定了操作步骤（先查 goods，再查 evaluations）属于命令式。</p><p><strong>当描述的目标变复杂时，声明式语言也不可避免变得更命令式，通过描述过程来描述更多细节</strong></p><h2 id="命令式里的声明式"><a class="header-anchor" href="#命令式里的声明式"></a>命令式里的声明式</h2><p>传统上的一些编程语言，如 C/C++、Java、Python 等都被认为是命令式语言。用这些语言编写程序时的确是一条语句一条语句导向最终的目标。但这些编程语言与声明式的界限也并非泾渭分明。</p><p>除了机器码，包括汇编在内的几乎其它所有编程语言都有“函数”的概念。通过将语句组装成函数，无论是在使用还是阅读上，似乎都可以认为是在指定目标，是声明式的。例如要计算 Fibonacci 数列的第 N 个数，如果已经有现成的库，我们也只需要写 <code>x = fibonacci(n)</code>，似乎也不是“命令式”吧。</p><p>另外，编程语言的一些语法糖也加强了我们“声明目标”的能力，如 Python 的装饰器(decorator) <code>@dataclass</code>，“声明”式地定义一个类为数据类，Java 的 lombok 库也有<code>@Data</code> 这样的注解(annotation)实现类似的功能。</p><p><strong>通过适当的封装、组件化，命令式也可以变成目标导向，变得更加“声明式”</strong></p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>声明式使用方便、容易理解、易于优化，但表达能力有限，要表达更复杂的目标时，它往往也在向命令式靠拢了。而命令式里很多重复性的工作，也可以通过适当地组件化部分变成声明式。这样看来，一门语言是声明式还是命令式，似乎取决于我们接触的细节多少。</p><p>生活中，大老板决定路线，小老板决定方案，螺丝钉具体落实，不也类似嘛。</p><p>在我们设计语言、库时，尽可能地将接口设计得“声明式”，暴露更少的细节给用户，不仅能让用户用得开心，也方便内部的扩展、优化。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://reactjs.org/" target="_blank" rel="noopener">https://reactjs.org/</a> React 的设计理念：Declarative view</li><li>《Design Data-Intensive Applications》第二章，说明 CSS/XSL 是声明式的语言</li><li><a href="https://djyde.github.io/blog/declarative-programming-is-the-future/" target="_blank" rel="noopener">未来属于声明式编程</a> 对声明式编程语言的思考</li><li><a href="https://cloud.tencent.com/developer/article/1080886" target="_blank" rel="noopener">命令式和声明式，哪个才是你的菜</a> 描述了声明式、命令式的一些差别</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://en.wikipedia.org/wiki/Declarative_programming" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Declarative_programming</a> <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p><a href="https://en.wikipedia.org/wiki/Imperative_programming" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Imperative_programming</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p>出现在 <a href="https://ronsavage.github.io/SQL/sql-99.bnf.html" target="_blank" rel="noopener">ISO/IEC7095:199</a> 标准中，Postgre、Flink 支持，其它本人没查全 <a href="#fnref3" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;声明式(declarative)是结果导向的，命令式(imperative)是过程导向的。它们都有自己适用的场景和局限，于是现实中的编程语言常常都有两者的身影。&lt;/p&gt;
&lt;h2 id=&quot;命令式-vs-声明式&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#
      
    
    </summary>
    
      <category term="Post" scheme="https://lotabout.me/categories/Post/"/>
    
    
      <category term="Programming Paradigm" scheme="https://lotabout.me/tags/Programming-Paradigm/"/>
    
      <category term="Declarative" scheme="https://lotabout.me/tags/Declarative/"/>
    
      <category term="Imperative" scheme="https://lotabout.me/tags/Imperative/"/>
    
  </entry>
  
  <entry>
    <title>事务隔离级别备忘</title>
    <link href="https://lotabout.me/2020/QQA-Isolation-Level-of-Database/"/>
    <id>https://lotabout.me/2020/QQA-Isolation-Level-of-Database/</id>
    <published>2020-04-17T09:27:43.000Z</published>
    <updated>2021-05-22T10:33:50.853Z</updated>
    
    <content type="html"><![CDATA[<p>数据库的事务有哪些隔离级别，它们解决了哪些问题？</p><h2 id="并发问题"><a class="header-anchor" href="#并发问题"></a>并发问题</h2><p>隔离级别解决的事务的并发问题。当两个事务同时发生时，数据库最终的执行结果可以等价将事务里的各个操作排序后执行<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，不过不是任意排序都可以，有些排序的结果不符合业务的预期。本节会列举其中的一些“错误”，而“隔离级别”就是一种约定，告诉我们数据库不会出现哪些“错误”。</p><p>记号：<code>w1[x]</code> 代表事务 1 写入行 x，<code>r1[x]</code> 代表事务 1 读取行 x, <code>c1</code> 代表提交事务 1, <code>a1</code> 代表回滚事务 1.</p><h3 id="p0-dirty-write"><a class="header-anchor" href="#p0-dirty-write"></a>P0: Dirty Write</h3><p>问题时序P0：<code>w1[x]...w2[x]...(c1 or a1)</code></p><p>两个事务分别写入，然后两个事务分别提交或回滚，则事务的结果无法确定。考虑下图：</p><img src="/2020/QQA-Isolation-Level-of-Database/P0-dirty-write.svg" class="" title="P0 Dirty Write"><p>图中假设在一个事务里，满足约束 <code>x == y</code>，如果不做隔离，则事务结束后，数据库中的值不满足约束。</p><p>当前支持事务的数据库都可以避免上述时序。例如在 MySQL 中，如果两个事务写入同一行，后写入的事务会等待直到前一个事务结束或超时。</p><h3 id="p1-dirty-read"><a class="header-anchor" href="#p1-dirty-read"></a>P1: Dirty Read</h3><p>问题时序P1：<code>w1[x]...r2[x]...(c1 or a1)</code></p><p>即 r2 能读取未提交的事务的修改 w1。这会导致 t2 事务过程中的约束被打破，如下图：</p><img src="/2020/QQA-Isolation-Level-of-Database/P1-dirty-read.svg" class="" title="P1 Dirty Read"><p>该时序下，在 t2 事务内部，原本的约束 <code>x+y==100</code> 由于 t1 的写入被打破了。</p><p>隔离级别 READ COMMITTED 的目的就是阻止该时序的发生。即在 t1 未提交时，它的修改对 t2 不可见。</p><h3 id="p2-fuzzy-read-non-repeatable-read"><a class="header-anchor" href="#p2-fuzzy-read-non-repeatable-read"></a>P2: Fuzzy Read | Non-repeatable Read</h3><ul><li>典型时序A2：<code>r1[x]...w2[x]...c2...r1[x]...c1</code></li><li>问题时序P2：<code>r1[x]...w2[x]...(c1 or a1)</code> 是 A2 的扩展</li></ul><p>在事务 t1 读取数据后，另一个事务 t2 提交的修改对 t1 后续的读可见，则会造成不一致，如下图(A2)：</p><img src="/2020/QQA-Isolation-Level-of-Database/A2-fuzzy-read.svg" class="" title="A2 Fuzzy Read"><p>而 P2 是对 A2 的扩展，下例虽然不违反 A2，实际使用时也有问题：</p><img src="/2020/QQA-Isolation-Level-of-Database/P2-fuzzy-read.svg" class="" title="P2 Fuzzy Read"><p>事务 t2 提交后的修改对 t1 可见，导致 t1 内部的约束失效。</p><p>一般数据库的隔离级别 REPEATABLE READ 能阻止 A2 的发生，但不一定能完全支持 P2。</p><h3 id="p3-phantom"><a class="header-anchor" href="#p3-phantom"></a>P3: Phantom</h3><ul><li>典型时序A3：<code>r1[P]...w2[y in P]...c2...r1[P]...c1</code></li><li>问题时序P3：<code>r1[P]...w2[y in P]...(c1 or a1)</code></li></ul><p>与 Fuzzy Read 不同，Phantom（幻读）涉及的不是单个数据行，而是查询（如 <code>SELECT ... WHERE P</code>）。</p><img src="/2020/QQA-Isolation-Level-of-Database/A3-phantom.svg" class="" title="A3 Phanom"><p>而 P3 是对 A3 的扩展，下例(H3)虽然不违反 A3，实际使用时也有问题：</p><img src="/2020/QQA-Isolation-Level-of-Database/P3-phantom.svg" class="" title="P3 Phanom"><p>Phantom 问题在于，查询条件隐含要求了范围数据的可重复读。需要 SERIALIZABLE 隔离级别才能防止。</p><h3 id="p4-lost-update"><a class="header-anchor" href="#p4-lost-update"></a>P4: Lost Update</h3><p>问题时序：<code>r1[x]...w2[x]...w1[x]...c1</code></p><p>该时序下，事务 t1 的修改 w1 将被 t2 的修改覆盖而丢失，如下图：</p><img src="/2020/QQA-Isolation-Level-of-Database/P4-Lost-Update.svg" class="" title="P4 Lost Update"><p>注意的是，禁用 P1 依旧会出现 P4，而禁用 P2 后就不会出现 P4，可以说 P4 是 P2 的一个子模式。</p><p>在 MySQL 中，需要使用 <code>SELECT ... FOR UPDATE</code> 来锁住对应的行，阻止其它事务对选中行的读写，来防止 P4 的发生。</p><h3 id="a5-data-item-constraint-violation"><a class="header-anchor" href="#a5-data-item-constraint-violation"></a>A5: Data Item Constraint Violation</h3><p>我们隐式地对数据的两行数据有约束，下面是两种破坏约束的情形：</p><h4 id="a5a-read-skew"><a class="header-anchor" href="#a5a-read-skew"></a>A5A: Read Skew</h4><p>问题时序：<code>r1[x]...w2[x]...w2[y]...c2...r1[y]...(c1 or a1)</code>，示例：</p><img src="/2020/QQA-Isolation-Level-of-Database/A5A-Read-Skew.svg" class="" title="A5A Read Skew"><h4 id="a5b-write-skew"><a class="header-anchor" href="#a5b-write-skew"></a>A5B: Write Skew</h4><p>问题时序：<code>r1[x]...r2[y]...w1[y]...w2[x]...(c1 and c2 occur)</code>，示例：</p><img src="/2020/QQA-Isolation-Level-of-Database/A5B-Write-Skew.svg" class="" title="A5B Write Skew"><p>A5A 和 A5B 在 P2(Fuzzy Read) 的加强版被禁止的情况下是不会出现的，不过仅在 ANSI版本(A2) 被禁止的情况下依然可能出现。</p><h2 id="隔离级别"><a class="header-anchor" href="#隔离级别"></a>隔离级别</h2><p>从原论文摘抄如下（省略了 P4C）：</p><p>（注意的是，下图假设 REPEATABLE READ 是支持了 P2 扩展的，而许多数据库的实现并不支持）</p><img src="/2020/QQA-Isolation-Level-of-Database/Isolation.svg" class="" title="Isolation"><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>有时候更重要的不是解决问题的方法，而是认识到问题是什么。</p><p>文章里介绍了并发事务可能出现的多种问题。</p><ul><li>主要注意 <code>P1: Dirty Read</code>、<code>P2: Fuzzy Read</code> 和 <code>P3: Phantom</code></li><li><code>P4: Lost Update</code> 和 <code>A5: Constraint Violation</code> 都是 P2 的变种。</li><li>不过真正的实现上，P2 并没有被良好的支持，所以了解 P4、A5A、A5B 都是挺重要的</li></ul><p>文章本来是阅读《Design Data-Intensive Applications》后想做个备忘，在给各个问题举例时发现了论文《A Critique of ANSI SQL Isolation Levels》，结果花了很长时间来理解论文里的各种情形。本文也算是另一种形式的备忘吧，只不过更“学术”了，不“实用”了。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li><a href="https://arxiv.org/pdf/cs/0701157.pdf" target="_blank" rel="noopener">A Critique of ANSI SQL Isolation Levels</a> 论文，本文的主要来源</li><li>《Design Data-Intensive Applications》第7章的小结部分，有相似的讨论，不那么学术，更实用</li><li><a href="https://blog.pythian.com/understanding-mysql-isolation-levels-repeatable-read/" target="_blank" rel="noopener">Understanding MySQL Isolation Levels: Repeatable-Read</a> MySQL 中的 RR 隔离级别的实际表现，包括幻读</li><li><a href="https://blog.acolyer.org/2016/02/24/a-critique-of-ansi-sql-isolation-levels/" target="_blank" rel="noopener">A Critique of ANSI SQL Isolation Levels</a> 论文的图文版博客，参考了文章里的图</li><li><a href="http://www.adp-gmbh.ch/ora/misc/isolation_level.html" target="_blank" rel="noopener">ANSI isolation levels</a> ANSI 规定的 4 种隔离级别</li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px">1.</span><span style="display: inline-block; vertical-align: top">并发的一致性可以参考另一篇文章 <a href="http://localhost:4000/2019/QQA-What-is-Sequential-Consistency/" target="_blank" rel="noopener">什么是顺序一致性</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据库的事务有哪些隔离级别，它们解决了哪些问题？&lt;/p&gt;
&lt;h2 id=&quot;并发问题&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#并发问题&quot;&gt;&lt;/a&gt;并发问题&lt;/h2&gt;
&lt;p&gt;隔离级别解决的事务的并发问题。当两个事务同时发生时，数据库最终的执行结果可以等
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="Database" scheme="https://lotabout.me/tags/Database/"/>
    
      <category term="isolation level" scheme="https://lotabout.me/tags/isolation-level/"/>
    
      <category term="consistency" scheme="https://lotabout.me/tags/consistency/"/>
    
  </entry>
  
  <entry>
    <title>C3 算法：Python 多继承的内部原理</title>
    <link href="https://lotabout.me/2020/C3-Algorithm/"/>
    <id>https://lotabout.me/2020/C3-Algorithm/</id>
    <published>2020-04-15T18:56:42.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>在 Python 中使用 Mixin 有没有遇到过 <code>Cannot create a consistent method resolution</code> 错误？Mixin 在 Python 里只是多继承(multiple inheritance) 的一种用法，而多继承时，Python 是如何决定父类的顺序呢？咱们就来看看 C3 算法是何方神圣。</p><p>TLDR; 我个人觉得 C3 算法就是拓扑排序…</p><h2 id="method-resolution-order-mro"><a class="header-anchor" href="#method-resolution-order-mro"></a>Method Resolution Order(MRO)</h2><p>考虑下面的多继承的代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"hello from A"</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"hello from A"</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span><span class="params">(A, B)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">C().hello()</span><br></pre></td></tr></table></figure><p>上面的 <code>C().hello()</code> 输出是什么呢？这里会输出 <code>hello from A</code>。</p><p>Python 的多继承符合直觉，可以认为：在查找一个方法或类时，<strong>会从左到右查找父类的方法或类</strong>，找到为止。这个查找顺序叫作 Method Resolution Order，简称 MRO。可以通过 <code>&lt;class&gt;.mro()</code> 查看，如：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; C.mro()</span><br><span class="line">[__main__.C, __main__.A, __main__.B, object]</span><br></pre></td></tr></table></figure><p>可以看出，查找方法时，会先查 A 再查 B。</p><h2 id="c3-算法"><a class="header-anchor" href="#c3-算法"></a>C3 算法</h2><p>那么如何计算 MRO 呢？Python 里使用 C3 算法<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。其实就是拓扑排序，只是排序的“图”上加了点特技。</p><p>符号定义：</p><ul><li>方便起见，先定义符号 $C_1C_2…C_N$ 代表一个列表 $[C_1, C_2, …, C_N]$</li><li>再定义加号： $C + (C_1 C_2 … C_N) = C C_1 C_2 … C_N$</li><li>定义 $C_1C_2…C_N$ 列表中，$C_1$ 为头部，$C_2…C_N$ 为尾部</li></ul><p>算法：</p><ul><li>对于类定义 <code>class C(B1, B2, ..., BN)</code>，记它的 MRO 为 <code>L[C]</code>（L 代表 linearization）</li><li>所有类都会继承 <code>object</code>，定义 <code>L[object] = object</code></li><li>算法定义计算步骤为 $L[C] = C + merge(L[B_1], L[B_2], …, L[B_N], B_1B_2…B_N)$<ul><li>注意这里末尾的 $B_1B_2…B_N$，就是我们说的“特技”</li></ul></li><li><code>merge</code> 方法定义为：<ol><li>选取第一个列表 $B_1$</li><li>首先选取第一个列表 $B_1$ 第一个元素</li><li>如果该元素不出现在 merge 方法其它列表的尾部，则输出元素，并将该元素从其它列表中移除，取下一个元素</li><li>如果该元素出现在其它列表的尾部，则选取下一个列表，并重复步骤 2，直到所有列表为空</li><li>如果遍历过所有的列表，有列表不为空且过程中没有输出，则说明得不到有效MRO，报错</li></ol></li></ul><h2 id="算法示例"><a class="header-anchor" href="#算法示例"></a>算法示例</h2><p>merge 算法其实就是拓扑排序，举例如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">O = object</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">F</span><span class="params">(O)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">E</span><span class="params">(O)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">D</span><span class="params">(O)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span><span class="params">(D,F)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(E,D)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(B,C)</span>:</span> <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>继承关系如下图左，而预期的 MRO 关系如下图右（A-&gt;B 表示 MRO 中 A 出现在 B 之前）：</p><img src="/2020/C3-Algorithm/C3-example-1.svg" class="" title="C3 Example 1"><p>计算 MRO 相当于对上右图做拓扑排序，merge 参数的最后一项，实际定义了同层元素间的指向。</p><p>Level 2 的 MRO 很容易计算</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">L[E] &#x3D; E + merge(L[O]) &#x3D; E + merge(O) &#x3D; E + O &#x3D; EO</span><br><span class="line">L[D] &#x3D; D + merge(L[O]) &#x3D; D + merge(O) &#x3D; D + O &#x3D; DO</span><br><span class="line">L[F] &#x3D; F + merge(L[O]) &#x3D; F + merge(O) &#x3D; F + O &#x3D; FO</span><br></pre></td></tr></table></figure><p>Level 1 的 MRO 计算如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">L[B] &#x3D; B + merge(L[E], L[D], ED)</span><br><span class="line">     &#x3D; B + merge(EO, DO, ED)     # 检测 EO 中的元素 E</span><br><span class="line">     &#x3D; B + E + merge(O, DO, D)   # 检测 DO 中的元素 D</span><br><span class="line">     &#x3D; B + E + D ＋merge(O, O, ) # 检测元素 O</span><br><span class="line">     &#x3D; B + E + D ＋O</span><br><span class="line">     &#x3D; BEDO</span><br><span class="line"></span><br><span class="line">L[C] &#x3D; C + merge(L[D], L[F], DF)</span><br><span class="line">     &#x3D; B + merge(DO, FO, DF)     # 检测 DO 中的元素 D</span><br><span class="line">     &#x3D; B + D + merge(O, FO, F)   # 检测 FO 中的元素 F</span><br><span class="line">     &#x3D; B + D + F + merge(O, O, ) # 检测元素 O</span><br><span class="line">     &#x3D; B + D + F + O</span><br><span class="line">     &#x3D; BDFO</span><br></pre></td></tr></table></figure><p>于是 A 的 MRO 为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">L[A] &#x3D; A + merge(L[B], L[C], BC)</span><br><span class="line">     &#x3D; A + merge(BEDO, BDFO, BC)              # 检测 BEDO 中的 B</span><br><span class="line">     &#x3D; A + B + merge(EDO, DFO, C)             # 检测 EDO 中的 E</span><br><span class="line">     &#x3D; A + B + E + merge(DO, DFO, C)          # 检测 DO 中的 D</span><br><span class="line">     &#x3D; A + B + E + D + merge(O, FO, C)        # 检测 O 中的 O，出现在 FO 尾部</span><br><span class="line">     &#x3D; A + B + E + D + merge(O, FO, C)        # 检测 C 中的 C</span><br><span class="line">     &#x3D; A + B + E + D + C + merge(O, FO, )     # 检测 O 中的 O，出现在 FO 尾部</span><br><span class="line">     &#x3D; A + B + E + D + C + merge(O, FO, )     # 检测 FO 中的 F</span><br><span class="line">     &#x3D; A + B + E + D + C + F ＋merge(O, O, )  # 检测 O</span><br><span class="line">     &#x3D; A + B + E + D + C + F ＋O</span><br><span class="line">     &#x3D; ABEDCFO</span><br></pre></td></tr></table></figure><p>最后注意根据拓扑图，元素 E 和 C 的顺序先后其实无关紧要。</p><h2 id="反例"><a class="header-anchor" href="#反例"></a>反例</h2><p>对于下面的类定义，算法就会报错。因为 A 要求 X 在 Y 左边，而 B 的要求正好相反，二者矛盾。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">O = object</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span><span class="params">(O)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Y</span><span class="params">(O)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(X,Y)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(Y,X)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">T</span><span class="params">(A,B)</span>:</span> <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>拓扑图如下，我们发现它存在循环引用：</p><img src="/2020/C3-Algorithm/Cyclic.svg" class="" title="Cyclic Example"><p>算法计算过程如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">L[X] &#x3D; XO</span><br><span class="line">L[Y] &#x3D; YO</span><br><span class="line">L[A] &#x3D; A + merge(L[X], L[Y], XY)</span><br><span class="line">     &#x3D; A + merge(XO, YO, XY)</span><br><span class="line">     &#x3D; AXYO</span><br><span class="line">L[B] &#x3D; B + merge(L[Y], L[X], XY)</span><br><span class="line">     &#x3D; B + merge(YO, XO, YX)</span><br><span class="line">     &#x3D; BYXO</span><br><span class="line">L[T] &#x3D; T + merge(L[A], L[B], AB)</span><br><span class="line">     &#x3D; T + merge(AXYO, BYXO, AB)        # 检测 AXYO 中的 A</span><br><span class="line">     &#x3D; T + A + merge(XYO, BYXO, B)      # 检测 XYO 中的 X，出现在 BYXO 的尾部，跳过</span><br><span class="line">     &#x3D; T + A + merge(XYO, BYXO, B)      # 检测 BYXO 中的 B</span><br><span class="line">     &#x3D; T + A + B + merge(XYO, YXO, )    # 检测 YXO 中的 Y，出现在 XYO 的尾部</span><br><span class="line">     # 此处无法再化简，报错</span><br></pre></td></tr></table></figure><h2 id="python-2-3-之前的问题"><a class="header-anchor" href="#python-2-3-之前的问题"></a>Python 2.3 之前的问题</h2><p>C3 算法是在 Python 2.3 后引入的，在这之前，考虑下面的示例：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">F=type(<span class="string">'Food'</span>,(),&#123;<span class="string">'remember2buy'</span>:<span class="string">'spam'</span>&#125;)</span><br><span class="line">E=type(<span class="string">'Eggs'</span>,(F,),&#123;<span class="string">'remember2buy'</span>:<span class="string">'eggs'</span>&#125;)</span><br><span class="line">G=type(<span class="string">'GoodFood'</span>,(F,E),&#123;&#125;) <span class="comment"># works before Python 2.3</span></span><br></pre></td></tr></table></figure><p>用 C3 的方式画出拓扑图如下，虽然代码里不明显，图里可以看到存在循环引用：</p><img src="/2020/C3-Algorithm/Before-2.3.svg" class="" title="Bad Example Before Python 2.3"><p>而 Python 2.3 之前的 MRO 算法在调用 <code>G.remember2buy</code> 属性时，预期输出 <code>spam</code>（因为 <code>G(F, E)</code>，预期先查找 F 的方法），而实际会输出 <code>eggs</code>（E 的方法），不符合预期。Python 2.3 及以后就会报错。</p><p>因此如果在实现 Mixin 的时候，如果搞错顺序可能就无法运行，例如：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">(object)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MixinA</span><span class="params">(Base)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MixinB</span><span class="params">(Base)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Y</span><span class="params">(MixinA, MixinB, Base)</span>:</span> <span class="keyword">pass</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span><span class="params">(Base, MixinA, MixinB)</span>:</span> <span class="keyword">pass</span> <span class="comment"># error</span></span><br></pre></td></tr></table></figure><p>简单的结论是越具体的实现位置越靠前。</p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>写到最后发现：C3 算法似乎和拓扑排序没有任何区别？只是在标记拓扑图上做一些工夫，保证类定义的先后顺序反映在 MRO 中：即 <code>A(B, C)</code> 最后的 MRO 中 B 一定在 C 之前。</p><p>这个知识也许在使用 mixin 出错的时候能帮上忙，剩余时候感觉也没什么用。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><p>算法、示例取自 <a href="https://www.python.org/download/releases/2.3/mro/" target="_blank" rel="noopener">The Python 2.3 Method Resolution Order</a>，建议看原文。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px">1.</span><span style="display: inline-block; vertical-align: top">python 2.3 及以后</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在 Python 中使用 Mixin 有没有遇到过 &lt;code&gt;Cannot create a consistent method resolution&lt;/code&gt; 错误？Mixin 在 Python 里只是多继承(multiple inheritance) 的一种用法，
      
    
    </summary>
    
      <category term="Knowledge" scheme="https://lotabout.me/categories/Knowledge/"/>
    
    
      <category term="python" scheme="https://lotabout.me/tags/python/"/>
    
      <category term="mixin" scheme="https://lotabout.me/tags/mixin/"/>
    
      <category term="multiple inheritance" scheme="https://lotabout.me/tags/multiple-inheritance/"/>
    
      <category term="C3" scheme="https://lotabout.me/tags/C3/"/>
    
  </entry>
  
  <entry>
    <title>低延时场景不要用 Webflux</title>
    <link href="https://lotabout.me/2020/Webflux-vs-Sync/"/>
    <id>https://lotabout.me/2020/Webflux-vs-Sync/</id>
    <published>2020-04-12T09:54:45.000Z</published>
    <updated>2021-05-22T10:33:50.869Z</updated>
    
    <content type="html"><![CDATA[<p>Webflux 号称性能强悍，实际项目里却发现性能不升反降。经验上，当后端服务的响应时间小于10ms，则异步非阻塞提升不明显，甚至效果变差。本文会将对此做验证。</p><p>（注：性能相关的结论只能作为经验结论，实际程序的表现还是需要实际 profile）</p><h2 id="实验设置"><a class="header-anchor" href="#实验设置"></a>实验设置</h2><p>数据流如下：通过 jmeter 发送 POST 请求到 TestService，转发流量到后端服务。</p><img src="/2020/Webflux-vs-Sync/Experiment-Setup.svg" class="" title="Experiment Setup"><p>这里发送的请求是 POST 请求，发送内容是约为 800B 的 Json 来保证一定程度上的计算量，目的是为了模拟真实的使用场景。事实上如果只是转发 GET 而没有任何计算，则webflux 完胜 blocking 的方式。</p><h2 id="实验结果"><a class="header-anchor" href="#实验结果"></a>实验结果</h2><p>结论：在 Backend 低延时(&lt;10ms)的情况下，Webflux 的的彼时和吞吐都普遍不如blocking 的方式。</p><img src="/2020/Webflux-vs-Sync/Webflux-vs-Sync.svg" class="" title="Experiment Result"><p>上图中，左图代表延时，右图代表吞吐，横坐标是后端 sleep 的毫秒数。横坐标是 log坐标，用以保证 &lt;10ms 的密集区可以较好地展示。延时只关心 99 分位和 999 分位（图中同颜色的线，下方代表 99 分位，上方代表 999 分位），不用关心绝对值，只需要关注蓝线和红线的相对位置。解读如下：</p><ul><li>左边 4 图中，当后端 sleep &lt; 10ms 时，99 分位的蓝线都要低于红线，代表同步延时要低于 webflux</li><li>sleep &lt; 10ms 时，999 分位的蓝线普遍低于红线，但也有例外</li><li>右边 4 图的吞吐，在 sleep &lt; 10ms 时蓝线均低于红线。代表同步的吞吐更高</li><li>灰线代表的直接发送的方式不同情况下延时和吞吐都有波动，目前还没想明白原因</li><li>当压力和后端延时增加时，webflux 的优势也慢慢体现</li></ul><p>详细实验结果参见：<a href="https://docs.google.com/spreadsheets/d/1BDWcwZhEx2SczAXUteRQhYk5DIpwv3m6E5P6EU3vNp4/edit?usp=sharing" target="_blank" rel="noopener">Webflux vs Sync</a>。</p><h2 id="测试代码"><a class="header-anchor" href="#测试代码"></a>测试代码</h2><p>Backend 代码：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"/post/&#123;ms&#125;/&#123;numItems&#125;"</span>)</span><br><span class="line"><span class="keyword">public</span> Mono&lt;Map&lt;String, Object&gt;&gt; postAsync(<span class="meta">@PathVariable</span> <span class="keyword">long</span> ms, <span class="meta">@PathVariable</span> <span class="keyword">int</span> numItems, <span class="meta">@RequestBody</span> Map&lt;String, Object&gt; request) &#123;</span><br><span class="line">    Map&lt;String, Object&gt; response = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// consume request</span></span><br><span class="line">    <span class="keyword">long</span> requestLength = request.entrySet().stream()</span><br><span class="line">            .map(Object::toString)</span><br><span class="line">            .mapToInt(String::length)</span><br><span class="line">            .sum();</span><br><span class="line">    response.put(<span class="string">"total"</span>, requestLength);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// insert random items</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;numItems; i++) &#123;</span><br><span class="line">        response.put(<span class="string">"random_"</span> + i, UUID.randomUUID().toString());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sleep</span></span><br><span class="line">    <span class="keyword">if</span> (ms &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> Mono.delay(Duration.ofMillis(ms)).map(it -&gt; response);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Mono.just(response);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同步代码如下，注意 http client 的最大连接数设置为 300，tomcat 线程数默认为200。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"/post/&#123;ms&#125;/&#123;numItems&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">post</span><span class="params">(@PathVariable <span class="keyword">long</span> ms, @PathVariable <span class="keyword">int</span> numItems, @RequestBody Map&lt;String, Object&gt; request)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    String url = String.format(<span class="string">"http://%s/post/%d/%d"</span>, baseUrl, ms, numItems);</span><br><span class="line">    StringEntity entity = <span class="keyword">new</span> StringEntity(objectMapper.writeValueAsString(request), ContentType.APPLICATION_JSON);</span><br><span class="line">    HttpPost httpPost = <span class="keyword">new</span> HttpPost(url);</span><br><span class="line">    httpPost.setEntity(entity);</span><br><span class="line">    HttpEntity responseEntity = httpClient.execute(httpPost).getEntity();</span><br><span class="line">    <span class="keyword">return</span> EntityUtils.toString(responseEntity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Webflux 异步发送代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"/post/&#123;ms&#125;/&#123;numItems&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Mono&lt;String&gt; <span class="title">post</span><span class="params">(@PathVariable <span class="keyword">long</span> ms, @PathVariable <span class="keyword">int</span> numItems, @RequestBody Map&lt;String, Object&gt; request)</span> </span>&#123;</span><br><span class="line">    String url = String.format(<span class="string">"http://%s/post/%d/%d"</span>, baseUrl, ms, numItems);</span><br><span class="line">    <span class="keyword">return</span> webClient.post()</span><br><span class="line">            .uri(url)</span><br><span class="line">            .body(BodyInserters.fromValue(request))</span><br><span class="line">            .retrieve()</span><br><span class="line">            .bodyToMono(String<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发送的 Json 为：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"random1"</span>: <span class="number">1</span>, <span class="attr">"random2"</span>: <span class="number">2</span>, <span class="attr">"random3"</span>: <span class="number">3</span>, <span class="attr">"random4"</span>: <span class="number">4</span>, <span class="attr">"random5"</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="attr">"random6"</span>: <span class="number">6</span>, <span class="attr">"random7"</span>: <span class="number">7</span>, <span class="attr">"random8"</span>: <span class="number">8</span>, <span class="attr">"random9"</span>: <span class="number">9</span>, <span class="attr">"random10"</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">"random11"</span>: <span class="number">11</span>, <span class="attr">"random12"</span>: <span class="number">12</span>, <span class="attr">"random13"</span>: <span class="number">13</span>, <span class="attr">"random14"</span>: <span class="number">14</span>, <span class="attr">"random15"</span>: <span class="number">15</span>,</span><br><span class="line">    <span class="attr">"random16"</span>: <span class="number">16</span>, <span class="attr">"random17"</span>: <span class="number">17</span>, <span class="attr">"random18"</span>: <span class="number">18</span>, <span class="attr">"random19"</span>: <span class="number">19</span>, <span class="attr">"random20"</span>: <span class="number">20</span>,</span><br><span class="line">    <span class="attr">"random21"</span>: <span class="number">21</span>, <span class="attr">"random22"</span>: <span class="number">22</span>, <span class="attr">"random23"</span>: <span class="number">23</span>, <span class="attr">"random24"</span>: <span class="number">24</span>, <span class="attr">"random25"</span>: <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"random26"</span>: <span class="number">26</span>, <span class="attr">"random27"</span>: <span class="number">27</span>, <span class="attr">"random28"</span>: <span class="number">28</span>, <span class="attr">"random29"</span>: <span class="number">29</span>, <span class="attr">"random30"</span>: <span class="number">30</span>,</span><br><span class="line">    <span class="attr">"random31"</span>: <span class="number">31</span>, <span class="attr">"random32"</span>: <span class="number">32</span>, <span class="attr">"random33"</span>: <span class="number">33</span>, <span class="attr">"random34"</span>: <span class="number">34</span>, <span class="attr">"random35"</span>: <span class="number">35</span>,</span><br><span class="line">    <span class="attr">"random36"</span>: <span class="number">36</span>, <span class="attr">"random37"</span>: <span class="number">37</span>, <span class="attr">"random38"</span>: <span class="number">38</span>, <span class="attr">"random39"</span>: <span class="number">39</span>, <span class="attr">"random40"</span>: <span class="number">40</span>,</span><br><span class="line">    <span class="attr">"random41"</span>: <span class="number">41</span>, <span class="attr">"random42"</span>: <span class="number">42</span>, <span class="attr">"random43"</span>: <span class="number">43</span>, <span class="attr">"random44"</span>: <span class="number">44</span>, <span class="attr">"random45"</span>: <span class="number">45</span>,</span><br><span class="line">    <span class="attr">"random46"</span>: <span class="number">46</span>, <span class="attr">"random47"</span>: <span class="number">47</span>, <span class="attr">"random48"</span>: <span class="number">48</span>, <span class="attr">"random49"</span>: <span class="number">49</span>, <span class="attr">"random50"</span>: <span class="number">50</span>,</span><br><span class="line">    <span class="attr">"random51"</span>: <span class="number">51</span>, <span class="attr">"random52"</span>: <span class="number">52</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="详细实验设置"><a class="header-anchor" href="#详细实验设置"></a>详细实验设置</h2><ul><li>分别对 sleep 1-10, 20, 30, 40, 50ms 的 Backend 进行压测，numItems 均为 1</li><li>压测使用 Jmeter（尝试过 wrk，结果不准确）</li><li>分别用 50, 100, 200, 300 线程发送请求</li><li>每次实验压测 1 分钟。</li><li>JVM 参数中 <code>Xmx</code> 和 <code>Xms</code> 均设置为 4G</li><li>Jmeter 到 TestService 使用长连接，TestService 到 Backend 使用库的默认选项（应该都是短连接）。</li></ul><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>要再次强调的是：实验不代表真实使用场景。本实验也只是尝试模拟博主自己的使用场景，而且是事后验证，先是生产遇到不升反降，再反过来验证。</p><p>结论：在 IO 延时小的情况下，webflux 的性能不如同步阻塞的方法</p><p>从原理来说，webflux 所代表的异步非阻塞的主要作用是使用少量的线程资源处理大量的IO ，也就是<strong>提高吞吐</strong>，但是提交任务和 worker thread 抢占任务执行等等都有开销，而这部分开销和同步阻塞的线程创建和切换的开销相比，究竟谁优谁劣，就需要在程序中实际验证了。</p><p>不过从技术选型的角度，文章得出的结论是，webflux 不适用于低延时的场景。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><p>Webflux 文档中关于性能的描述：</p><blockquote><p>Performance has many characteristics and meanings. Reactive and non-blockinggenerally do not make applications run faster. They can, in some cases, (forexample, if using the WebClient to execute remote calls in parallel). On thewhole, it requires more work to do things the non-blocking way and that canincrease slightly the required processing time.</p><p><a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-performance" target="_blank" rel="noopener">https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-performance</a></p></blockquote><ul><li><a href="https://medium.com/@filia.aleks/microservice-performance-battle-spring-mvc-vs-webflux-80d39fd81bf0" target="_blank" rel="noopener">Spring Boot performance battle: blocking vs non-blocking vs reactive</a> 对后端高延时的情况进行测试，结论是 webflux 均好于其它情况</li><li><a href="https://medium.com/@the.raj.saxena/springboot-2-performance-servlet-stack-vs-webflux-reactive-stack-528ad5e9dadc" target="_blank" rel="noopener">SpringBoot 2 performance — servlet stack vs WebFlux reactive stack</a> Webflux 不几乎不损失性能下能极大提高吞吐</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Webflux 号称性能强悍，实际项目里却发现性能不升反降。经验上，当后端服务的响应时间小于10ms，则异步非阻塞提升不明显，甚至效果变差。本文会将对此做验证。&lt;/p&gt;
&lt;p&gt;（注：性能相关的结论只能作为经验结论，实际程序的表现还是需要实际 profile）&lt;/p&gt;
&lt;h2
      
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="benchmark" scheme="https://lotabout.me/tags/benchmark/"/>
    
      <category term="java" scheme="https://lotabout.me/tags/java/"/>
    
      <category term="webflux" scheme="https://lotabout.me/tags/webflux/"/>
    
      <category term="reactor" scheme="https://lotabout.me/tags/reactor/"/>
    
  </entry>
  
  <entry>
    <title>过早优化为什么是万恶之源？</title>
    <link href="https://lotabout.me/2020/premature-optimization/"/>
    <id>https://lotabout.me/2020/premature-optimization/</id>
    <published>2020-04-06T20:24:43.000Z</published>
    <updated>2021-05-22T10:33:50.885Z</updated>
    
    <content type="html"><![CDATA[<p>因为它不是。对不关键部分的过早优化才是。Donald Knuth 这句话的原文是：</p><blockquote><p>Programmers waste enormous amounts of time thinking about, or worryingabout, the speed of noncritical parts of their programs, and these attemptsat efficiency actually have a strong negative impact when debugging andmaintenance are considered. We should forget about small efficiencies, sayabout 97% of the time: <strong>premature optimization is the root of all evil</strong>.Yet we should not pass up our opportunities in that critical 3%.</p><p>– <a href="https://wiki.c2.com/?PrematureOptimization" target="_blank" rel="noopener">https://wiki.c2.com/?PrematureOptimization</a></p></blockquote><p>翻译过来是（注意前半句话）：</p><blockquote><p>程序员们浪费了大量的时间去思考、担心程序中非关键部分的性能，如果考虑整体代码的 debug 和维护的时间，则这些性能优化的开销是得不偿失的。对于约 97% 的小优化点，我们应该忽略它们：<strong>过早优化为什么万恶之源</strong>。而对于剩下的关键的 3%，我们则不能放弃优化的机会。</p></blockquote><p>原文说的是：对于不关键的部分不要过早优化。而原因主要是性价比太低。</p><h2 id="什么部分才关键？"><a class="header-anchor" href="#什么部分才关键？"></a>什么部分才关键？</h2><p>一看预算、二看数量、三看单价。</p><ul><li>“预算”是指你能容忍的时间/空间。支付宝的一笔转帐大概率需要在 200ms 内完成；一笔贷款申请 10 min 审批可能算快的；淘宝新商品也许上线 1h 后才能搜到。</li><li>“数量”是指某个操作被调用的次数。量变引起质变。如一般 64 位的 String 里 length字段是 8 个字节，100 万个就被放大到 8MB 内存了。</li><li>“单价”就是某个操作本身的耗时了，通常需要和数量结合起来看。</li></ul><p>换句话说，当<code>单价*数量</code>有可能大于<code>预算</code>时，要么优化数量，要么优化单价。</p><p>问题在于，我怎么知道哪部分操作可能出问题？这也许也是 Donald Knuth 最想要表达的：我们并不知道，所以要最后通过 profile 找到。借用知乎网友的回答<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，原文应该翻译为“盲目优化是万恶之源”。</p><p>也许上面的说法都指向“不要过早优化”，但实际编码中，多数情况下，我认为<strong>需要</strong>尽早优化。原因有二：</p><ol><li>事后优化代价很大</li><li>事实上通过经验是可以预判优化点的</li></ol><h2 id="事后优化头很大"><a class="header-anchor" href="#事后优化头很大"></a>事后优化头很大</h2><p>这里我举两个亲身经历的事件。</p><p>第一个是做规则引擎，允许用户编写规则，QA 发现在导入一个大的配置文件 (2k个规则)需要 2 小时，在 profile 之后也很快定位到瓶颈：读写数据库的次数过多。之前的逻辑是针对界面创建规则写的，在创建规则过程中需要访问多次数据库，而批量导入时重用了单次的规则，没有合并批量的读写，导致特别慢。</p><p>思路很清晰，批量读写数据库。问题在于写入规则的逻辑很复杂，费了九牛二虎之力才理清楚逻辑改成了批量的版本，结果 bug 还是修了好几个迭代。</p><p>第二个是有一个微服务，调用的协议使用了 Avro，请求和响应中会携带数据的 Schema。经过 profile 后发现数据的序列化和反序列化占用了最多的时间，而 Schema 的内容远大于数据本身。</p><p>由于有些服务已经上线，修改协议的难度比较大，后期只能尝试增加批量的接口一定程度上缓解。</p><p>除此之外，还可能遇到“处处是热点，处处是瓶颈”的情况。比如 Rust 的编译时间很长，可是 profile 了编译器发现没有明显的热点，每个过程都占用不多，但整体性能就是优化不了。</p><h2 id="让优化刻入骨髓"><a class="header-anchor" href="#让优化刻入骨髓"></a>让优化刻入骨髓</h2><p>虽然提前判断出优化点很大程度上依赖于经验，但其实还是有一定“套路”的。</p><p>比如考虑“数量”，只要一个操作的次数与输入的规模相关，且输入规模可能爆炸，就要注意去优化。比如上节示例里的批量数据库读写。</p><p>比如考虑“单价”，比如上例中，Schema 内容大于数据内容，本身就是不合理的，单价的损耗太大了，就需要在设计时提前考虑。当然“单价”一般要依托于数量。</p><p>对于“处处是热点，处处是瓶颈”其实就没有特别好的方法了，只能说，要把一些知识化成习惯。例如知道了二维数组先遍历行再遍历列能更高效利用缓存，把它作为编码习惯就好了。</p><p>当然，最最重要的还是确定“预算”！接需求的时候确认输入的规模，能接受的延时等等都能让我们更好地理解优化的边界和粒度。</p><h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2><p>不要让“过早优化是万恶之源”成为懒惰的借口。过早优化不好的前提是你不知道瓶颈在哪，而在实际中是有迹可循的：预算、数量、单价。事后的优化往往代价会很大，预防才是最便宜的治疗。</p><h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2><ul><li>多搜搜谷歌相关的讨论，正反的观点都多了解了解</li><li><a href="https://gywbd.github.io/posts/2016/10/the-premature-optimization-is-evil-myth.html" target="_blank" rel="noopener">对“提早优化是万恶之源”的批判</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px">1.</span><span style="display: inline-block; vertical-align: top"><a href="https://www.zhihu.com/question/24282796/answer/846758069" target="_blank" rel="noopener">「过早的优化是万恶之源」这种说法对不对，为什么？ - 南星的回答 - 知乎</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;因为它不是。对不关键部分的过早优化才是。Donald Knuth 这句话的原文是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Programmers waste enormous amounts of time thinking about, or worrying
abou
      
    
    </summary>
    
      <category term="Post" scheme="https://lotabout.me/categories/Post/"/>
    
    
      <category term="optimization" scheme="https://lotabout.me/tags/optimization/"/>
    
  </entry>
  
  <entry>
    <title>实验：ForkJoinPool 并行度</title>
    <link href="https://lotabout.me/2020/Benchmark-ForkJoinPool/"/>
    <id>https://lotabout.me/2020/Benchmark-ForkJoinPool/</id>
    <published>2020-04-01T22:00:47.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>在调用外部接口时通过 <code>CompletableFuture.supplyAsync</code> 异步调用，该方法默认将任务提交到全局唯一的 ForkJoinPool，而它的并行度可以受<code>java.util.concurrent.ForkJoinPool.common.parallelism</code> 影响。</p><p>本实验的目的是探究在异步请求快响应(~= 1ms)时，并行度对整体性能的影响。</p><a id="more"></a><h2 id="实验设置"><a class="header-anchor" href="#实验设置"></a>实验设置</h2><p>真实场景：</p><ul><li>每次请求约调用接口 200 次</li><li>每次接口请求约 1ms 完成</li></ul><p>当然由于接受并发请求，同时会接收多个请求，暂不纳入考虑。bench 代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Future&gt; futures = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> x = i;</span><br><span class="line">    futures.add(CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        bh.consume(x);</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (Future future: futures) &#123;</span><br><span class="line">    future.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="实验环境"><a class="header-anchor" href="#实验环境"></a>实验环境</h2><ul><li>OS: Mac, 8C, 16G</li><li>Java version: JDK 11.0.2, OpenJDK 64-Bit Server VM, 11.0.2+9</li><li>Bench 框架：JMH</li><li>JMH 调用参数：<code>java -jar target/benchmarks.jar -i 5 -bs 50 -f 3</code></li></ul><h2 id="实验结果"><a class="header-anchor" href="#实验结果"></a>实验结果</h2><p>实验结果如下图：</p><img src="/2020/Benchmark-ForkJoinPool/result.svg" class="" title="Benchmark Result"><ul><li>图中的并行度分别为 1, 2, 4, 8, 16, 32, 64, 128, 256</li><li>图中的 x 轴间隔是 log 过后的结果，可以看到两点的 x 轴距离相等</li><li>最左边的点 <code>parallelism = 1</code> 时，ForkJoinPool 会为每个提交的任务创建一个线程</li><li>第二个点代表 <code>parallelism = 2</code>，此时最多运行两个线程，预期的时间为<code>1 * 200 50 / 2 = 5000ms</code> 实际开销 <code>6610</code>，多出的猜测是线程创建和切换</li><li>并行度翻倍后，平均时间大概减少一半，但随着并行度的增大(&gt;8)，减少的时间慢慢就小于一半了。</li><li>最后即使 <code>parallelism &gt; 200</code>，也没办法达到完全并行(1ms)的状态。</li></ul><p>大致结论：并行度越大效果越好，但 overhead 也会越来越大。</p><p>详细实验结果参见：<a href="https://gist.github.com/lotabout/430f96f0829cc586c773643a9883d1ec" target="_blank" rel="noopener">Gist: CompletableFuture.supplyAsync profile</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在调用外部接口时通过 &lt;code&gt;CompletableFuture.supplyAsync&lt;/code&gt; 异步调用，该方法默认将任务提交到全局唯一的 ForkJoinPool，而它的并行度可以受
&lt;code&gt;java.util.concurrent.ForkJoinPool.common.parallelism&lt;/code&gt; 影响。&lt;/p&gt;
&lt;p&gt;本实验的目的是探究在异步请求快响应(~= 1ms)时，并行度对整体性能的影响。&lt;/p&gt;
    
    </summary>
    
      <category term="Notes" scheme="https://lotabout.me/categories/Notes/"/>
    
    
      <category term="benchmark" scheme="https://lotabout.me/tags/benchmark/"/>
    
      <category term="java" scheme="https://lotabout.me/tags/java/"/>
    
      <category term="ForkJoinPool" scheme="https://lotabout.me/tags/ForkJoinPool/"/>
    
  </entry>
  
  <entry>
    <title>Python fileinput 模块：命令行工具利器</title>
    <link href="https://lotabout.me/2020/python-fileinput-module/"/>
    <id>https://lotabout.me/2020/python-fileinput-module/</id>
    <published>2020-03-27T10:34:33.000Z</published>
    <updated>2021-05-22T10:33:50.885Z</updated>
    
    <content type="html"><![CDATA[<p>命令行工具经常要处理从 <code>stdin</code> 或文件读取输入，<code>fileinput</code> 模块让我们很轻松就能实现。</p><h2 id="示例需求"><a class="header-anchor" href="#示例需求"></a>示例需求</h2><p>在 <code>tail -f</code> 看日志的时候，如果在某一行卡了很长时间，往往我们想看到底花了多长时间。因此希望有一个工具，能在每行日志前加上接收时的时间戳。例如：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ tail -f xxx.log</span><br><span class="line">some good thing happend</span><br><span class="line">some good thing happend</span><br><span class="line">some bad thing happend</span><br></pre></td></tr></table></figure><p>需要一个工具，如 <code>timed.py</code>:</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ tail -f xxx.log | timed.py</span><br><span class="line">[2020-03-27 10:41:13.514709] some good thing happend</span><br><span class="line">[2020-03-27 10:41:13.525803] some good thing happend</span><br><span class="line">[2020-03-27 10:41:13.630232] some bad thing happend</span><br></pre></td></tr></table></figure><p>这样就能知道花了多长时间。</p><h2 id="示例实现"><a class="header-anchor" href="#示例实现"></a>示例实现</h2><p>有了 <code>fileinput</code> 处理标准输入，只需要 4 行：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> fileinput</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fileinput.input():</span><br><span class="line">    print(<span class="string">f'[<span class="subst">&#123;datetime.now()&#125;</span>] <span class="subst">&#123;line&#125;</span>'</span>, end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure><h2 id="更多特性"><a class="header-anchor" href="#更多特性"></a>更多特性</h2><p>其实如果只是从标准输入读取，也不麻烦，上面的例子可以写成：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    print(<span class="string">f'[<span class="subst">&#123;datetime.now()&#125;</span>] <span class="subst">&#123;line&#125;</span>'</span>, end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure><p><code>fileinput</code> 同时还能处理参数(<code>sys.args</code>)中的文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ timed.py &lt;file1&gt; &lt;file2&gt;</span><br><span class="line">$ timed.py &lt;file1&gt; - # 读取文件 file1 后等待标准输入</span><br></pre></td></tr></table></figure><p>对于传统的行处理程序来说，十分便利</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;命令行工具经常要处理从 &lt;code&gt;stdin&lt;/code&gt; 或文件读取输入，&lt;code&gt;fileinput&lt;/code&gt; 模块让我们很轻松就能实现。&lt;/p&gt;
&lt;h2 id=&quot;示例需求&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#示例需求&quot;&gt;&lt;/a&gt;示
      
    
    </summary>
    
      <category term="Project" scheme="https://lotabout.me/categories/Project/"/>
    
    
      <category term="python" scheme="https://lotabout.me/tags/python/"/>
    
      <category term="fileinput" scheme="https://lotabout.me/tags/fileinput/"/>
    
  </entry>
  
  <entry>
    <title>评：分布式系统相关挑战</title>
    <link href="https://lotabout.me/2020/Comment-on-Challenges-with-distributed-systems/"/>
    <id>https://lotabout.me/2020/Comment-on-Challenges-with-distributed-systems/</id>
    <published>2020-03-15T10:08:51.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>如果有人说分布式系统不难，很可能是他还不知道自己不知道。AWS 的文章：<a href="https://aws.amazon.com/cn/builders-library/challenges-with-distributed-systems/" target="_blank" rel="noopener">分布式系统相关挑战</a>很好地描述了布式系统面临问题。本文针对其中的一些内容，做些笔记，记录下自己的想法。</p><h2 id="分布式系统的类型"><a class="header-anchor" href="#分布式系统的类型"></a>分布式系统的类型</h2><p>三种类型：</p><ol><li>离线分布式系统，一般与线上业务无关，如批处理，大数据分析平台等</li><li>软实时分布式系统，宕机几分钟或几个小时不影响线上业务，如索引生成器</li><li>硬实时分布式系统，也称为 请求/响应 服务，如 web 前端服务器，交易系统</li></ol><p>原文章主要考虑的是“硬实时系统”，就博主接触的业务来说，一般“硬实时”要求在200~500ms 内一个请求要返回，其它行业的业务可能要求更宽一些。</p><p>一般硬实时系统跟终端用户直接相关，因此要求有很高的容错性。</p><h2 id="容错域"><a class="header-anchor" href="#容错域"></a>容错域</h2><blockquote><p>硬实时分布式系统的难点在于网络允许将消息从一个<strong>容错域</strong>发送到另一个<strong>容错域</strong>。发送消息似乎没有什么危害。但事实上，发送消息是一切变得比正常情况更加复杂的源头</p></blockquote><p>容错域指的是一个边界，当错误发生时，边界内的所有内容都受到影响。例如我们的的程序调用一个方法 <code>save(id)</code>，这个方法需要写入硬盘，但是现在硬盘满了，那么我们可以假设，不仅仅 <code>save</code> 方法受影响了，接下来所有跟写硬盘相关的方法都会错误，我们也不必花心思从这个错误中恢复了，反正都没用。</p><p>传统上，一台机器（或虚拟机）就可以认为是一个容错域，机器里的程序要是因为 CPU、内存、硬盘等等问题而发生错误，经常情况下程序内部也无能为力去恢复，所以索性也可以不管。</p><p>而分布式是将消息从一个容错域（机器）发到另一个，因此需要考虑当另一个容错域（机器）出错时，我们要如何处理，是重试还是放弃？而最恶心的是，很多时候甚至无法得知对方发生了什么。</p><h2 id="通过网络收发消息"><a class="header-anchor" href="#通过网络收发消息"></a>通过网络收发消息</h2><p>通过网络收发消息至少需要 8 个步骤，而每个步骤都可能出错（整合自原文）：</p><img src="/2020/Comment-on-Challenges-with-distributed-systems/Network-Call.svg" class="" title="Network Call"><ol><li>POST REQUEST：Client 将消息放到网络上，过程中可能因为网络问题或 SERVER拒绝而发送失败</li><li>DELIVER REQUEST：网络将消息发到 Server，可能 Server 接到消息立即崩溃而失败（Server 没收到）</li><li>VALIDATE REQUEST：Server 验证请求有效性，可能由于数据包损坏，版本不兼容或其它错误而失败</li><li>UPDATE SERVER STATE：Server 根据请求更新内部状态，可能由于 Server 内部问题出错</li><li>POST REPLY：Server 向网络发送响应，可能由于网卡或其它问题导致失败</li><li>DELIVER REPLY：即使网络在上面的步骤中正常工作，这时也可能无法正确将响应传递给 Client</li><li>VALIDATE REPLY：Client 验证响应的有效性，Client 可能判定响应无效</li><li>UPDATE CLIENT STAT：Client 根据响应更新自己的状态，可能由于消息不兼容或其它问题而失败</li></ol><p>这意味着每一个网络调用，你都需要处理上述的 8 种可能的错误。通常结果就是发现业务代码被淹没在错误处理代码中。客户端代码通常像这样（来自原文）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(error, reply) &#x3D; network.send(remote, actionData)</span><br><span class="line">switch error</span><br><span class="line">  case POST_FAILED:</span><br><span class="line">    &#x2F;&#x2F; 处理 Server 没有接收到请求的情形</span><br><span class="line">  case RETRYABLE:</span><br><span class="line">    &#x2F;&#x2F; Server 接收到请求，但未处理(transient failure)，需要重试</span><br><span class="line">  case FATAL:</span><br><span class="line">    &#x2F;&#x2F; Server 接到请求，但是请求不符合要求</span><br><span class="line">  case UNKNOWN: &#x2F;&#x2F; 超时</span><br><span class="line">    &#x2F;&#x2F; 最恶心的情况，只知道消息发出去了，但不知道 Server 收没收到？处理了没？结果是成功还是失败？</span><br><span class="line">    &#x2F;&#x2F; P.S. 原文说“这里我们只知道 Server 收到消息，但不知道结果”，但博主理解其实是不知道 Server 是否收到消息的。</span><br><span class="line">  case SUCCESS:</span><br><span class="line">    if validate(reply)</span><br><span class="line">      &#x2F;&#x2F; 根据响应更新状态</span><br><span class="line">      &#x2F;&#x2F; do something with reply object</span><br><span class="line">    else</span><br><span class="line">      &#x2F;&#x2F; 响应有问题或不兼容等</span><br></pre></td></tr></table></figure><h2 id="爆炸的测试"><a class="header-anchor" href="#爆炸的测试"></a>爆炸的测试</h2><p>例如一个功能需要 4 次网络调用，则对每个请求，客户端都需要测试 5 种错误情况，共记 20 个测试。如果单机版本的程序有 10 个测试，则现在需要 200 个测试。同样，服务端也需要类似的测试用例。</p><h2 id="处理未知的错误"><a class="header-anchor" href="#处理未知的错误"></a>处理未知的错误</h2><p>当调用超时的时候，客户端要怎么处理呢？这时我们只知道消息发送了，不知道 Server收到没有？开始处理没有？处理的结果如何？当一个 API 不是幂等的时候，问题尤为严重。</p><p>例如下订单超时了，客户端应该重试吗？如果消息已经处理了，重试就会重复下单；如果消息只是网络延时了，重试之后，之前的消息又到来了，还是会重复下单；不重试的话，如果 Server 确实没收到消息，则业务逻辑出错。</p><p>难处理是因为不知道真实的情况，没有办法做准确的应对。这也是为什么微服务的 API最好是幂等的，客户端就可以无脑重试了。</p><h2 id="硬实时分布式系统群"><a class="header-anchor" href="#硬实时分布式系统群"></a>硬实时分布式系统群</h2><blockquote><p>天启的八种故障模式可以发生在分布式系统中的任何抽象层。上文的示例仅限于一台客户端计算机、一个网络和一台服务器计算机。即使在这种简单的场景中，故障状态矩阵的复杂性也会呈爆炸式增长。与单台客户端计算机示例相比，实时分布式系统具有更复杂的故障状态矩阵</p></blockquote><p>每过一层网络就会有 8 个步骤，就可能会有 8 个错误。考虑<code>客户端 -&gt; 负载均衡 -&gt; 服务器</code>，多了一层网络就多了 8 个可能的错误。</p><h2 id="分布式错误通常是潜在的"><a class="header-anchor" href="#分布式错误通常是潜在的"></a>分布式错误通常是潜在的</h2><p>通常这些错误并不是立马发生（和稳定复现）的。</p><blockquote><p>这些故障不仅普遍而且成本高昂，而且几个月前部署到生产中的错误也可能引发这些故障。然后需要一段时间来触发实际导致这些错误发生（并蔓延到整个系统）的场景的组合</p></blockquote><h2 id="分布式错误的病毒式传播"><a class="header-anchor" href="#分布式错误的病毒式传播"></a>分布式错误的病毒式传播</h2><p>原文举了很有意思的例子：</p><ul><li>一台 catalog server 硬盘满了，于是总是返回空</li><li>负载均衡发现它的响应特别快，将更多的请求发到这台机器上</li><li>接到空请求的业务系统出错，整个网站瘫痪了</li></ul><h2 id="分布式系统中的问题总结"><a class="header-anchor" href="#分布式系统中的问题总结"></a>分布式系统中的问题总结</h2><blockquote><ul><li>工程师无法对错误状况进行组合。相反，他们必须考虑许多故障排列。大多数错误可以随时发生，与任何其他错误状况无关（因此，可能会与其他错误状况相结合）。</li><li>任何网络操作的结果都可能是 UNKNOWN，在这种情况下，请求可能已成功、失败或已接收但未处理。</li><li>分布式问题发生在分布式系统的所有逻辑层级，而不仅仅是低层级的物理计算机。</li><li>由于递归，分布式问题在更高层级的系统上会变得更加严重。</li><li>分布式错误通常会在部署到系统后很长时间才出现。</li><li>分布式错误可能会蔓延到整个系统。</li><li>上述许多问题都源自联网的物理定律，无法更改</li></ul></blockquote><h2 id="写在后面"><a class="header-anchor" href="#写在后面"></a>写在后面</h2><p>原文描述的挑战主要是容错/故障方面的，分布式系统的“难”还有其它方面的体现，例如（不全面）：</p><ul><li>业务上，如何管理分布式状态，如何处理数据一致性</li><li>开发上，不同服务可能使用不同技术栈，如何抹平差异，服务间如何通信，隔离？</li><li>安全上，如何管理授权，如何止恶意破坏、修改，如何防止可用性的干扰</li><li>管理上，机器多，服务多，配置多，如何有效管理（部署、更新、排查、扩展、监控等）。</li></ul><p>分布式系统是十分复杂的，要心存敬畏。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果有人说分布式系统不难，很可能是他还不知道自己不知道。AWS 的文章：&lt;a href=&quot;https://aws.amazon.com/cn/builders-library/challenges-with-distributed-systems/&quot; target=&quot;_bl
      
    
    </summary>
    
      <category term="Comment" scheme="https://lotabout.me/categories/Comment/"/>
    
    
      <category term="Comment" scheme="https://lotabout.me/tags/Comment/"/>
    
      <category term="Distributed" scheme="https://lotabout.me/tags/Distributed/"/>
    
  </entry>
  
  <entry>
    <title>《微服务设计》</title>
    <link href="https://lotabout.me/2020/Book-Notes-Building-Microservices/"/>
    <id>https://lotabout.me/2020/Book-Notes-Building-Microservices/</id>
    <published>2020-02-21T14:14:50.000Z</published>
    <updated>2021-05-22T10:33:50.825Z</updated>
    
    <content type="html"><![CDATA[<p>简评：<a href="https://www.amazon.cn/dp/B01M3VNAYQ/" target="_blank" rel="noopener">这本书</a>是很“宽”的一本书，描述了许多构建微服务中将面临的挑战，不过大多数知识点还是点到为止。个人觉得适合有一定基础的读者，能扩展知识的宽度，之后再针对其中的知识点深造。</p><p>本文是读书笔记，由 XMind 导出（<a href="/2020/Book-Notes-Building-Microservices/building-microservices.xmind">XMind 源文件</a>）。 不建议阅读。</p><a id="more"></a><h2 id="ch01-微服务"><a class="header-anchor" href="#ch01-微服务"></a>Ch01: 微服务</h2><h3 id="什么是微服务"><a class="header-anchor" href="#什么是微服务"></a>什么是微服务</h3><ul><li><p>很小，专注好做一件事</p><ul><li>构建服务时，内聚性很重要</li><li>单一职责原则：把因相同原因而变化的东西聚合到一起，把因不同原因而变化的东西分离开来</li><li>服务越小，独立性的好处越多，但管理大量服务也会越复杂</li></ul></li><li><p>自治性</p><ul><li>能独立部署</li><li>通过网络通信</li><li>能独立修改（不对调用方产生影响）</li></ul></li></ul><h3 id="主要好处"><a class="header-anchor" href="#主要好处"></a>主要好处</h3><ul><li><p>技术异构性</p></li><li><p>弹性</p><ul><li>舱壁，一个组件失效不会影响其它部分</li></ul></li><li><p>扩展</p><ul><li>粒度更细</li></ul></li><li><p>简化部署</p><ul><li>局部更新（C端常用）</li><li>快速迭代，容易回滚</li></ul></li><li><p>与组织结构相匹配</p></li><li><p>可组合性</p><ul><li>利于重用已有功能</li></ul></li><li><p>对可替代性的优化</p><ul><li>（可以重写小服务）</li></ul></li></ul><h3 id="面向服务的架构"><a class="header-anchor" href="#面向服务的架构"></a>面向服务的架构</h3><ul><li>Service-Oriented Architecture(SOA)</li><li>可以认为微服务架构是 SOA 的一种特定方法</li></ul><h3 id="其它分解技术"><a class="header-anchor" href="#其它分解技术"></a>其它分解技术</h3><ul><li><p>微服务两个优势</p><ul><li>较小的粒度</li><li>解决问题方法上的更多选择</li></ul></li><li><p>共享库</p><ul><li>无法选择异构的技术</li><li>无法保证弹性</li><li>个人观点：共享库通常业务信息太浓</li></ul></li><li><p>模块</p><ul><li>OSGI：语言对生命周期管理支持不足，模块作者工作很大，进程内模块间耦合太重</li><li>Erlang 在语言层面内支持模块，很强大。但还是无法采用异构的技术，局限性</li><li>模块在实际中会迅速耦合（强烈同意）</li></ul></li><li><p>没有银弹</p></li></ul><h2 id="ch02-演化式架构师"><a class="header-anchor" href="#ch02-演化式架构师"></a>Ch02: 演化式架构师</h2><h3 id="不准确的比较"><a class="header-anchor" href="#不准确的比较"></a>不准确的比较</h3><ul><li>Architect 这个词是有问题的</li><li>建筑领域内，是详细的计划和按部就班的实施</li><li>但在软件领域内，这是不可能的</li></ul><h3 id="架构师的演化视角"><a class="header-anchor" href="#架构师的演化视角"></a>架构师的演化视角</h3><ul><li>大量的需求变更</li><li>使用的工具、技术多样</li><li>发布之后依然在变化</li><li>类比城市规划师，应当聚焦于规划，保证系统适合开发人员在其上工作</li></ul><h3 id="分区"><a class="header-anchor" href="#分区"></a>分区</h3><ul><li>服务边界（对比于城市里的区域）</li><li>应该考虑服务间如何交互，较少关心服务内</li></ul><h3 id="一个原则性方法"><a class="header-anchor" href="#一个原则性方法"></a>一个原则性方法</h3><ul><li><p>战略目标</p><ul><li>通常我们不需要去定义战略目标</li></ul></li><li><p>原则</p><ul><li>为了与目标保持一致，制定一些规则，称为原则</li><li>一般不要超过 10 个</li><li>区分“原则”和“约束”</li></ul></li><li><p>实践</p><ul><li><p>通过实践来保证原则能得到实施</p></li><li><p>通常实践是技术相关的、偏底层的</p></li><li><p>实践应该巩固原则</p><p>如原则：开发团队应该对软件的开发全流程有控制权则对应实践：所有的服务部署在不同的 AWS 帐户中，从而提供资源的自助管理和其它团队的资源隔离</p></li></ul></li><li><p>将原则和实践结合</p><ul><li><p>有时原则和实际会混淆</p><p>如 HTTP/REST 是实践还是原则？</p></li><li><p>重要的是需要有原则指导系统的演化</p></li></ul></li><li><p>Real World Example</p></li></ul><h3 id="要求的标准"><a class="header-anchor" href="#要求的标准"></a>要求的标准</h3><p>在考虑取舍时，要考虑：系统允许多少可变性？如何在优化单个服务自治性的同时，兼顾全局？一种方法是：清楚地定义出一个好服务应用的属性</p><p>换句话说，有什么是系统的所有服务要统一遵守的？</p><ul><li><p>监控</p><ul><li>能够清楚地描绘出跨服务系统的健康状态非常关键</li><li>必须在系统级别而非单个服务级别进行考虑</li><li>建议所有服务使用同样的方法报告健康状态</li><li>Subtopic 4</li></ul></li><li><p>接口</p><ul><li>选用几种少数明确的接口技术有助于新消费者集成</li><li>使用一种或两种接口技术作为标准，不要多</li></ul></li><li><p>架构安全性</p><ul><li><p>必须保证每个服务都可以应对下游服务的错误</p></li><li><p>返回码也应该遵守一定规则</p></li><li><p>处理不同的请求</p><ul><li>正常且正确处理</li><li>错误请求且被系统识别</li><li>被访问的服务宕机，无法判断请求是否正常</li></ul></li></ul></li></ul><h3 id="代码治理"><a class="header-anchor" href="#代码治理"></a>代码治理</h3><ul><li><p>如何保证共识？</p></li><li><p>范例</p><ul><li>理想情况下，范例应该来自真实项目</li></ul></li><li><p>裁剪服务代码模板</p><ul><li>即新服务的核心属性最好是一致、现成的</li><li>对标：maven 的 architecture</li><li>注意：服务模板不是中心化的职责，也不是指导</li><li>重用代码有危险，可能会引入服务间的耦合</li></ul></li></ul><h3 id="技术债务"><a class="header-anchor" href="#技术债务"></a>技术债务</h3><ul><li>有时可能会因为紧急发布某些特性而忽略一些约束，但最终是需要还债的</li><li>架构师需要从更高的层次出发，理解如何做权衡</li><li>理解债务的层次及对系统的影响</li></ul><h3 id="例外管理"><a class="header-anchor" href="#例外管理"></a>例外管理</h3><ul><li>多次对原则的偏离可能意味着需要修改原则</li></ul><h3 id="集中治理和领导"><a class="header-anchor" href="#集中治理和领导"></a>集中治理和领导</h3><ul><li>治理通过评估干系人的需求、当前情况及下一步的可能性来确保企业目标的达成，通过排优先级和做决策来设定方向。对于已经达成一致的方向和目标进行监督</li><li>架构师不应该独自做这些事</li><li>有时架构师不认同小组的决定，最好尊重他们</li></ul><h3 id="建设团队"><a class="header-anchor" href="#建设团队"></a>建设团队</h3><ul><li>重要的是帮助你的队友成长</li></ul><h3 id="小结：架构师的职责"><a class="header-anchor" href="#小结：架构师的职责"></a>小结：架构师的职责</h3><ul><li>愿景：确保系统有一个充分沟通的技术愿景，可能帮助满足客户和组织的需求</li><li>同理心：理解你的决定对客户和同事的影响</li><li>合作：和尽量多的同事沟通，更好地对愿景进行定义、修订和执行。</li><li>适应性：确保在你的客户和组织需求的时候调整技术愿景</li><li>自治性：在标准化和团队自治之间寻找一个正确的平衡点</li><li>治理：确保系统按照技术愿景实现</li></ul><h2 id="ch03-如何建模服务"><a class="header-anchor" href="#ch03-如何建模服务"></a>Ch03: 如何建模服务</h2><h3 id="什么样的服务是好服务"><a class="header-anchor" href="#什么样的服务是好服务"></a>什么样的服务是好服务</h3><ul><li><p>低耦合+高内聚</p></li><li><p>低耦合</p><ul><li>修改一个服务不需要修改另一个服务</li><li>尽可能少地知道其它服务的信息</li></ul></li><li><p>高内聚</p><ul><li>把相关的行为聚在一起，不相关的放在别处</li><li>最好能只在一个地方进行修改，就可以尽快发布</li></ul></li></ul><h3 id="限界上下文"><a class="header-anchor" href="#限界上下文"></a>限界上下文</h3><ul><li><p>一个由显式边界限定的特定职责，类比“细胞”</p></li><li><p>共享的隐藏模型</p><ul><li>同一个名字在不同的上下文中有完全不同的含义</li><li>应当共享特定模型，不应该共享内部表示</li></ul></li><li><p>模块和服务</p><ul><li>一旦发现领域内的限界上下文，一定要用模块对其进行建模，同时共享和隐藏模型</li><li>一般来说，服务应该和限界上下文保持一致</li></ul></li><li><p>过早划分</p><ul><li>很多时候，将一个已有代码库划分成微服务，比重头构建要简单得多</li></ul></li></ul><h3 id="业务功能"><a class="header-anchor" href="#业务功能"></a>业务功能</h3><ul><li>限界上下文应从业务功能出发，而非共享数据</li></ul><h3 id="逐步划分上下文"><a class="header-anchor" href="#逐步划分上下文"></a>逐步划分上下文</h3><ul><li>嵌套上下文 vs 完全分离？</li><li>也许应该根据组织结构决定</li><li>嵌套的另一个好处是方便成块测试</li></ul><h3 id="关于业务概念的沟通"><a class="header-anchor" href="#关于业务概念的沟通"></a>关于业务概念的沟通</h3><h3 id="技术边界"><a class="header-anchor" href="#技术边界"></a>技术边界</h3><ul><li>边界划分时要考虑组织结构（如地理位置）</li></ul><h2 id="ch04-集成"><a class="header-anchor" href="#ch04-集成"></a>Ch04: 集成</h2><h3 id="寻找理想的集成技术"><a class="header-anchor" href="#寻找理想的集成技术"></a>寻找理想的集成技术</h3><ul><li><p>SOAP? XML-RPC? REST? Protocol Buffers?</p></li><li><p>避免破坏性修改</p><ul><li>比如在响应中添加一个字段，已有的消费方不应该受到影响</li></ul></li><li><p>保证 API 的技术无关性</p><ul><li>用以兼容未来的技术</li></ul></li><li><p>隐藏内部的实现细节</p></li></ul><h3 id="共享数据库"><a class="header-anchor" href="#共享数据库"></a>共享数据库</h3><ul><li><p>最快的集成方式</p></li><li><p>暴露了内部实现，后续修改困难</p></li><li><p>消费方与特定技术绑定</p><ul><li>如果今后要使用 NoSQL?</li></ul></li><li><p>行为上，如果隐藏修改的 API？</p><ul><li>修改的逻辑可能散落在各个地方，破坏内聚性</li></ul></li></ul><h3 id="同步与异步"><a class="header-anchor" href="#同步与异步"></a>同步与异步</h3><ul><li>同步一般基于请求/响应</li><li>异步一般基于事件</li></ul><h3 id="编排与协同"><a class="header-anchor" href="#编排与协同"></a>编排与协同</h3><ul><li><p>如何处理跨服务业务流程的逻辑</p></li><li><p>编排(orchestration)：中心化管理</p><ul><li>相当于有一个统一的协调者</li><li>比如规则引擎（商业流程建模软件）</li><li>缺点：编排的任务过于重大</li></ul></li><li><p>协同(chereography)：各自为政</p><ul><li>只触发事件，各方作出各自的响应</li><li>缺点：缺少明确的流程视图</li><li>需要额外工作来监控流程是否正确执行</li><li>总评：能降耦合，但需要跨服务监控，微服务下优先考虑</li></ul></li></ul><h3 id="远程过程调用-rpc"><a class="header-anchor" href="#远程过程调用-rpc"></a>远程过程调用(RPC)</h3><ul><li><p>技术的耦合</p><ul><li>耦合的技术方便使用，解耦的技术方便扩展</li><li>如 Java RMI 只能在 Java 中使用，方便但限定技术栈</li><li>如 Thrift, protocol buffers 能对接各种语言，但使用过程比较繁琐</li></ul></li><li><p>本地调用与远程调用并不相同</p><ul><li><p>RPC 的核心是隐藏远程调用的复杂性</p></li><li><p>封装得太好会导致人们忽略了性能、可靠性</p><p>JPA 也是类似，相比于 Mybatis 封装性更好，更易用，但是也容易过度使用导致性能问题</p></li></ul></li><li><p>脆弱性</p><ul><li>如 Java RMI，添加接口的新方法需要修改所有客户端</li><li>如 Java RMI，仅在服务端删除某个字段会导致序列化和反序列化逻辑不一致，从而导致服务失败</li></ul></li><li><p>RPC 很糟糕吗？</p><ul><li>如果决定使用 RPC，注意：不要对远程调用过度抽象</li></ul></li></ul><h3 id="rest"><a class="header-anchor" href="#rest"></a>REST</h3><ul><li><p>REST 和 HTTP</p><ul><li>它们在一起会更强</li></ul></li><li><p>Hypermedia As The Engine Of Application State(HATEOAS)</p><ul><li>避免客户端和服务端耦合的一个原则</li><li>如 Amazon，用户点击购物车，这是一种隐式约定，即使购物车的真实地址变化，用户还是能找到</li><li>对电子用户而言，我们希望它总是从“商品”找到购买链接，尽管链接会变化，商品本身不变</li><li>缺点是：通信次数比较多</li><li>实践中，可以先让用户自行遍历，有必要时再优化</li></ul></li><li><p>JSON、XML 及其它</p></li><li><p>留心过多的约定</p><ul><li>不要直接暴露内部的对象（转成 JSON）</li></ul></li><li><p>基于 HTTP 的 REST 的缺点</p><ul><li>易用性：无法生成客户端的 stub 代码</li><li>有些 Web 框架无法很好地支持所有的 HTTP 动词</li><li>性能上：性能不如二进制协议（如 Thrift），不适用于低延迟的通信</li></ul></li></ul><h3 id="实现基于事件的异步协作方式"><a class="header-anchor" href="#实现基于事件的异步协作方式"></a>实现基于事件的异步协作方式</h3><ul><li><p>技术选择</p><ul><li><p>发布事件和接收事件的机制</p></li><li><p>如 RabbitMQ 的消费代理</p><ul><li>能够处理发布和接收的问题</li><li>同时还能对消息进行管理追踪</li><li>代价是增加开发复杂度，因为需要额外中间件</li><li>尽量保持中间件简单，把业务逻辑放在自己的服务里</li></ul></li><li><p>通过 HTTP 传播事件</p><ul><li>例如 ATOM 协议（feed)</li><li>有事件时发布到该聚合上，消费者会轮询</li></ul></li></ul></li><li><p>异步架构的复杂性</p><ul><li><p>复杂性，不仅来源于发布、订阅操作</p></li><li><p>银行系统的示例</p><ul><li>如何处理消费者故障？</li><li>如何处理失败消息？最大重试次数？死信队列？</li><li>简评：异步架构看似各自为政，但会隐藏一些全局的需求。这些需求恰恰是复杂性的来源</li></ul></li></ul></li></ul><h3 id="服务即状态机"><a class="header-anchor" href="#服务即状态机"></a>服务即状态机</h3><ul><li>将领域的生命周期显示建模</li><li>不仅是对 CRUD，也对状态转换封装一些行为</li></ul><h3 id="响应式扩展-reactive-extensions-rx"><a class="header-anchor" href="#响应式扩展-reactive-extensions-rx"></a>响应式扩展(Reactive Extensions, Rx)</h3><ul><li>组装一个或多个异步调用，简化代码</li><li>简评：异步是坑，Think Twice</li></ul><h3 id="微服务中的-dry-和代码重用的危险"><a class="header-anchor" href="#微服务中的-dry-和代码重用的危险"></a>微服务中的 DRY 和代码重用的危险</h3><ul><li>个人认为 DRY 抽取重复代码是增加内聚性的过程，不需要修改多个地方</li><li>共享代码会导致微服务间的耦合，一处修改会影响多个服务</li><li>经验法则：微服务内 DRY，跨服务适当违反</li></ul><h3 id="按引用访问"><a class="header-anchor" href="#按引用访问"></a>按引用访问</h3><ul><li>领域实体的生命周期应当只在某个服务内管理</li><li>如果保存本地副本，应该保留原始实体的引用，方便后续查询，更新</li><li>需要知道事件是否发生，还需要知道发生了什么</li><li>具体是否引用要看场景，是否数据切片能满足要求</li></ul><h3 id="版本管理"><a class="header-anchor" href="#版本管理"></a>版本管理</h3><ul><li><p>尽可能推迟</p><ul><li><p>采用一些耦合小的技术（如 REST 而非数据库集成）</p></li><li><p>鼓励客户端的正确行为</p><ul><li>宽进严出（对自己发送的东西要严格，对接收的东西要宽容）</li></ul></li></ul></li><li><p>及早发现破坏性修改</p></li><li><p>使用语义化的版本管理</p><ul><li>MAJOR.MINOR.PATCH</li><li>个人觉得并没有什么用</li></ul></li><li><p>不同的接口共存</p><ul><li>平滑过渡</li></ul></li><li><p>同时使用多个版本的服务</p><ul><li>坏处：老版本永远不会升级</li></ul></li></ul><h3 id="用户界面"><a class="header-anchor" href="#用户界面"></a>用户界面</h3><ul><li><p>是否轻界面，重后端</p></li><li><p>走向数字化</p><ul><li>API 的粒度，细 vs 粗</li></ul></li><li><p>约束</p><ul><li>如移动端的带宽、电量等的影响</li></ul></li><li><p>API 组合（让 UI 直接访问 API）</p><ul><li>不同的设备可能需要不同的数据，一个解决方案是允许客户选择字段（如 GraphQL?）</li><li>谁来创建 UI？如果是不同团队，会回到分层合并的模式，则细微的修改都需要多个团队参与</li></ul></li><li><p>UI 版本的组合：服务直接暴露部分 UI，上层应用对其进行组合</p></li><li><p>为前端服务的后端：即增加一层代理，将细粒度 API 拼接成粗粒度，提供给前端</p><ul><li>问题是最终代理层会变得巨大无比</li></ul></li><li><p>混合方式</p></li></ul><h3 id="与第三方软件集成"><a class="header-anchor" href="#与第三方软件集成"></a>与第三方软件集成</h3><ul><li><p>缺乏控制</p></li><li><p>定制化</p><ul><li>一般购买的定制化成本很大</li></ul></li><li><p>在自己可控的平台上进行定制化</p><ul><li>把三方软件当成服务，以此为基础搭建自己的系统</li></ul></li><li><p>绞杀者模式</p><ul><li>拦截对三方系统的应用，路由部分到新系统</li></ul></li></ul><h2 id="ch05-分解单块系统"><a class="header-anchor" href="#ch05-分解单块系统"></a>Ch05: 分解单块系统</h2><p>服务怎么拆？拆了怎么办？源头是业务，找到上下文的边界。拆的过程中很可能最终发现数据库层面的耦合。拆成服务后可能会遇到分布式事务的要求还有一些跨数据库（报告）的需求和方法。</p><h3 id="关键是接缝"><a class="header-anchor" href="#关键是接缝"></a>关键是接缝</h3><ul><li>从接缝处抽取相对独立的代码，对其修改不影响其它部分</li><li>尝试找到服务的边界</li></ul><h3 id="分解单块系统的原因"><a class="header-anchor" href="#分解单块系统的原因"></a>分解单块系统的原因</h3><ul><li><p>改变的速度</p><ul><li>抽成服务，加速后期开发</li></ul></li><li><p>团队结构</p></li><li><p>安全</p></li><li><p>技术</p><ul><li>可以用其它的技术栈</li></ul></li></ul><h3 id="杂乱的依赖"><a class="header-anchor" href="#杂乱的依赖"></a>杂乱的依赖</h3><ul><li>经常会发现：数据库是所有杂乱依赖的源头</li></ul><h3 id="找到问题的关键"><a class="header-anchor" href="#找到问题的关键"></a>找到问题的关键</h3><ul><li>即找到服务对数据库的交叉使用</li></ul><h3 id="例子：打破外键关系"><a class="header-anchor" href="#例子：打破外键关系"></a>例子：打破外键关系</h3><ul><li>把外键变成服务调用</li></ul><h3 id="例子：共享静态数据"><a class="header-anchor" href="#例子：共享静态数据"></a>例子：共享静态数据</h3><ul><li>例如：国家代码等数据</li><li>方法一：为每个包复制一份</li><li>方法二：静态数据放入代码（属性文件、枚举）</li><li>方法三：静态数据作为单独服务</li></ul><h3 id="例子：共享-可变-数据"><a class="header-anchor" href="#例子：共享-可变-数据"></a>例子：共享（可变）数据</h3><ul><li>原因：领域概念在数据库中隐式建模</li><li>示例中可以将这个对数据的交叉抽离成新的服务</li></ul><h3 id="例子：共享表"><a class="header-anchor" href="#例子：共享表"></a>例子：共享表</h3><ul><li>如：Catalog 中的条目与电子记录的条目存放在通用条目表</li><li>方法：拆成两个表</li></ul><h3 id="重构数据库"><a class="header-anchor" href="#重构数据库"></a>重构数据库</h3><ul><li>推荐在分离服务前先分离数据库结构</li><li>逐步进行：单块服务+单表 -&gt; 单块服务 + 分离表 -&gt; 分离服务+分离表</li></ul><h3 id="事务边界"><a class="header-anchor" href="#事务边界"></a>事务边界</h3><ul><li><p>Retry Later</p><ul><li>最终一致性</li></ul></li><li><p>Abort</p><ul><li>补偿事务抵消之前的操作</li><li>多个服务下如何处理？</li></ul></li><li><p>分布式事务</p><ul><li>2PC</li></ul></li><li><p>太复杂怎么办？</p><ul><li>业务是否需要一致？ double check</li><li>能否从业务上做处理？而不是技术</li></ul></li></ul><h3 id="分离数据库后如何做报告"><a class="header-anchor" href="#分离数据库后如何做报告"></a>分离数据库后如何做报告</h3><ul><li><p>报告生成需要跨数据库/表访问</p></li><li><p>定期同步到报告数据库</p><ul><li>表结构修改怎么办</li></ul></li><li><p>通过服务调用获取数据</p><ul><li>只适用于少量数据，长时间同期的数据量太大</li><li>批量 API 将结果写入文件</li></ul></li><li><p>推送数据到报告系统（ELK）</p><ul><li>直接对数据库操作</li></ul></li><li><p>导出事件数据</p><ul><li>低耦合</li><li>比较难应对大数据量</li></ul></li><li><p>数据导出的备份</p><ul><li>持久化数据备份+Hadoop</li></ul></li></ul><h3 id="修改的代价"><a class="header-anchor" href="#修改的代价"></a>修改的代价</h3><ul><li>修改的量越大风险越大</li><li>在影响最小的地方犯错误（白板）</li></ul><h2 id="ch06-部署"><a class="header-anchor" href="#ch06-部署"></a>Ch06: 部署</h2><h3 id="持续集成简介"><a class="header-anchor" href="#持续集成简介"></a>持续集成简介</h3><ul><li>是否每天合并代码到主线？</li><li>是否有测试来验证修改？</li><li>构建失败后，修复 CI 是否是团队的头等大事？</li></ul><h3 id="ci-应用到微服务"><a class="header-anchor" href="#ci-应用到微服务"></a>CI 应用到微服务</h3><ul><li><p>单仓库、单构建</p><ul><li>问题是一次性部署多个服务</li><li>粒度太粗，影响 CI 周期，不易定位发生修改的服务</li></ul></li><li><p>单仓库、多构建</p><ul><li>缺点：代码粒度太粗，一个项目小修改 CI 的失败会卡其它项目的 CI</li></ul></li><li><p>多仓库、多构建</p></li></ul><h3 id="pipeline-与-ci"><a class="header-anchor" href="#pipeline-与-ci"></a>pipeline 与 CI</h3><ul><li><p>评：pipeline 可以将测试粒度变细，fail fast</p></li><li><p>例外：团队刚开始的时候应该先用单仓库、单构建</p><ul><li>开始时不容易分辨边界</li><li>开始时容易有跨服务的修改</li><li>但只能是过渡</li></ul></li></ul><h3 id="artifact"><a class="header-anchor" href="#artifact"></a>Artifact</h3><ul><li><p>Platform specific Artifact</p><ul><li>Ruby gem, Java jar/war, Python egg</li><li>构建物可能不够，还需要中间件和其它配置</li><li>考虑用 puppet, chef, ansible 管理</li></ul></li><li><p>OS specific artifact</p><ul><li>rpm, deb, MSI</li><li>好处多多，写构建脚本比较困难，且平台支持不一</li></ul></li><li><p>定制化镜像</p><ul><li>构建镜像会花费大量时间</li><li>镜像可能很大</li></ul></li><li><p>将镜像作为 artifact</p></li><li><p>Immutable Server</p><ul><li>配置漂移：如果有人登录服务器修改了配置呢？</li></ul></li></ul><h3 id="环境"><a class="header-anchor" href="#环境"></a>环境</h3><ul><li>耗时测试、UAT、性能测试、生产</li><li>环境要保持一致，否则会有预期之外的情况</li></ul><h3 id="服务配置"><a class="header-anchor" href="#服务配置"></a>服务配置</h3><ul><li>尽量各环境的配置保持一致</li></ul><h3 id="服务与主机的映射"><a class="header-anchor" href="#服务与主机的映射"></a>服务与主机的映射</h3><ul><li><p>“每台机器应该有多少服务”？</p></li><li><p>单主机、多服务</p><ul><li>主机管理工作量小</li><li>管理工作量不随服务增长而增长</li><li>监控困难</li><li>服务部署也会更复杂，难以保证服务不相互影响</li><li>不利于团队自治性</li><li>虚拟技术的发展，不太应该继续这样</li></ul></li><li><p>应用程序容器(tomcat, glassfish,…)</p></li><li><p>每个主机一个服务</p></li><li><p>PaaS</p><ul><li>如果出错比较难排查</li><li>一些特定的要求比较难满足</li></ul></li></ul><h3 id="自动化"><a class="header-anchor" href="#自动化"></a>自动化</h3><ul><li>自动化管理是微服务的必经之路</li></ul><h3 id="从物理机到虚拟机"><a class="header-anchor" href="#从物理机到虚拟机"></a>从物理机到虚拟机</h3><ul><li><p>传统的虚拟化技术</p><ul><li>一般不做，虚拟化会有额外的开销</li></ul></li><li><p>Vagrant</p><ul><li>开发机上资源消耗大</li></ul></li><li><p>Linux 容器</p><ul><li>如 LXC</li><li>更轻量</li><li>并不是真正的隔离</li></ul></li><li><p>Docker</p><ul><li>构建于容器之上的平台</li></ul></li></ul><h3 id="一个部署接口"><a class="header-anchor" href="#一个部署接口"></a>一个部署接口</h3><ul><li>最佳实践是有一个统一的接口来部署服务</li><li>服务的名字、版本、哪个环境</li></ul><h2 id="ch07-测试"><a class="header-anchor" href="#ch07-测试"></a>Ch07: 测试</h2><h3 id="测试类型"><a class="header-anchor" href="#测试类型"></a>测试类型</h3><ul><li>单元测试（是否正确实现功能）</li><li>非功能性测试（响应、扩展、性能、安全）</li><li>验收测试（是否实现了正确的功能）</li><li>探索性测试（如何破坏系统）</li></ul><h3 id="测试范围-金字塔"><a class="header-anchor" href="#测试范围-金字塔"></a>测试范围（金字塔）</h3><ul><li><p>用户界面</p><ul><li>范围最大、信心最足、最难定位</li></ul></li><li><p>服务测试</p><ul><li>绕开界面，直接对服务测试</li><li>测试单独的服务可以提高测试的隔离性</li><li>为了达到要求，需要 stub</li></ul></li><li><p>单元测试</p><ul><li>TDD</li><li>不会启动服务</li><li>外部文件、网络连接访问有限</li><li>对重构非常重要</li></ul></li><li><p>比例</p><ul><li>经验：下层比上层多一个数量级</li></ul></li></ul><h3 id="实现服务测试"><a class="header-anchor" href="#实现服务测试"></a>实现服务测试</h3><ul><li><p>Mock vs Stub?</p><ul><li>这两个概念可能跟我们平时的用法不一样</li><li>这里 stub 无副作用，mock 有</li><li>stub 用得多</li></ul></li></ul><h3 id="端到端测试"><a class="header-anchor" href="#端到端测试"></a>端到端测试</h3><ul><li><p>微秒的端到端测试</p><ul><li>界面依赖多个服务，当前服务依赖的其它服务也有新版本，测试时要用什么组合？</li><li>不同服务的测试要重合，要重复测试吗？</li><li>一种方法是让每个服务“扇入”到端到端测试</li></ul></li><li><p>脆弱的测试</p><ul><li><p>存在一些非功能错误无法识别（如底层服务未响应）</p></li><li><p>谁来写测试？</p></li><li><p>测试多长时间？</p></li><li><p>测试量大大，可能产生大量堆积</p></li><li><p>元版本</p><ul><li>会产生为所有服务给一个统一的版本号</li><li>这样就回到了单块架构</li></ul></li></ul></li><li><p>测试场景、而不是故事</p><p>这个概念和之前的理解有出入</p><ul><li>核心端到端，其余在服务测试中覆盖</li></ul></li><li><p>消费者驱动的测试</p><ul><li>端到端测试解决问题：修改不破坏消费者</li><li>另一种方式：CDC(Consumer-Driven Contract 消费者驱动的契约)</li><li>即定义消费者的期望，并转化成测试代码，进入 CI pipeline</li><li>Pact: 一个 CDC 测试工具</li><li>CDC 与 story 一样有助于沟通</li></ul></li><li><p>还要做端到端测试吗？</p><ul><li>评：在业务还在强烈变化时，个人认为还是需要的，优化点在于有多少可以转移成 CDC</li></ul></li></ul><h3 id="部署后再测试"><a class="header-anchor" href="#部署后再测试"></a>部署后再测试</h3><ul><li><p>区分部署和上线</p><ul><li>部署后不一定立马切流量，切流量才是上线</li></ul></li><li><p>Canary Releasing</p><ul><li>小流量测试</li></ul></li><li><p>平均修复时间 胜于 平均故障时间</p><ul><li>平均故障间隔时间 (Mean Time Between Failures, MTBF)</li><li>平均修复时间 (Mean Time To Prepare, MTTP)</li><li>MTBF 是指两次故障之间正常工作时间的均值，需要靠更多的测试，而 MTTP 指出现故障平均花多长时间修复。这两者是需要平衡的</li></ul></li></ul><h3 id="非功能性需求-性能-用户-稳定"><a class="header-anchor" href="#非功能性需求-性能-用户-稳定"></a>非功能性需求（性能、用户、稳定……）</h3><ul><li>频率可能更小，但一定要做，不能拖到上生产</li></ul><h2 id="ch08-监控"><a class="header-anchor" href="#ch08-监控"></a>Ch08: 监控</h2><p>小结：要做监控，要标准化做法手段：传递唯一标识最低限度：服务的响应时间最你限度：下游的健康状态</p><h3 id="单一服务-单一服务器"><a class="header-anchor" href="#单一服务-单一服务器"></a>单一服务、单一服务器</h3><ul><li><p>主机本身：CPU、内存等主机数据</p><ul><li>如 Nagios 工具或 New Relic 托管服务</li></ul></li><li><p>服务器本身的日志</p><ul><li>rogrotate 移除旧日志</li></ul></li></ul><h3 id="单一服务-多服务器"><a class="header-anchor" href="#单一服务-多服务器"></a>单一服务、多服务器</h3><ul><li>应用场景：负载均衡</li><li>除了查看所有主机的数据，也需要查看单个主机的数据</li><li>如果只有几个主机，可以使用 ssh-multiplexers</li><li>响应时间可以看负载均衡器中的聚合数据</li></ul><h3 id="多个服务-多个服务器"><a class="header-anchor" href="#多个服务-多个服务器"></a>多个服务、多个服务器</h3><ul><li>是系统问题？服务问题？是哪个服务？</li><li>回答：集中收集和聚合尽可能多的数据</li></ul><h3 id="日志-日志-更多的日志"><a class="header-anchor" href="#日志-日志-更多的日志"></a>日志、日志、更多的日志</h3><ul><li>新需求：日志收集子系统</li><li>例如 logstash、Kibana</li></ul><h3 id="多个服务的指标跟踪"><a class="header-anchor" href="#多个服务的指标跟踪"></a>多个服务的指标跟踪</h3><ul><li><p>有了日志后，最好能生成指标方便追踪</p></li><li><p>Graphite 系统</p><ul><li>接收指标并展示</li><li>通过有效配置，聚合数据减少存储容量</li><li>跨样本做聚合</li></ul></li></ul><h3 id="服务指标"><a class="header-anchor" href="#服务指标"></a>服务指标</h3><ul><li><p>collectd 生成操作系统的大量指标</p></li><li><p>Nginx, Varnish 支撑系统也会暴露有用的信息</p></li><li><p>自己服务的指标呢？</p><ul><li>Metrics 库</li></ul></li></ul><h3 id="综合监控"><a class="header-anchor" href="#综合监控"></a>综合监控</h3><ul><li>Naive 的监控：设定一个标准值，超过报警</li><li>示例：定期插入假事件，并判断是否被处理，更贴近最终的监控需求</li><li>合成事务执行语义监控，比使用低层指标更能表明问题</li><li>在生产系统上执行端到端测试（保证无副作用）</li></ul><h3 id="关联标识"><a class="header-anchor" href="#关联标识"></a>关联标识</h3><ul><li>用 GUID 给请求打标识，并传递给后续所有系统</li><li>Zipkin</li><li>使用包装的客户端确保信息不会丢失</li></ul><h3 id="级联"><a class="header-anchor" href="#级联"></a>级联</h3><ul><li>上游需要确认下游服务的健康状态并打日志</li><li>添加断路器更加优雅地处理</li></ul><h3 id="标准化"><a class="header-anchor" href="#标准化"></a>标准化</h3><ul><li>以标准的方式暴露监控接口、落日志</li></ul><h2 id="ch09-安全"><a class="header-anchor" href="#ch09-安全"></a>Ch09: 安全</h2><h3 id="身份验证和授权"><a class="header-anchor" href="#身份验证和授权"></a>身份验证和授权</h3><ul><li><p>人或事，抽象为“主体”(Principle)</p></li><li><p>常见的单点登录（SSO）实现</p><ul><li>SAML, OpenID Connect</li><li>OAuth 2.0</li></ul></li><li><p>单点登录网关</p><ul><li>网关接收请求，如果已授权，则将主体信息放在 HTTP Header 信息中，如果未授权，则由网关进行授权</li><li>孤立地在微服务中定位问题会更难（包括生产环境的搭建）</li><li>虚假的安全感：如果网关服务故障了……</li><li>小心网关变成耦合点</li></ul></li><li><p>细粒度的授权</p><ul><li>细粒度的 Authorization 应该留给具体服务</li></ul></li></ul><h3 id="服务间的身份验证和授权"><a class="header-anchor" href="#服务间的身份验证和授权"></a>服务间的身份验证和授权</h3><ul><li><p>在边界内允许一切</p><ul><li>风险：当有人入侵网络后，系统对中间人攻击没有任何防备</li><li>许多组织使用，但其实有许多风险，更糟糕的是，很多时候人们没有意识到风险</li></ul></li><li><p>HTTP(s) Basic Authentication</p><ul><li>在 HEADER 中指定用户名密码</li><li>HTTP 会被中间人截取明文</li><li>HTTPS 的证书管理复杂（尤其是多台机器）</li><li>流量无法被反向代理缓存，但可以在反向代理时转成 HTTP 流量</li><li>如何和现有 SSO 集成？</li></ul></li><li><p>SAML 或 OpenID Connect</p><ul><li>同一个网关来路由内部流量</li><li>微服务的客户端有一组凭证，用于验证自身，服务获取所需信息，用于细粒度验证</li><li>需要为每个微服务创建自己的凭证，可撤销</li><li>缺点：需要客户端安全地存储凭证</li></ul></li><li><p>客户端证书</p><ul><li>每个客户端存储一个 X.509 证书，与服务端建立通信</li><li>缺点：管理证书的工作很繁重</li></ul></li><li><p>HTTP 上的 HMAC</p><ul><li>防止密码泄露</li><li>即传输的是哈希后的内容，服务端独立算哈希</li><li>好处 1 ：如果哈希不匹配，则得知中间人篡改过</li><li>好处 2: 密钥不泄露</li><li>好处 2: 开销低于 HTTPS</li><li>缺点 1: 需要共享密钥，不好撤销</li><li>缺点 2: 它是一个模式，不是标准，实现不一</li><li>缺点 3: 它只保证密码不泄露，其它信息依旧可能被嗅探</li></ul></li><li><p>API 密钥 (token)</p><ul><li>具体如何使用取决于使用的具体技术</li><li>常见方法：使用公钥私钥对，并集中管理</li><li>该方法关注了程序的易用性</li></ul></li><li><p>代理问题</p><ul><li><p>服务提供方是允许代理方访问服务？</p><ul><li>混淆代理人问题：欺诈代理人去访问本不该是自己能访问的服务。服务提供方是否</li></ul></li><li><p>一种方法是让代理/路由做验证</p></li><li><p>另一种方法：请求时传递主体凭证</p></li><li><p>没有简单的答案</p></li></ul></li></ul><h3 id="静态数据的安全"><a class="header-anchor" href="#静态数据的安全"></a>静态数据的安全</h3><ul><li><p>防止网络被攻破，静态数据被窃取</p></li><li><p>使用众所周知的加密方法</p><ul><li>AES</li><li>密码哈希加盐</li></ul></li><li><p>一切皆与密钥相关</p><ul><li>密码不应和密文存储在一起</li><li>方案一：单独的安全设备来加密和解密</li><li>方案二：单独的密钥库</li></ul></li><li><p>选择你的目标</p><ul><li>考虑哪些数据可以被放入日志，帮助识别哪些数据需要加密</li></ul></li><li><p>按需解密</p></li><li><p>加密备份</p><ul><li>备份加密数据</li><li>确保备份也被加密</li></ul></li></ul><h3 id="深度-防御"><a class="header-anchor" href="#深度-防御"></a>深度防御</h3><ul><li><p>防火墙</p></li><li><p>日志</p><ul><li>可以检测异常、之后恢复</li><li>要小心在日志中存储敏感信息</li></ul></li><li><p>入侵检测（和预防）系统</p></li><li><p>网络隔离</p></li><li><p>操作系统</p></li></ul><h3 id="保持节俭"><a class="header-anchor" href="#保持节俭"></a>保持节俭</h3><ul><li>有些信息是不需要存储的</li></ul><h3 id="黄金法则"><a class="header-anchor" href="#黄金法则"></a>黄金法则</h3><ul><li>不要自己实现加密算法</li></ul><h3 id="内建安全"><a class="header-anchor" href="#内建安全"></a>内建安全</h3><ul><li>相应的安全意识、流程</li><li>自动化工具探测系统漏洞</li></ul><h3 id="外部验证"><a class="header-anchor" href="#外部验证"></a>外部验证</h3><ul><li>开发人员离问题太近导致可能发现不了问题</li></ul><h2 id="ch10-康威定律和系统设计"><a class="header-anchor" href="#ch10-康威定律和系统设计"></a>Ch10: 康威定律和系统设计</h2><h3 id="康威定律"><a class="header-anchor" href="#康威定律"></a>康威定律</h3><ul><li>任何组织在设计一套系统（广义）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致</li><li>“如果你有四个小组开发一个编译器，那你会得到一个四步编译器”</li></ul><h3 id="证据"><a class="header-anchor" href="#证据"></a>证据</h3><ul><li><p>松耦合组织和紧耦合组织</p><ul><li>紧耦合组织：商业产品公司，所有员工一起工作</li><li>松耦合组织：开源社区</li><li>组织的耦合度越低，模块化越好，耦合度越低</li></ul></li><li><p>Windows Vista</p><ul><li>组织结构相关的指标与软件质量的相关度最高</li></ul></li><li><p>Netflix 和 Amazon</p><ul><li>“两个比萨团队”，没有团队应该大到两个比萨不够吃</li></ul></li></ul><h3 id="适应沟通途径"><a class="header-anchor" href="#适应沟通途径"></a>适应沟通途径</h3><ul><li>当协调成本增加后，人们要么设法降低成本，要么停止更改数据</li></ul><h3 id="服务所有权"><a class="header-anchor" href="#服务所有权"></a>服务所有权</h3><ul><li>所有权程度的增加会增加自治和交付速度</li></ul><h3 id="共享服务的原因"><a class="header-anchor" href="#共享服务的原因"></a>共享服务的原因</h3><ul><li><p>难以分割</p><ul><li>拆分成本太高</li></ul></li><li><p>特性团队</p><ul><li>小团队负责一系列我需要的所有功能，即使功能跨组件（甚至服务）</li><li>大范围采用特性团队后，所有服务都是共享的</li><li>微服务根据业务领域划分而非技术，更容易进行以特性为导向的开发</li></ul></li><li><p>交付瓶颈</p><ul><li>如果某个服务突然出现大量的变量需求？</li></ul></li></ul><h3 id="内部开源"><a class="header-anchor" href="#内部开源"></a>内部开源</h3><ul><li><p>守护者角色</p><ul><li>核心团队+不受信任的提交者</li></ul></li><li><p>成熟</p><ul><li>往往 1.0 后才接受外部提交</li></ul></li><li><p>工具</p><ul><li>版本控制、CI、CD</li></ul></li></ul><h3 id="限界上下文和团队结构"><a class="header-anchor" href="#限界上下文和团队结构"></a>限界上下文和团队结构</h3><ul><li>可能的话，团队结构和限界上下文保持一致</li></ul><h3 id="孤儿服务"><a class="header-anchor" href="#孤儿服务"></a>孤儿服务</h3><ul><li>长时间不需要更改的服务</li></ul><h3 id="反向的康威定律"><a class="header-anchor" href="#反向的康威定律"></a>反向的康威定律</h3><ul><li>系统设计能改变组织结构吗？</li></ul><h3 id="人"><a class="header-anchor" href="#人"></a>人</h3><ul><li>“不管一开始看起来是什么样，它永远是人的问题”</li></ul><h2 id="ch11-规模化微服务"><a class="header-anchor" href="#ch11-规模化微服务"></a>Ch11: 规模化微服务</h2><h3 id="故障无处不在"><a class="header-anchor" href="#故障无处不在"></a>故障无处不在</h3><ul><li>大规模后的故障是必然发生的</li><li>即使买最好的工具、最昂贵的硬件也必然发生</li><li>少花些精力在阻止故障发生，而想办法从故障中恢复</li></ul><h3 id="多少是太多"><a class="header-anchor" href="#多少是太多"></a>多少是太多</h3><ul><li><p>系统的非功能性需求取决于用户</p><ul><li>如内部系统的自动扩容可能无意义</li></ul></li><li><p>理解以下需求</p><p>在现场交付时，需要先量化这些指标</p><ul><li><p>响应时间/延迟</p><ul><li>如：200 并发下，90%的响应在 2s 内</li></ul></li><li><p>可用性</p><ul><li>能接受服务出现故障吗？</li></ul></li><li><p>数据持久性</p><ul><li>多大比较的数据丢失是可以接受的</li><li>数据应该保存多久</li></ul></li></ul></li></ul><h3 id="功能降级"><a class="header-anchor" href="#功能降级"></a>功能降级</h3><ul><li><p>依赖多个服务时，不能因为一个系统宕机导致整个调用链都失败（否则可用性和单块系统没区别）</p></li><li><p>具体的决策依赖业务</p><ul><li>有些服务是致命的，有些则是可以绕过的</li></ul></li></ul><h3 id="架构性安全措施"><a class="header-anchor" href="#架构性安全措施"></a>架构性安全措施</h3><ul><li>目标：确保如果真的出错，不会引起严重的级联影响</li><li>处理慢下游比处理宕机下游要难得多</li></ul><h3 id="反脆弱的组织"><a class="header-anchor" href="#反脆弱的组织"></a>反脆弱的组织</h3><ul><li><p>Netflix 通过引发故障来确保系统的容错</p></li><li><p>Chaos Monkey</p><ul><li>随机停掉服务器或机器（生产环境）</li></ul></li><li><p>拥抱故障</p></li><li><p>如何应对？</p><ul><li><p>超时</p><ul><li>给所有跨进程的调用都加上超时</li></ul></li><li><p>断路器</p><ul><li>被动 &amp; 手动</li><li>被动断路器依赖于业务定义</li></ul></li><li><p>舱壁</p><ul><li>必要情况下可以“自闭”</li><li>例如为每个下游服务的连接使用不同连接池</li><li>例如将功能分离成独立的微服务</li><li>可以把断路器作为密封舱壁的自动机制</li></ul></li><li><p>隔离</p><ul><li>在实现上游时，允许下游服务离线</li></ul></li></ul></li></ul><h3 id="幂等"><a class="header-anchor" href="#幂等"></a>幂等</h3><ul><li><p>多次调用的效果与一次调用相同</p></li><li><p>实际要完全实现幂等挺困难</p><ul><li>如需要保存已经处理的事件</li><li>多个 worker 可能在窗口内会处理多个事件</li></ul></li></ul><h3 id="扩展-scale"><a class="header-anchor" href="#扩展-scale"></a>扩展(scale?)</h3><ul><li><p>防止单点故障，负载加强性能</p></li><li><p>更强大的主机（垂直扩展）</p></li><li><p>拆分负载</p><ul><li>之前在单机上的微服务拆分到多机上</li></ul></li><li><p>分散风险</p><ul><li>“两地三机房”</li></ul></li><li><p>负载均衡</p><ul><li>避免单点故障</li><li>SSL 终止</li></ul></li><li><p>基于 worker 的系统</p><ul><li>即任务提交到队列，由 worker 运行</li><li>woker 本身不需要很高的可靠性，但任务队列需求</li></ul></li><li><p>重新设计</p><ul><li>最初的架构可能无法应对很大负载</li></ul></li></ul><h3 id="扩展数据库"><a class="header-anchor" href="#扩展数据库"></a>扩展数据库</h3><ul><li><p>（单点）瓶颈到了数据库上</p></li><li><p>区分“可用性”和“数据的持久性”</p><ul><li>例如对数据库备份，数据不丢，但服务不可用</li></ul></li><li><p>扩展读取</p><ul><li>只读复本（如 MySQL 主从）</li><li>最终一致性</li></ul></li><li><p>扩展写操作</p><ul><li><p>分片</p><ul><li>分片如何处理跨分片查询？</li><li>如何添加新节点？</li><li>写入分片可能会扩展写容量，但不会提高弹性</li><li>一致性哈希</li></ul></li></ul></li><li><p>共享数据库基础设施</p></li><li><p>CQRS</p><ul><li>读写分离</li><li>Event Sourcing</li></ul></li></ul><h3 id="缓存"><a class="header-anchor" href="#缓存"></a>缓存</h3><ul><li><p>HTTP 协议本身允许缓存(GET)</p></li><li><p>客户端、代理、服务器缓存</p></li><li><p>HTTP 缓存(cache)</p><ul><li><p>Cache-control + Expires</p><ul><li>一般适用于静态资源</li></ul></li><li><p>ETag</p></li></ul></li><li><p>写缓存(buffer)</p><ul><li><p>writebehind 缓存</p><ul><li>类比操作系统写入磁盘前缓存在内存</li></ul></li></ul></li><li><p>为弹性使用缓存(buffer)</p><ul><li>下游失效时先缓存请求</li></ul></li><li><p>隐藏源服务</p><ul><li>缓存雪崩，缓存服务宕机，导致大量请求打到源服务</li><li>一种方法：第一时间不要对源服务发起请求</li><li>源服务定期填写缓存，客户端在 miss 时发布通知</li></ul></li><li><p>保持简单</p><ul><li>不需要不要用</li></ul></li><li><p>缓存可能中毒</p></li></ul><h3 id="自动伸缩"><a class="header-anchor" href="#自动伸缩"></a>自动伸缩</h3><ul><li>响应型伸缩</li><li>预测型伸缩</li><li>事实上比起响应负载，更多应用于响应故障</li></ul><h3 id="cap"><a class="header-anchor" href="#cap"></a>CAP</h3><ul><li>CP 还是 AP？P 是一定需要的</li><li>对于具体的服务，要求可能不同</li></ul><h3 id="服务发现"><a class="header-anchor" href="#服务发现"></a>服务发现</h3><ul><li><p>DNS</p><ul><li>标准</li><li>更新很痛苦（TTL）</li><li>DNS 指向负载均衡</li></ul></li><li><p>动态服务注册</p><ul><li>ZK</li><li>Consul</li><li>Eureka</li></ul></li><li><p>自己构建</p></li><li><p>别忘了人的需求（查看、监控）</p></li></ul><h3 id="文档服务"><a class="header-anchor" href="#文档服务"></a>文档服务</h3><ul><li>API 文档</li><li>Swagger</li><li>HAL 和 HAL 浏览器</li><li>自描述系统（UDDI)</li></ul><h2 id="ch12-总结"><a class="header-anchor" href="#ch12-总结"></a>Ch12: 总结</h2><h3 id="微服务原则"><a class="header-anchor" href="#微服务原则"></a>微服务原则</h3><ul><li><p>围绕业务概念建模</p></li><li><p>接受自动化文化</p></li><li><p>隐藏内部实现细节</p></li><li><p>一切去中心化</p></li><li><p>可独立部署（不影响当前服务）</p></li><li><p>隔离失败</p><ul><li>不要像使用本地调用那样处理远程调用</li><li>反脆弱信条</li></ul></li><li><p>高度可观察</p><ul><li>日志、监控</li></ul></li></ul><h3 id="什么时候不使用"><a class="header-anchor" href="#什么时候不使用"></a>什么时候不使用</h3><ul><li>不了解领域，无法很好做拆分</li><li>基础设施不完善前</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简评：&lt;a href=&quot;https://www.amazon.cn/dp/B01M3VNAYQ/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这本书&lt;/a&gt;是很“宽”的一本书，描述了许多构建微服务中将面临的挑战，不过大多数知识点还是点到为止。个人觉得适合有一定基础的读者，能扩展知识的宽度，之后再针对其中的知识点深造。&lt;/p&gt;
&lt;p&gt;本文是读书笔记，由 XMind 导出（&lt;a href=&quot;/2020/Book-Notes-Building-Microservices/building-microservices.xmind&quot;&gt;XMind 源文件
&lt;/a&gt;）。 不建议阅读。&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="https://lotabout.me/categories/Reading/"/>
    
    
      <category term="Book" scheme="https://lotabout.me/tags/Book/"/>
    
      <category term="MicroService" scheme="https://lotabout.me/tags/MicroService/"/>
    
  </entry>
  
</feed>
