<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content=" R: 4.3.2 (2023-10-31) R studio: 2023.12.1+402 (2023.12.1+402)\nChoice modeling æ˜¯ä¸€ç§å¸‚åœºç ”ç©¶æ–¹æ³•ï¼Œç”¨äºç†è§£æ¶ˆè´¹è€…åœ¨è´­ä¹°å†³ç­–ä¸­åšå‡ºé€‰æ‹©çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨æ•°å­¦æ¨¡å‹æ¥åˆ†ææ¶ˆè´¹è€…å¦‚ä½•æ ¹æ®ä¸åŒçš„äº§å“æˆ–æœåŠ¡ç‰¹å¾åšå‡ºé€‰æ‹©ï¼Œå¹¶é‡åŒ–è¿™äº›é€‰æ‹©çš„æ¦‚ç‡ã€‚é€šå¸¸ï¼Œç ”ç©¶è€…ä¼šè®¾è®¡å®éªŒæˆ–è°ƒæŸ¥æ¥æ”¶é›†å…³äºæ¶ˆè´¹è€…å¯¹ä¸åŒäº§å“æˆ–æœåŠ¡çš„åå¥½å’Œé€‰æ‹©çš„æ•°æ®ï¼Œç„¶åä½¿ç”¨é€‰æ‹©æ¨¡å‹æ¥è§£é‡Šè¿™äº›æ•°æ®ã€‚\né€‰æ‹©æ¨¡å‹å¯ä»¥æ˜¯åŸºäºå‚æ•°çš„ï¼Œæ¯”å¦‚æ¦‚ç‡æ¨¡å‹ï¼ˆå¦‚é€»è¾‘å›å½’ï¼‰ã€åå¥½æ¨¡å‹ï¼ˆå¦‚åå¥½å‡½æ•°ï¼‰æˆ–æ•ˆç”¨æ¨¡å‹ï¼ˆå¦‚ç¦åˆ©å‡½æ•°ï¼‰ç­‰ï¼›ä¹Ÿå¯ä»¥æ˜¯éå‚æ•°çš„ï¼Œæ¯”å¦‚å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿå¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…å¯¹äº§å“æˆ–æœåŠ¡çš„åå¥½ï¼Œä»è€ŒæŒ‡å¯¼äº§å“å®šä»·ã€å¸‚åœºå®šä½ã€å¹¿å‘Šç­–ç•¥ç­‰å†³ç­–ã€‚\nMarketers often observe yes/no outcomes:\nâ€¢ Did a customer purchase a product?\nâ€¢ Did a customer take a test drive?\nâ€¢ Did a customer sign up for a credit card, renew her subscription, or respond to a promotion?\nAll of these kinds of outcomes are binary because they have only two possible overserved states: yes or no. A logistic model is used to fit such outcomes.\n"><title>R[week4] Choice model code</title><link rel=canonical href=https://MyLoveES.github.io/p/rweek4-choice-model-code/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="R[week4] Choice model code"><meta property='og:description' content=" R: 4.3.2 (2023-10-31) R studio: 2023.12.1+402 (2023.12.1+402)\nChoice modeling æ˜¯ä¸€ç§å¸‚åœºç ”ç©¶æ–¹æ³•ï¼Œç”¨äºç†è§£æ¶ˆè´¹è€…åœ¨è´­ä¹°å†³ç­–ä¸­åšå‡ºé€‰æ‹©çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨æ•°å­¦æ¨¡å‹æ¥åˆ†ææ¶ˆè´¹è€…å¦‚ä½•æ ¹æ®ä¸åŒçš„äº§å“æˆ–æœåŠ¡ç‰¹å¾åšå‡ºé€‰æ‹©ï¼Œå¹¶é‡åŒ–è¿™äº›é€‰æ‹©çš„æ¦‚ç‡ã€‚é€šå¸¸ï¼Œç ”ç©¶è€…ä¼šè®¾è®¡å®éªŒæˆ–è°ƒæŸ¥æ¥æ”¶é›†å…³äºæ¶ˆè´¹è€…å¯¹ä¸åŒäº§å“æˆ–æœåŠ¡çš„åå¥½å’Œé€‰æ‹©çš„æ•°æ®ï¼Œç„¶åä½¿ç”¨é€‰æ‹©æ¨¡å‹æ¥è§£é‡Šè¿™äº›æ•°æ®ã€‚\né€‰æ‹©æ¨¡å‹å¯ä»¥æ˜¯åŸºäºå‚æ•°çš„ï¼Œæ¯”å¦‚æ¦‚ç‡æ¨¡å‹ï¼ˆå¦‚é€»è¾‘å›å½’ï¼‰ã€åå¥½æ¨¡å‹ï¼ˆå¦‚åå¥½å‡½æ•°ï¼‰æˆ–æ•ˆç”¨æ¨¡å‹ï¼ˆå¦‚ç¦åˆ©å‡½æ•°ï¼‰ç­‰ï¼›ä¹Ÿå¯ä»¥æ˜¯éå‚æ•°çš„ï¼Œæ¯”å¦‚å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿå¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…å¯¹äº§å“æˆ–æœåŠ¡çš„åå¥½ï¼Œä»è€ŒæŒ‡å¯¼äº§å“å®šä»·ã€å¸‚åœºå®šä½ã€å¹¿å‘Šç­–ç•¥ç­‰å†³ç­–ã€‚\nMarketers often observe yes/no outcomes:\nâ€¢ Did a customer purchase a product?\nâ€¢ Did a customer take a test drive?\nâ€¢ Did a customer sign up for a credit card, renew her subscription, or respond to a promotion?\nAll of these kinds of outcomes are binary because they have only two possible overserved states: yes or no. A logistic model is used to fit such outcomes.\n"><meta property='og:url' content='https://MyLoveES.github.io/p/rweek4-choice-model-code/'><meta property='og:site_name' content='Kunkka'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='R-Language'><meta property='article:published_time' content='2024-03-25T00:00:00+00:00'><meta property='article:modified_time' content='2024-03-25T00:00:00+00:00'><meta name=twitter:title content="R[week4] Choice model code"><meta name=twitter:description content=" R: 4.3.2 (2023-10-31) R studio: 2023.12.1+402 (2023.12.1+402)\nChoice modeling æ˜¯ä¸€ç§å¸‚åœºç ”ç©¶æ–¹æ³•ï¼Œç”¨äºç†è§£æ¶ˆè´¹è€…åœ¨è´­ä¹°å†³ç­–ä¸­åšå‡ºé€‰æ‹©çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨æ•°å­¦æ¨¡å‹æ¥åˆ†ææ¶ˆè´¹è€…å¦‚ä½•æ ¹æ®ä¸åŒçš„äº§å“æˆ–æœåŠ¡ç‰¹å¾åšå‡ºé€‰æ‹©ï¼Œå¹¶é‡åŒ–è¿™äº›é€‰æ‹©çš„æ¦‚ç‡ã€‚é€šå¸¸ï¼Œç ”ç©¶è€…ä¼šè®¾è®¡å®éªŒæˆ–è°ƒæŸ¥æ¥æ”¶é›†å…³äºæ¶ˆè´¹è€…å¯¹ä¸åŒäº§å“æˆ–æœåŠ¡çš„åå¥½å’Œé€‰æ‹©çš„æ•°æ®ï¼Œç„¶åä½¿ç”¨é€‰æ‹©æ¨¡å‹æ¥è§£é‡Šè¿™äº›æ•°æ®ã€‚\né€‰æ‹©æ¨¡å‹å¯ä»¥æ˜¯åŸºäºå‚æ•°çš„ï¼Œæ¯”å¦‚æ¦‚ç‡æ¨¡å‹ï¼ˆå¦‚é€»è¾‘å›å½’ï¼‰ã€åå¥½æ¨¡å‹ï¼ˆå¦‚åå¥½å‡½æ•°ï¼‰æˆ–æ•ˆç”¨æ¨¡å‹ï¼ˆå¦‚ç¦åˆ©å‡½æ•°ï¼‰ç­‰ï¼›ä¹Ÿå¯ä»¥æ˜¯éå‚æ•°çš„ï¼Œæ¯”å¦‚å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿå¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…å¯¹äº§å“æˆ–æœåŠ¡çš„åå¥½ï¼Œä»è€ŒæŒ‡å¯¼äº§å“å®šä»·ã€å¸‚åœºå®šä½ã€å¹¿å‘Šç­–ç•¥ç­‰å†³ç­–ã€‚\nMarketers often observe yes/no outcomes:\nâ€¢ Did a customer purchase a product?\nâ€¢ Did a customer take a test drive?\nâ€¢ Did a customer sign up for a credit card, renew her subscription, or respond to a promotion?\nAll of these kinds of outcomes are binary because they have only two possible overserved states: yes or no. A logistic model is used to fit such outcomes.\n"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_c68a00bbf16dac8.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ¥</span></figure><div class=site-meta><h1 class=site-name><a href=/>Kunkka</a></h1><h2 class=site-description>wind rises</h2></div></header><ol class=menu-social><li><a href=https://github.com/MyLoveES target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=/index.xml target=_blank title=RSS rel=me><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/archives><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/all-categories><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/links><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/all-tags><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#31-the-logit-model>3.1 The Logit Model</a></li><li><a href=#32-predicting-probabilities>3.2 Predicting probabilities</a></li><li><a href=#33-predicting-behaviour>3.3 Predicting behaviour</a></li><li><a href=#34-evaluating-the-model>3.4 Evaluating the model</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/r-language/>R-Language</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/rweek4-choice-model-code/>R[week4] Choice model code</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 25, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>12 minute read</time></div></footer></div></header><section class=article-content><blockquote><p>R: 4.3.2 (2023-10-31)
R studio: 2023.12.1+402 (2023.12.1+402)</p></blockquote><p>Choice modeling æ˜¯ä¸€ç§å¸‚åœºç ”ç©¶æ–¹æ³•ï¼Œç”¨äºç†è§£æ¶ˆè´¹è€…åœ¨è´­ä¹°å†³ç­–ä¸­åšå‡ºé€‰æ‹©çš„è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨æ•°å­¦æ¨¡å‹æ¥åˆ†ææ¶ˆè´¹è€…å¦‚ä½•æ ¹æ®ä¸åŒçš„äº§å“æˆ–æœåŠ¡ç‰¹å¾åšå‡ºé€‰æ‹©ï¼Œå¹¶é‡åŒ–è¿™äº›é€‰æ‹©çš„æ¦‚ç‡ã€‚é€šå¸¸ï¼Œç ”ç©¶è€…ä¼šè®¾è®¡å®éªŒæˆ–è°ƒæŸ¥æ¥æ”¶é›†å…³äºæ¶ˆè´¹è€…å¯¹ä¸åŒäº§å“æˆ–æœåŠ¡çš„åå¥½å’Œé€‰æ‹©çš„æ•°æ®ï¼Œç„¶åä½¿ç”¨é€‰æ‹©æ¨¡å‹æ¥è§£é‡Šè¿™äº›æ•°æ®ã€‚</p><p>é€‰æ‹©æ¨¡å‹å¯ä»¥æ˜¯åŸºäºå‚æ•°çš„ï¼Œæ¯”å¦‚æ¦‚ç‡æ¨¡å‹ï¼ˆå¦‚é€»è¾‘å›å½’ï¼‰ã€åå¥½æ¨¡å‹ï¼ˆå¦‚åå¥½å‡½æ•°ï¼‰æˆ–æ•ˆç”¨æ¨¡å‹ï¼ˆå¦‚ç¦åˆ©å‡½æ•°ï¼‰ç­‰ï¼›ä¹Ÿå¯ä»¥æ˜¯éå‚æ•°çš„ï¼Œæ¯”å¦‚å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿå¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…å¯¹äº§å“æˆ–æœåŠ¡çš„åå¥½ï¼Œä»è€ŒæŒ‡å¯¼äº§å“å®šä»·ã€å¸‚åœºå®šä½ã€å¹¿å‘Šç­–ç•¥ç­‰å†³ç­–ã€‚</p><p>Marketers often observe yes/no outcomes:<br>â€¢ Did a customer purchase a product?<br>â€¢ Did a customer take a test drive?<br>â€¢ Did a customer sign up for a credit card, renew her subscription, or respond to a promotion?<br>All of these kinds of outcomes are binary because they have only two possible overserved states: yes or no. A logistic model is used to fit such outcomes.</p><p><strong>è¿™äº›ç±»å‹çš„ç»“æœéƒ½æ˜¯äºŒå…ƒçš„ï¼Œå®ƒä»¬åªæœ‰ä¸¤ç§å¯èƒ½çš„çŠ¶æ€ï¼šæ˜¯æˆ–å¦ã€‚ logisticæ¨¡å‹è¢«ç”¨æ¥æ‹Ÿåˆè¿™æ ·çš„ç»“æœã€‚</strong></p><h1 id=1-basics-of-logistic-regression>1. Basics of logistic regression</h1><p>The core feature of a logistic model is that it relates the probability of an outcome to an exponential function of a predictor variable.<br>By modelling the probability of an outcome, a logistic model accomplishes two things:<br>â€¢ First, it more directly models what we are interested in, which is a probability or proportion, such as the likelihood of a given customer to purchase a product or the expected proportion of a segment who will respond to a promotion.<br>â€¢ Second, it limits the model to the appropriate range for a proportion, which is [0, 1]. A basic linear model, as generated with lm(), does not have such a limit. The equation for the logistic function is:</p>$$
p(y) = \frac{e^{v_x}}{e^{v_x} + 1}
$$<p>Logisticæ¨¡å‹çš„æ ¸å¿ƒç‰¹å¾æ˜¯å®ƒå°†ç»“æœçš„æ¦‚ç‡ä¸é¢„æµ‹å˜é‡çš„æŒ‡æ•°å‡½æ•°ç›¸å…³è”ã€‚<br>é€šè¿‡å¯¹ç»“æœçš„æ¦‚ç‡å»ºæ¨¡ï¼Œlogisticæ¨¡å‹å®ç°äº†ä¸¤ä¸ªç›®æ ‡ã€‚<br>â€¢ é¦–å…ˆï¼Œå®ƒæ›´ç›´æ¥åœ°å¯¹æˆ‘ä»¬æ„Ÿå…´è¶£çš„å†…å®¹è¿›è¡Œå»ºæ¨¡ï¼Œå³æ¦‚ç‡æˆ–æ¯”ä¾‹ï¼Œä¾‹å¦‚ç»™å®šå®¢æˆ·è´­ä¹°äº§å“çš„å¯èƒ½æ€§æˆ–å°†å¯¹ä¿ƒé”€æ´»åŠ¨åšå‡ºå›åº”çš„ç»†åˆ†é¢„æœŸæ¯”ä¾‹ã€‚<br>â€¢ å…¶æ¬¡ï¼Œå®ƒå°†æ¨¡å‹é™åˆ¶åœ¨æ¯”ä¾‹çš„é€‚å½“èŒƒå›´å†…ï¼Œå³[0,1]ã€‚åŸºæœ¬çš„çº¿æ€§æ¨¡å‹ï¼Œå¦‚lm()ç”Ÿæˆçš„æ¨¡å‹ï¼Œæ²¡æœ‰è¿™æ ·çš„é™åˆ¶ã€‚</p><p>In this equation, the outcome of interest is y, and we compute its likelihood p(y) as a function of vx. We typically estimate vx as a function of the features (x) of a product, such as price. vx can take any real value, so we are able to treat it as a continuous function in a linear model. In that case, vx is composed of one or more coefficients of the model and indicates the importance of the corresponding features of the product.</p><p>åœ¨è¿™ä¸ªæ–¹ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„ç»“æœæ˜¯yï¼Œæˆ‘ä»¬è®¡ç®—å…¶æ¦‚ç‡p(y)ä½œä¸ºvxçš„å‡½æ•°ã€‚æˆ‘ä»¬é€šå¸¸å°†vxä¼°è®¡ä¸ºäº§å“ç‰¹å¾ï¼ˆxï¼‰çš„å‡½æ•°ï¼Œä¾‹å¦‚ä»·æ ¼ã€‚vxå¯ä»¥å–ä»»ä½•å®æ•°å€¼ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†å…¶è§†ä¸ºçº¿æ€§æ¨¡å‹ä¸­çš„è¿ç»­å‡½æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œvxç”±æ¨¡å‹çš„ä¸€ä¸ªæˆ–å¤šä¸ªç³»æ•°ç»„æˆï¼Œå¹¶æŒ‡ç¤ºäº§å“ç›¸åº”ç‰¹å¾çš„é‡è¦æ€§ã€‚</p><p>The formula gives a value between [0, 1]. The likelihood of y is less than 50% when vx is negative, is 50% when vx = 0 and is above 50% when vx is positive. We compute this first by hand and then switch to the equivalent plogis() function:</p><p>è¿™ä¸ªå…¬å¼ç»™å‡ºäº†ä¸€ä¸ªåœ¨[0, 1]ä¹‹é—´çš„å€¼ã€‚å½“vxä¸ºè´Ÿæ—¶ï¼Œyçš„æ¦‚ç‡å°äº50ï¼…ï¼Œå½“vx = 0æ—¶ï¼Œæ¦‚ç‡ä¸º50ï¼…ï¼Œå½“vxä¸ºæ­£æ—¶ï¼Œæ¦‚ç‡å¤§äº50ï¼…ã€‚æˆ‘ä»¬é¦–å…ˆæ‰‹å·¥è®¡ç®—è¿™ä¸ªå€¼ï¼Œç„¶ååˆ‡æ¢åˆ°ç­‰æ•ˆçš„plogis()å‡½æ•°ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; exp(0) / exp(0)+1 # computing logistic by hand, or using plogis()
</span></span><span class=line><span class=cl>â€¢[1] 2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># plogiså‚æ•°å…¶å®å°±æ˜¯p(y)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; plogis(-Inf) #infinitely low = likelihood 0
</span></span><span class=line><span class=cl>[1] 0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; plogis(2) #moderate probability = 88% chance of outcome
</span></span><span class=line><span class=cl>[1] 0.8807971
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; plogis(-0.2) # weak likelihood
</span></span><span class=line><span class=cl>[1] 0.450166
</span></span></code></pre></td></tr></table></div></div><div style=background-color:#f0f0f0;padding:10px><blockquote><p>plogis():</p></blockquote><p><code>plogis()</code> å‡½æ•°æ˜¯ R è¯­è¨€ä¸­ç”¨äºè®¡ç®—é€»è¾‘å‡½æ•°ï¼ˆlogistic functionï¼‰çš„å‡½æ•°ã€‚</p><p>é€»è¾‘å‡½æ•°çš„å®šä¹‰å¦‚ä¸‹æ‰€ç¤ºï¼š</p>$$
\text{logistic}(x) = \frac{1}{1 + e^{-x}}
$$<p>å…¶ä¸­ï¼Œ\(x\) æ˜¯é€»è¾‘å‡½æ•°çš„è¾“å…¥å€¼ã€‚<code>plogis()</code> å‡½æ•°æ¥å—ä¸€ä¸ªå‚æ•° \(x\)ï¼Œè¡¨ç¤ºé€»è¾‘å‡½æ•°çš„è¾“å…¥å€¼ï¼Œç„¶åè¿”å›é€»è¾‘å‡½æ•°çš„å€¼ã€‚è¿™ä¸ªå‡½æ•°é€šå¸¸ç”¨äºé€»è¾‘å›å½’æ¨¡å‹ä¸­ï¼Œå°†çº¿æ€§é¢„æµ‹å€¼è½¬æ¢ä¸º0åˆ°1ä¹‹é—´çš„æ¦‚ç‡å€¼ã€‚</p><p>åœ¨ R ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>plogis()</code> å‡½æ•°æ¥è®¡ç®—é€»è¾‘å‡½æ•°çš„å€¼ã€‚ä¾‹å¦‚ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># è®¡ç®—é€»è¾‘å‡½æ•°å€¼
</span></span><span class=line><span class=cl>x &lt;- 2
</span></span><span class=line><span class=cl>probability &lt;- plogis(x)
</span></span><span class=line><span class=cl>print(probability)
</span></span></code></pre></td></tr></table></div></div></div><p>Such a model is known as a logit model, which determines the value of vx from the logarithm of the relative probability of occurence of y:</p>$$
v_x = \log \left( \frac{p(y)}{1 - p(y)} \right)
$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; log(0.88 / (1-0.88)) # moderate high likelihood
</span></span><span class=line><span class=cl>[1] 1.99243
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; qlogis(0.88) # equivalent to hand computation
</span></span><span class=line><span class=cl>[1] 1.99243
</span></span></code></pre></td></tr></table></div></div><div style=background-color:#f0f0f0;padding:10px><blockquote><p>qlogis()</p></blockquote><p><code>qlogis()</code> å‡½æ•°æ˜¯ R è¯­è¨€ä¸­ç”¨äºè®¡ç®—é€»è¾‘å‡½æ•°çš„åå‡½æ•°çš„å‡½æ•°ã€‚</p><p>é€»è¾‘å‡½æ•°çš„åå‡½æ•°é€šå¸¸ç§°ä¸ºé€†é€»è¾‘å‡½æ•°ï¼Œå…¶å®šä¹‰å¦‚ä¸‹æ‰€ç¤ºï¼š</p>$$
\text{logit}(p) = \log\left(\frac{p}{1 - p}\right)
$$<p>å…¶ä¸­ï¼Œ\( p \) æ˜¯é€»è¾‘å‡½æ•°çš„è¾“å‡ºå€¼ï¼Œå³æ¦‚ç‡å€¼ã€‚</p><p><code>qlogis()</code> å‡½æ•°æ¥å—ä¸€ä¸ªå‚æ•° \( p \)ï¼Œè¡¨ç¤ºé€»è¾‘å‡½æ•°çš„è¾“å‡ºå€¼ï¼ˆå³æ¦‚ç‡å€¼ï¼‰ï¼Œç„¶åè¿”å›é€†é€»è¾‘å‡½æ•°çš„å€¼ã€‚è¿™ä¸ªå‡½æ•°é€šå¸¸ç”¨äºä»é€»è¾‘å‡½æ•°çš„æ¦‚ç‡å€¼ä¸­åæ¨å‡ºçº¿æ€§é¢„æµ‹å€¼ã€‚</p><p>åœ¨ R ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>qlogis()</code> å‡½æ•°æ¥è®¡ç®—é€†é€»è¾‘å‡½æ•°çš„å€¼ã€‚ä¾‹å¦‚ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=line><span class=cl><span class=c1># è®¡ç®—é€†é€»è¾‘å‡½æ•°å€¼</span>
</span></span><span class=line><span class=cl><span class=n>p</span> <span class=o>&lt;-</span> <span class=m>0.7</span>
</span></span><span class=line><span class=cl><span class=n>linear_pred</span> <span class=o>&lt;-</span> <span class=nf>qlogis</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>print</span><span class=p>(</span><span class=n>linear_pred</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><h1 id=2-generalised-linear-model-glm>2. Generalised linear model (GLM)</h1><p>A logistic regression model in R is fitted as a generalised linear model (GLM) using a process similar to linear regression with lm(), but with the difference that a GLM can handle dependent variables that are not normally distributed. Thus, GLM can be used to model data counts (such as the number of purchases), time intervals (such as time spent on a website), or binary variables (e.g., did/didnâ€™t purchase). The common feature of all GLM models is that they relate normally distributed predictors to a non-normal outcome using a function known as a link. This means that they are able to fit models for many different distributions using a single, consistent framework.</p><p>åœ¨Rä¸­ï¼Œé€»è¾‘å›å½’æ¨¡å‹æ˜¯ä½œä¸ºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMï¼‰è¿›è¡Œæ‹Ÿåˆçš„ï¼Œä½¿ç”¨çš„è¿‡ç¨‹ç±»ä¼¼äºä½¿ç”¨lm()è¿›è¡Œçº¿æ€§å›å½’ï¼Œä½†ä¸åŒä¹‹å¤„åœ¨äºGLMå¯ä»¥å¤„ç†ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒçš„å› å˜é‡ã€‚å› æ­¤ï¼ŒGLMå¯ç”¨äºå¯¹æ•°æ®è®¡æ•°ï¼ˆä¾‹å¦‚è´­ä¹°æ¬¡æ•°ï¼‰ã€æ—¶é—´é—´éš”ï¼ˆä¾‹å¦‚åœ¨ç½‘ç«™ä¸Šçš„åœç•™æ—¶é—´ï¼‰æˆ–äºŒå…ƒå˜é‡ï¼ˆä¾‹å¦‚æ˜¯å¦è´­ä¹°ï¼‰å»ºæ¨¡ã€‚æ‰€æœ‰GLMæ¨¡å‹çš„å…±åŒç‰¹ç‚¹æ˜¯å®ƒä»¬å°†æ­£æ€åˆ†å¸ƒçš„é¢„æµ‹å˜é‡ä¸ä¸€ä¸ªéæ­£æ€çš„ç»“æœç›¸å…³è”ï¼Œä½¿ç”¨çš„å‡½æ•°ç§°ä¸ºé“¾æ¥å‡½æ•°ã€‚è¿™æ„å‘³ç€å®ƒä»¬èƒ½å¤Ÿä½¿ç”¨å•ä¸€ã€ä¸€è‡´çš„æ¡†æ¶æ‹Ÿåˆè®¸å¤šä¸åŒåˆ†å¸ƒçš„æ¨¡å‹ã€‚</p><div style=background-color:#f0f0f0;padding:10px><p>å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGeneralized Linear Modelï¼ŒGLMï¼‰æ˜¯ä¸€ç§å¹¿æ³›åº”ç”¨äºç»Ÿè®¡åˆ†æä¸­çš„æ¨¡å‹ï¼Œå®ƒå°†çº¿æ€§æ¨¡å‹æ‰©å±•åˆ°äº†æ›´å¹¿æ³›çš„æ•°æ®ç±»å‹å’Œåˆ†å¸ƒã€‚GLMå¯ä»¥å¤„ç†ä¸åŒç±»å‹çš„å“åº”å˜é‡ï¼ŒåŒ…æ‹¬äºŒé¡¹åˆ†å¸ƒã€æ³Šæ¾åˆ†å¸ƒã€æ­£æ€åˆ†å¸ƒç­‰ï¼Œå¹¶ä¸”å¯ä»¥å¤„ç†ä¸åŒçš„é“¾æ¥å‡½æ•°ï¼Œå¦‚æ’ç­‰å‡½æ•°ã€å¯¹æ•°å‡½æ•°ã€é€»è¾‘æ–¯è’‚å‡½æ•°ç­‰ã€‚</p><p>GLMçš„åŸºæœ¬å½¢å¼å¦‚ä¸‹ï¼š</p><ol><li>çº¿æ€§éƒ¨åˆ†ï¼š</li></ol>$$
\eta = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p
$$<p>è¿™éƒ¨åˆ†ä¸å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ç›¸ä¼¼ï¼Œå…¶ä¸­ $ \eta $ æ˜¯çº¿æ€§é¢„æµ‹å€¼ï¼Œ$ \beta_0 $ , $ \beta_1 $ , $ \ldots $, $ \beta_p $ æ˜¯ç³»æ•°ï¼Œ$ x_1 $ , $ x_2 $ , $ \ldots $, $ x_p $ æ˜¯é¢„æµ‹å˜é‡ã€‚</p><ol start=2><li>é“¾æ¥å‡½æ•°ï¼š</li></ol>$$ g(\mu) = \eta $$<p>è¿™é‡Œçš„ $ g(\cdot) $ æ˜¯é“¾æ¥å‡½æ•°ï¼Œå®ƒå®šä¹‰äº†é¢„æµ‹å˜é‡ $ \eta $ ä¸å“åº”å˜é‡ $ \mu $ ä¹‹é—´çš„å…³ç³»ã€‚é“¾æ¥å‡½æ•°é€šå¸¸æ ¹æ®å“åº”å˜é‡çš„ç±»å‹é€‰æ‹©ï¼Œå¦‚å¯¹æ•°é“¾æ¥å‡½æ•°ç”¨äºå¤„ç†æ³Šæ¾åˆ†å¸ƒçš„å“åº”å˜é‡ï¼Œé€»è¾‘æ–¯è’‚é“¾æ¥å‡½æ•°ç”¨äºå¤„ç†äºŒé¡¹åˆ†å¸ƒçš„å“åº”å˜é‡ç­‰ã€‚</p><ol start=3><li>åˆ†å¸ƒæ—ï¼š</li></ol>$$ Y \sim \text{Dist}(\mu) $$<p>è¿™é‡Œçš„ $ \text{Dist}(\mu) $ è¡¨ç¤ºå“åº”å˜é‡ Y çš„åˆ†å¸ƒæ—ï¼Œ$ \mu $ æ˜¯å“åº”å˜é‡çš„å‡å€¼ã€‚</p><p>GLMçš„ä¼˜åŠ¿åœ¨äºå®ƒçš„çµæ´»æ€§å’Œé€‚ç”¨æ€§ï¼Œå¯ä»¥é€‚åº”ä¸åŒç±»å‹å’Œåˆ†å¸ƒçš„æ•°æ®ï¼ŒåŒæ—¶ä¿æŒäº†å¯¹å‚æ•°çš„è§£é‡Šæ€§ã€‚å®ƒåœ¨è®¸å¤šé¢†åŸŸéƒ½å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬ç”Ÿç‰©ç»Ÿè®¡å­¦ã€åŒ»å­¦ã€ç¤¾ä¼šç§‘å­¦ç­‰ã€‚</p></div><h1 id=3-rfm-recency-frequency-monetary>3. RFM (recency, frequency, monetary)</h1><p>RFM is a method used for analyzing customer value. RFM stands for the three dimensions: Recency: How recently did the customer purchase? Frequency: How often do they purchase? Monetary Value: How much do they spend?</p><p>RFMæ˜¯ç”¨äºåˆ†æå®¢æˆ·ä»·å€¼çš„ä¸€ç§æ–¹æ³•ã€‚RFMä»£è¡¨ä¸‰ä¸ªç»´åº¦ï¼šRecencyï¼ˆæœ€è¿‘è´­ä¹°æ—¶é—´ï¼‰ï¼šå®¢æˆ·æœ€è¿‘ä¸€æ¬¡è´­ä¹°æ˜¯åœ¨å¤šä¹…ä¹‹å‰ï¼ŸFrequencyï¼ˆè´­ä¹°é¢‘ç‡ï¼‰ï¼šä»–ä»¬è´­ä¹°çš„é¢‘ç‡å¦‚ä½•ï¼ŸMonetary Valueï¼ˆè´­ä¹°é‡‘é¢ï¼‰ï¼šä»–ä»¬çš„æ¶ˆè´¹é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ</p><h2 id=31-the-logit-model>3.1 The Logit Model</h2><p>The logit model restricts the output values to lie in [0, 1] intervals.<br>Specifically, it expresses the probability of purchase by customer i as a function of coefficients Î²0:3 and variables in the following manner:</p><p>é€»è¾‘æ–¯è’‚æ¨¡å‹å°†è¾“å‡ºå€¼é™åˆ¶åœ¨[0, 1]çš„åŒºé—´å†…ã€‚
å…·ä½“è€Œè¨€ï¼Œå®ƒå°†å®¢æˆ·içš„è´­ä¹°æ¦‚ç‡è¡¨è¾¾ä¸ºç³»æ•°Î²0:3å’Œä»¥ä¸‹å˜é‡çš„å‡½æ•°ï¼š</p>$$
P(Purchase_i) = \frac{exp(\beta_0 + \beta_1 \text{Recency}_i + \beta_2 \text{Frequency}_i + \beta_3 \text{Monetary}_i)}{exp(\beta_0 + \beta_1 \text{Recency}_i + \beta_2 \text{Frequency}_i + \beta_3 \text{Monetary}_i) + 1}
$$<div style=background-color:#f0f0f0;padding:10px><p>è¿™ä¸ªå…¬å¼æ˜¯ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹ä¸­ç”¨äºè®¡ç®—è´­ä¹°æ¦‚ç‡çš„æ–¹ç¨‹ã€‚åœ¨è¿™ä¸ªæ–¹ç¨‹ä¸­ï¼š</p><ul><li>$ P(Purchase_i) $ è¡¨ç¤ºç¬¬ i ä¸ªä¸ªä½“è´­ä¹°çš„æ¦‚ç‡ã€‚</li><li>$ \beta_0 $, $ \beta_1 $, $ \beta_2 $, $ \beta_3 $ æ˜¯æ¨¡å‹çš„å‚æ•°ï¼Œåˆ†åˆ«è¡¨ç¤ºæˆªè·å’Œä¸æ¯ä¸ªé¢„æµ‹å˜é‡ï¼ˆRecencyã€Frequencyã€Monetaryï¼‰ç›¸å…³çš„ç³»æ•°ã€‚</li><li>$ \text{Recency}_i $, $ \text{Frequency}_i $, $ \text{Monetary}_i $ æ˜¯ç¬¬ i ä¸ªä¸ªä½“çš„é¢„æµ‹å˜é‡å€¼ï¼Œåˆ†åˆ«è¡¨ç¤ºæœ€è¿‘ä¸€æ¬¡è´­ä¹°è·ç¦»ã€è´­ä¹°é¢‘ç‡å’Œè´­ä¹°é‡‘é¢ã€‚</li></ul><p>å…¬å¼çš„åˆ†å­éƒ¨åˆ†è¡¨ç¤ºäº†ä¸€ä¸ªçº¿æ€§ç»„åˆ$ (\beta_0 + \beta_1 \text{Recency}_i + \beta_2 \text{Frequency}_i + \beta_3 \text{Monetary}_i) $ çš„æŒ‡æ•°å½¢å¼ï¼Œå³æŒ‡æ•°å‡½æ•° $ \text{exp}(\ldots) $ ï¼Œä»£è¡¨äº†è´­ä¹°çš„å¯èƒ½æ€§ã€‚</p><p>åˆ†æ¯éƒ¨åˆ†æ˜¯åˆ†å­éƒ¨åˆ†åŠ ä¸Š1ï¼Œè¿™æ˜¯ç”±äºé€»è¾‘å›å½’æ¨¡å‹çš„å½¢å¼ï¼Œä¿è¯äº†æ¦‚ç‡å€¼åœ¨0å’Œ1ä¹‹é—´ã€‚æ•´ä¸ªæ–¹ç¨‹å®é™…ä¸Šæ˜¯é€»è¾‘å›å½’æ¨¡å‹çš„é€»è¾‘å‡½æ•°ï¼ˆlogistic functionï¼‰ï¼Œå®ƒå°†çº¿æ€§é¢„æµ‹å€¼è½¬æ¢ä¸º0åˆ°1ä¹‹é—´çš„æ¦‚ç‡å€¼ï¼Œè¿™è¡¨ç¤ºä¸ªä½“è´­ä¹°çš„æ¦‚ç‡ã€‚</p></div><p>Intuitively, the utility of choosing to buy is:</p>$$ V_{bi} = \beta_0 + \beta_1 \text{Recency}_i + \beta_2 \text{Frequency}_i + \beta_3 \text{Monetary}_i $$<div style=background-color:#f0f0f0;padding:10px><p>è¿™ä¸ªå…¬å¼è¡¨ç¤ºäº†ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ä¸ªä½“ i çš„ $ V $ å€¼ã€‚åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼š</p><ul><li>$ V_{bi} $ è¡¨ç¤ºä¸ªä½“ $ i $ çš„ $ V $ å€¼ã€‚</li><li>$ \beta_0, \beta_1, \beta_2, \beta_3 $ æ˜¯æ¨¡å‹çš„å‚æ•°ï¼Œåˆ†åˆ«è¡¨ç¤ºæˆªè·å’Œä¸æ¯ä¸ªé¢„æµ‹å˜é‡ï¼ˆRecencyã€Frequencyã€Monetaryï¼‰ç›¸å…³çš„ç³»æ•°ã€‚</li><li>$ \text{Recency}_i, \text{Frequency}_i, \text{Monetary}_i $ ç¬¬ $ i $ ä¸ªä¸ªä½“çš„é¢„æµ‹å˜é‡å€¼ï¼Œåˆ†åˆ«è¡¨ç¤ºæœ€è¿‘ä¸€æ¬¡è´­ä¹°è·ç¦»ã€è´­ä¹°é¢‘ç‡å’Œè´­ä¹°é‡‘é¢ã€‚</li></ul><p>è¿™ä¸ªæ¨¡å‹çš„ç›®çš„æ˜¯é€šè¿‡ä¸ªä½“çš„è´­ä¹°è¡Œä¸ºçš„ç›¸å…³ç‰¹å¾ï¼ˆRecencyã€Frequencyã€Monetaryï¼‰æ¥é¢„æµ‹ä»–ä»¬çš„ $ V $ å€¼ã€‚è¿™ä¸ª $ V $ å€¼å¯èƒ½è¡¨ç¤ºä¸ªä½“çš„æ½œåœ¨ä»·å€¼æˆ–å…¶ä»–ç›¸å…³çš„æŒ‡æ ‡ã€‚</p><p>whereas utility of choosing not to buy is normalized to zero $ V_ni = 0 $, so $ exp(V_n) = exp(0) = 1 $ in the fraction above.<br>With the given formulation, we can estimate values $ \beta_0:3 $ that fit the data best. We use glm() of family=â€œbinomialâ€.</p><p>é€‰æ‹©ä¸è´­ä¹°çš„æ•ˆç”¨è¢«å½’ä¸€åŒ–ä¸ºé›¶ï¼Œå³ Vni = 0ï¼Œå› æ­¤åœ¨ä¸Šè¿°åˆ†æ•°ä¸­ exp(Vn) = exp(0) = 1ã€‚<br>é€šè¿‡ç»™å®šçš„å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä¼°è®¡æœ€é€‚åˆæ•°æ®çš„ Î²0:3 å€¼ã€‚æˆ‘ä»¬ä½¿ç”¨ glm() ä¸­çš„ family=&ldquo;binomial&rdquo;ã€‚</p></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; RFMdata &lt;- read.csv(file = &#34;RFMData.csv&#34;,row.names=1) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; head(RFMdata,5)
</span></span><span class=line><span class=cl>  Recency Frequency Monetary Purchase
</span></span><span class=line><span class=cl>1     120         7    41.66        0
</span></span><span class=line><span class=cl>2      90         9    46.71        0
</span></span><span class=line><span class=cl>3     120         6   103.99        1
</span></span><span class=line><span class=cl>4     270        17    37.13        1
</span></span><span class=line><span class=cl>5      60         5    88.92        0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; model &lt;- glm(Purchase~Recency+Frequency+Monetary, data=RFMdata, family = &#34;binomial&#34;) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; output &lt;- cbind(coef(summary(model))[, 1:4],exp(coef(model)))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; colnames(output) &lt;- c(&#34;beta&#34;,&#34;SE&#34;,&#34;z val.&#34;,&#34;Pr(&gt;|z|)&#34;,&#39;exp(beta)&#39;) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; kable(output,caption = &#34;Logistic regression estimates&#34;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Table: Logistic regression estimates
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>|            |        beta|        SE|    z val.| Pr(&gt;&amp;#124;z&amp;#124;)| exp(beta)|
</span></span><span class=line><span class=cl>|:-----------|-----------:|---------:|---------:|------------------:|---------:|
</span></span><span class=line><span class=cl>|(Intercept) | -30.2976692| 8.5522913| -3.542638|          0.0003961|  0.000000|
</span></span><span class=line><span class=cl>|Recency     |   0.1114175| 0.0309797|  3.596464|          0.0003226|  1.117862|
</span></span><span class=line><span class=cl>|Frequency   |   0.5941268| 0.2429393|  2.445577|          0.0144620|  1.811448|
</span></span><span class=line><span class=cl>|Monetary    |   0.1677054| 0.0465645|  3.601572|          0.0003163|  1.182588|
</span></span></code></pre></td></tr></table></div></div><blockquote><p>glm()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>glm() å‡½æ•°æ˜¯ R è¯­è¨€ä¸­çš„ä¸€ä¸ªé‡è¦å‡½æ•°ï¼Œç”¨äºæ‹Ÿåˆå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGeneralized Linear Modelsï¼‰ã€‚å¹¿ä¹‰çº¿æ€§æ¨¡å‹æ˜¯çº¿æ€§æ¨¡å‹çš„æ‰©å±•ï¼Œå…è®¸å› å˜é‡æœä»ä¸åŒçš„åˆ†å¸ƒï¼Œè€Œä¸ä»…ä»…æ˜¯æ­£æ€åˆ†å¸ƒã€‚è¿™ä½¿å¾—å¹¿ä¹‰çº¿æ€§æ¨¡å‹é€‚ç”¨äºæ›´å¹¿æ³›çš„æ•°æ®ç±»å‹ï¼ŒåŒ…æ‹¬äºŒé¡¹åˆ†å¸ƒï¼ˆäºŒå…ƒé€»è¾‘å›å½’ï¼‰ã€æ³Šæ¾åˆ†å¸ƒï¼ˆè®¡æ•°æ•°æ®ï¼‰ã€å¤šé¡¹åˆ†å¸ƒï¼ˆå¤šç±»åˆ«åˆ†ç±»ï¼‰ç­‰ã€‚</div><blockquote><p>cbind()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>cbind() å‡½æ•°æ˜¯ R è¯­è¨€ä¸­çš„ä¸€ä¸ªåŸºç¡€å‡½æ•°ï¼Œç”¨äºæŒ‰åˆ—åˆå¹¶å¤šä¸ªå¯¹è±¡ï¼ˆé€šå¸¸æ˜¯å‘é‡ã€çŸ©é˜µæˆ–æ•°æ®æ¡†ï¼‰ã€‚cbind æ˜¯ "column bind" çš„ç¼©å†™ï¼Œè¡¨ç¤ºæŒ‰åˆ—åˆå¹¶ã€‚</div><blockquote><p>kable()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>kable() å‡½æ•°æ˜¯ R è¯­è¨€ä¸­ knitr å’Œ rmarkdown åŒ…ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç”Ÿæˆç¾è§‚çš„è¡¨æ ¼è¾“å‡ºã€‚å®ƒèƒ½å¤Ÿå°† R ä¸­çš„æ•°æ®æ¡†ã€çŸ©é˜µæˆ–è¡¨æ ¼è½¬æ¢ä¸º Markdown æˆ– LaTeX æ ¼å¼çš„è¡¨æ ¼ï¼Œä»è€Œæ–¹ä¾¿åœ°å°†å…¶æ’å…¥åˆ° R Markdown æ–‡æ¡£æˆ– HTML é¡µé¢ä¸­ã€‚</div><p>We also run the likelihood ratio test with H0 : Î²1 = Î²2 = Î²3 = 0 â€“ to make sure our full logit model offers a significantly better fit than the model with just an intercept. We find that Ï‡2 = 107.14 and P(> |Chi|) â‰ˆ 0, so we reject H0.</p><p>æˆ‘ä»¬è¿˜è¿›è¡Œäº†ä¼¼ç„¶æ¯”æ£€éªŒï¼Œå‡è®¾ H0ï¼šÎ²1 = Î²2 = Î²3 = 0ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„å®Œæ•´ logit æ¨¡å‹æä¾›äº†æ˜¾ç€æ›´å¥½çš„æ‹Ÿåˆæ•ˆæœï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªæˆªè·æ¨¡å‹ã€‚æˆ‘ä»¬å‘ç° Ï‡2 = 107.14ï¼ŒP(> |Chi|) â‰ˆ 0ï¼Œå› æ­¤æˆ‘ä»¬æ‹’ç» H0ã€‚</p><div style=background-color:#f0f0f0;padding:10px><p>è¿™å¥è¯è¡¨æ˜äº†å¯¹å…¨æ¨¡å‹ï¼ˆå«æœ‰Recencyã€Frequencyã€Monetaryé¢„æµ‹å˜é‡ï¼‰å’Œåªæœ‰æˆªè·é¡¹çš„æ¨¡å‹ä¹‹é—´è¿›è¡Œäº†ä¼¼ç„¶æ¯”æ£€éªŒã€‚åœ¨ä¼¼ç„¶æ¯”æ£€éªŒä¸­ï¼ŒåŸå‡è®¾ $ H_0 $ æ˜¯æ¨¡å‹ä¸­æ‰€æœ‰é¢„æµ‹å˜é‡çš„ç³»æ•°éƒ½ä¸ºé›¶ï¼Œå³ $ \beta_1 = \beta_2 = \beta_3 = 0 $ï¼Œå³åªæœ‰æˆªè·é¡¹ã€‚å¤‡æ‹©å‡è®¾ $ H_1 $ æ˜¯è‡³å°‘æœ‰ä¸€ä¸ªé¢„æµ‹å˜é‡çš„ç³»æ•°ä¸ä¸ºé›¶ï¼Œå³å…¨æ¨¡å‹ã€‚</p><p>é€šè¿‡ä¼¼ç„¶æ¯”æ£€éªŒï¼Œå¯ä»¥ç¡®å®šæ˜¯å¦å…¨æ¨¡å‹ç›¸å¯¹äºåªæœ‰æˆªè·é¡¹çš„æ¨¡å‹æä¾›äº†æ›´å¥½çš„æ‹Ÿåˆã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šè¿‡è®¡ç®—å¾—åˆ°çš„å¡æ–¹ç»Ÿè®¡é‡ $ \chi^2 $ ä¸º107.14ï¼Œå¯¹åº”çš„På€¼éå¸¸æ¥è¿‘äº0ï¼Œé€šå¸¸å°äºæ˜¾è‘—æ€§æ°´å¹³ï¼ˆä¾‹å¦‚0.05ï¼‰ã€‚ç”±äºPå€¼å°äºæ˜¾è‘—æ€§æ°´å¹³ï¼Œæˆ‘ä»¬æ‹’ç»åŸå‡è®¾ $ H_0 $ï¼Œå³è®¤ä¸ºå…¨æ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœæ˜¾è‘—åœ°ä¼˜äºåªæœ‰æˆªè·é¡¹çš„æ¨¡å‹ã€‚</p></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; # likelihood ratio test
</span></span><span class=line><span class=cl>&gt; reduced.model &lt;- glm(Purchase ~ 1, data=RFMdata, family = &#34;binomial&#34;) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; kable(xtable(anova(reduced.model, model, test = &#34;Chisq&#34;)),caption = &#34;Likelihood ratio test&#34;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Table: Likelihood ratio test
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>| Resid. Df| Resid. Dev| Df| Deviance| Pr(&gt;Chi)|
</span></span><span class=line><span class=cl>|---------:|----------:|--:|--------:|--------:|
</span></span><span class=line><span class=cl>|        99|  137.62776| NA|       NA|       NA|
</span></span><span class=line><span class=cl>|        96|   30.48715|  3| 107.1406|        0|
</span></span></code></pre></td></tr></table></div></div><h2 id=32-predicting-probabilities>3.2 Predicting probabilities</h2><p>Now we calculate $ P(Purchase_i) $ for each individual in the data set.</p><p>ç°åœ¨æˆ‘ä»¬è®¡ç®—æ•°æ®é›†ä¸­æ¯ä¸ªä¸ªä½“çš„è´­ä¹°æ¦‚ç‡$ P(Purchase_i) $ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; # calculate logit probabilities
</span></span><span class=line><span class=cl>&gt; RFMdata$Base.Probability &lt;- predict(model, RFMdata, type=&#34;response&#34;) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; kable(head(RFMdata,5),row.names = TRUE)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>|   | Recency| Frequency| Monetary| Purchase| Base.Probability|
</span></span><span class=line><span class=cl>|:--|-------:|---------:|--------:|--------:|----------------:|
</span></span><span class=line><span class=cl>|1  |     120|         7|    41.66|        0|        0.0030728|
</span></span><span class=line><span class=cl>|2  |      90|         9|    46.71|        0|        0.0008332|
</span></span><span class=line><span class=cl>|3  |     120|         6|   103.99|        1|        0.9833225|
</span></span><span class=line><span class=cl>|4  |     270|        17|    37.13|        1|        0.9999999|
</span></span><span class=line><span class=cl>|5  |      60|         5|    88.92|        0|        0.0032378|
</span></span></code></pre></td></tr></table></div></div><blockquote><p>predict()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>predict() å‡½æ•°æ˜¯ R è¯­è¨€ä¸­çš„ä¸€ä¸ªå¸¸ç”¨å‡½æ•°ï¼Œç”¨äºå¯¹å·²æ‹Ÿåˆçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚å®ƒå¯ä»¥å¯¹æ–°çš„è§‚æµ‹æ•°æ®åº”ç”¨å·²ç»æ‹Ÿåˆå¥½çš„æ¨¡å‹ï¼Œä»è€Œç”Ÿæˆé¢„æµ‹å€¼ã€‚</div><h2 id=33-predicting-behaviour>3.3 Predicting behaviour</h2><p>We also calculate an indicator variable for whether individuals will purchase or not based on their predicted probabilities</p><p>æˆ‘ä»¬è¿˜æ ¹æ®ä»–ä»¬çš„é¢„æµ‹æ¦‚ç‡è®¡ç®—å‡ºä¸ªä½“æ˜¯å¦ä¼šè´­ä¹°çš„æŒ‡ç¤ºå˜é‡ã€‚</p><p>ç¬¦å· &ldquo;âŠ®&rdquo; ä»£è¡¨é€»è¾‘éï¼ˆnegationï¼‰æˆ–è€…â€œéâ€ã€‚æ‰€ä»¥æ•´ä¸ªå…¬å¼çš„å«ä¹‰æ˜¯ï¼šè´­ä¹°æ¦‚ç‡ä¸å¤§äºæˆ–ç­‰äº0.5ã€‚</p>$$
\neg [P(Purchase_i) \geq 0.5]
$$<p>If individualâ€™s predicted probability is greater or equal to 0.5, we predict he will make a purchase.<br>å¦‚æœä¸ªä½“çš„é¢„æµ‹æ¦‚ç‡å¤§äºæˆ–ç­‰äº0.5ï¼Œåˆ™æˆ‘ä»¬é¢„æµ‹ä»–ä¼šè´­ä¹°ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; # purchase vs. no purchase &lt;-&gt; p&gt;0.5 or p&lt;0.5
</span></span><span class=line><span class=cl>&gt; RFMdata$Predicted.Purchase &lt;- 1*(RFMdata$Base.Probability&gt;=0.5) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; kable(head(RFMdata,5),row.names = TRUE)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>|   | Recency| Frequency| Monetary| Purchase| Base.Probability| Predicted.Purchase|
</span></span><span class=line><span class=cl>|:--|-------:|---------:|--------:|--------:|----------------:|------------------:|
</span></span><span class=line><span class=cl>|1  |     120|         7|    41.66|        0|        0.0030728|                  0|
</span></span><span class=line><span class=cl>|2  |      90|         9|    46.71|        0|        0.0008332|                  0|
</span></span><span class=line><span class=cl>|3  |     120|         6|   103.99|        1|        0.9833225|                  1|
</span></span><span class=line><span class=cl>|4  |     270|        17|    37.13|        1|        0.9999999|                  1|
</span></span><span class=line><span class=cl>|5  |      60|         5|    88.92|        0|        0.0032378|                  0|
</span></span></code></pre></td></tr></table></div></div><h2 id=34-evaluating-the-model>3.4 Evaluating the model</h2><p>Now, we compute a confusion matrix between predicted purchases and actual purchase behaviour.</p><p>ç°åœ¨ï¼Œæˆ‘ä»¬è®¡ç®—é¢„æµ‹è´­ä¹°å’Œå®é™…è´­ä¹°è¡Œä¸ºä¹‹é—´çš„æ··æ·†çŸ©é˜µã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; confusionMatrix(table(RFMdata$Predicted.Purchase,RFMdata$Purchase),positive = &#34;1&#34;)
</span></span><span class=line><span class=cl>Confusion Matrix and Statistics
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>     0  1
</span></span><span class=line><span class=cl>  0 51  2
</span></span><span class=line><span class=cl>  1  4 43
</span></span><span class=line><span class=cl>                                         
</span></span><span class=line><span class=cl>               Accuracy : 0.94           
</span></span><span class=line><span class=cl>                 95% CI : (0.874, 0.9777)
</span></span><span class=line><span class=cl>    No Information Rate : 0.55           
</span></span><span class=line><span class=cl>    P-Value [Acc &gt; NIR] : &lt;2e-16         
</span></span><span class=line><span class=cl>                                         
</span></span><span class=line><span class=cl>                  Kappa : 0.8793         
</span></span><span class=line><span class=cl>                                         Now we calculate
</span></span><span class=line><span class=cl> Mcnemar&#39;s Test P-Value : 0.6831         
</span></span><span class=line><span class=cl>                                         
</span></span><span class=line><span class=cl>            Sensitivity : 0.9556         
</span></span><span class=line><span class=cl>            Specificity : 0.9273         
</span></span><span class=line><span class=cl>         Pos Pred Value : 0.9149         
</span></span><span class=line><span class=cl>         Neg Pred Value : 0.9623         
</span></span><span class=line><span class=cl>             Prevalence : 0.4500         
</span></span><span class=line><span class=cl>         Detection Rate : 0.4300         
</span></span><span class=line><span class=cl>   Detection Prevalence : 0.4700         
</span></span><span class=line><span class=cl>      Balanced Accuracy : 0.9414         
</span></span><span class=line><span class=cl>                                         
</span></span><span class=line><span class=cl>       &#39;Positive&#39; Class : 1   
</span></span></code></pre></td></tr></table></div></div><blockquote><p>confusionMatrix()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>confusionMatrix() å‡½æ•°æ˜¯ caret åŒ…ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè®¡ç®—åˆ†ç±»æ¨¡å‹çš„æ··æ·†çŸ©é˜µä»¥åŠå„ç§åˆ†ç±»æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡ã€çµæ•åº¦ã€ç‰¹å¼‚æ€§ç­‰ã€‚æ··æ·†çŸ©é˜µæ˜¯ä¸€ç§ç”¨äºè¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½çš„è¡¨æ ¼ï¼Œå…¶ä¸­è¡Œè¡¨ç¤ºçœŸå®ç±»åˆ«ï¼Œåˆ—è¡¨ç¤ºé¢„æµ‹ç±»åˆ«ã€‚<p>åœ¨å¸‚åœºè¥é”€åœºæ™¯ä¸­ï¼ŒconfusionMatrix() å‡½æ•°å¯ä»¥ç”¨äºè¯„ä¼°åˆ†ç±»æ¨¡å‹åœ¨é¢„æµ‹å®¢æˆ·è¡Œä¸ºæ–¹é¢çš„æ€§èƒ½ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å®é™…åº”ç”¨åœºæ™¯ï¼š</p><p>â€¢ å®¢æˆ·æµå¤±é¢„æµ‹ï¼šå‡è®¾ä½ æ­£åœ¨å¼€å±•å®¢æˆ·æµå¤±é¢„æµ‹é¡¹ç›®ã€‚ä½ å¯ä»¥ä½¿ç”¨å†å²æ•°æ®è®­ç»ƒä¸€ä¸ªæµå¤±é¢„æµ‹æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ confusionMatrix() å‡½æ•°æ¥è¯„ä¼°è¯¥æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡æ··æ·†çŸ©é˜µï¼Œä½ å¯ä»¥äº†è§£æ¨¡å‹æ­£ç¡®é¢„æµ‹æµå¤±å®¢æˆ·å’Œæœªæµå¤±å®¢æˆ·çš„æƒ…å†µï¼Œå¹¶è®¡ç®—å‡ºå‡†ç¡®ç‡ã€çµæ•åº¦ç­‰æŒ‡æ ‡ã€‚</p><p>â€¢ è¥é”€æ´»åŠ¨åé¦ˆï¼šå¦‚æœä½ è¿›è¡Œäº†ä¸€é¡¹å¸‚åœºè¥é”€æ´»åŠ¨ï¼Œä¾‹å¦‚å‘é€ç”µå­é‚®ä»¶æˆ–çŸ­ä¿¡è¥é”€æ´»åŠ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ confusionMatrix() å‡½æ•°æ¥è¯„ä¼°æ´»åŠ¨çš„æ•ˆæœã€‚ä½ å¯ä»¥å°†å®é™…æ´»åŠ¨çš„ç»“æœä¸é¢„æœŸç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œä»¥äº†è§£æ´»åŠ¨çš„æˆåŠŸç‡ä»¥åŠæ˜¯å¦æœ‰å¿…è¦è°ƒæ•´ä½ çš„è¥é”€ç­–ç•¥ã€‚</p><p>â€¢ å®¢æˆ·åˆ†ç¾¤ï¼šåœ¨å®¢æˆ·åˆ†ç¾¤é¡¹ç›®ä¸­ï¼Œä½ å¯èƒ½ä½¿ç”¨èšç±»ç®—æ³•å°†å®¢æˆ·åˆ†æˆä¸åŒçš„ç¾¤ä½“ã€‚ä½ å¯ä»¥ä½¿ç”¨ confusionMatrix() å‡½æ•°æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œä¾‹å¦‚æ¯”è¾ƒèšç±»ç»“æœä¸çœŸå®çš„å®¢æˆ·ç‰¹å¾ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚è¿™å¯ä»¥å¸®åŠ©ä½ ç¡®å®šæ˜¯å¦éœ€è¦é‡æ–°è°ƒæ•´åˆ†ç¾¤æ–¹æ³•æˆ–è€…æ”¹è¿›æ•°æ®è´¨é‡ã€‚</p><p>â€¢ äº§å“æ¨èç³»ç»Ÿï¼šå¦‚æœä½ æ­£åœ¨å¼€å‘ä¸€ä¸ªäº§å“æ¨èç³»ç»Ÿï¼Œä½ å¯ä»¥ä½¿ç”¨ confusionMatrix() å‡½æ•°æ¥è¯„ä¼°ç³»ç»Ÿçš„å‡†ç¡®æ€§ã€‚ä½ å¯ä»¥æ¯”è¾ƒç³»ç»Ÿæ¨èçš„äº§å“ä¸ç”¨æˆ·å®é™…è´­ä¹°çš„äº§å“ä¹‹é—´çš„åŒ¹é…æƒ…å†µï¼Œå¹¶è®¡ç®—å‡ºå‡†ç¡®ç‡ã€å¬å›ç‡ç­‰æŒ‡æ ‡ï¼Œä»¥äº†è§£ç³»ç»Ÿçš„æ€§èƒ½å’Œç”¨æˆ·çš„æ»¡æ„åº¦ã€‚</p></div><p>We can also plot the receiver operating characteristic (ROC) curve, which illustrates the diagnostic ability of a binary logit model. It is created by plotting the true positive rate (TPR) against the false positive rate (FPR) â€“ at various decision threshold values for prediction.<br>ROC curve can be quickly evaluated using the area under the curve (AUC) metric, which captures the overall quality of the classifier. The greater the AUC, the better. AUC of 1.0 represents a perfect classifier, AUC of 0.5 (diagonal line) represents a worthless classifier. As we see, the binary logit classifier does a good job of predicting purchases on the training data.</p><p>æˆ‘ä»¬è¿˜å¯ä»¥ç»˜åˆ¶æ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼ˆROCæ›²çº¿ï¼‰ï¼Œå®ƒå±•ç¤ºäº†äºŒå…ƒLogitæ¨¡å‹çš„è¯Šæ–­èƒ½åŠ›ã€‚ROCæ›²çº¿é€šè¿‡åœ¨ä¸åŒçš„é¢„æµ‹å†³ç­–é˜ˆå€¼ä¸‹ç»˜åˆ¶çœŸæ­£ç‡ï¼ˆTPRï¼‰ä¸å‡æ­£ç‡ï¼ˆFPRï¼‰ä¹‹é—´çš„å…³ç³»æ¥åˆ›å»ºã€‚<br>ROCæ›²çº¿å¯ä»¥é€šè¿‡æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰æŒ‡æ ‡è¿›è¡Œå¿«é€Ÿè¯„ä¼°ï¼Œè¯¥æŒ‡æ ‡æ•æ‰äº†åˆ†ç±»å™¨çš„æ•´ä½“è´¨é‡ã€‚AUCè¶Šå¤§ï¼Œåˆ†ç±»å™¨çš„æ€§èƒ½è¶Šå¥½ã€‚AUCä¸º1.0è¡¨ç¤ºå®Œç¾çš„åˆ†ç±»å™¨ï¼ŒAUCä¸º0.5ï¼ˆå¯¹è§’çº¿ï¼‰è¡¨ç¤ºä¸€ä¸ªæ¯«æ— ä»·å€¼çš„åˆ†ç±»å™¨ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼ŒäºŒå…ƒLogitåˆ†ç±»å™¨åœ¨è®­ç»ƒæ•°æ®ä¸Šé¢„æµ‹è´­ä¹°è¡Œä¸ºçš„æ•ˆæœè‰¯å¥½ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; rocobj &lt;- roc(RFMdata$Purchase, RFMdata$Base.Probability)
</span></span><span class=line><span class=cl>Setting levels: control = 0, case = 1
</span></span><span class=line><span class=cl>Setting direction: controls &lt; cases
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; {plot(rocobj,legacy.axes=TRUE)
</span></span><span class=line><span class=cl>  text(0.5, 0.8, labels = sprintf(&#34;AUC = %.5f&#34;,rocobj$auc))}
</span></span></code></pre></td></tr></table></div></div><blockquote><p>roc()</p></blockquote><div style=background-color:#f0f0f0;padding:10px>roc() å‡½æ•°æ˜¯ pROC åŒ…ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè®¡ç®—æ¥æ”¶è€…æ“ä½œç‰¹å¾ï¼ˆReceiver Operating Characteristicï¼ŒROCï¼‰æ›²çº¿ä»¥åŠè®¡ç®—æ›²çº¿ä¸‹é¢ç§¯ï¼ˆArea Under the Curveï¼ŒAUCï¼‰ã€‚ROC æ›²çº¿æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°äºŒå…ƒåˆ†ç±»å™¨æ€§èƒ½çš„å›¾å½¢å·¥å…·ï¼Œå®ƒæ˜¾ç¤ºäº†åœ¨ä¸åŒåˆ†ç±»é˜ˆå€¼ä¸‹çœŸæ­£ä¾‹ç‡ï¼ˆTrue Positive Rateï¼ŒTPRï¼Œåˆç§°ä¸ºçµæ•åº¦ï¼‰ä¸å‡æ­£ä¾‹ç‡ï¼ˆFalse Positive Rateï¼ŒFPRï¼‰ä¹‹é—´çš„å…³ç³»ã€‚</div><p>{% asset_image week4_plot.png %}</p><p>Finally, we predict new probabilities under a hypothetical scenario that everyoneâ€™s Monetary variable went up by one unit.</p>$$
V_{\text{new}} = \beta_0 + \beta_1 \text{Recency} + \beta_2 \text{Frequency} + \beta_3 (\text{Monetary} + 1)
$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&gt; # calculate new logit probabilities (Monetary+1)
</span></span><span class=line><span class=cl>&gt; RFMdata_new &lt;- RFMdata
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; RFMdata_new$Monetary &lt;- RFMdata_new$Monetary + 1 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&gt; RFMdata$New.Probability &lt;- predict(model, RFMdata_new, type=&#34;response&#34;)
</span></span></code></pre></td></tr></table></div></div><p>We compare mean new probability across individuals to the mean of old probabilities, and also calculate the lift metric.</p><p>æˆ‘ä»¬æ¯”è¾ƒå„ä¸ªä¸ªä½“çš„æ–°æ¦‚ç‡å‡å€¼ä¸æ—§æ¦‚ç‡å‡å€¼ï¼Œå¹¶è®¡ç®—æå‡åº¦é‡ã€‚</p>$$ P(Purchase_i) = \frac{1}{N} \sum_{i=1}^{N} \frac{\exp(V_{bi})}{\exp(V_{bi}) + 1} $$$$ P(Purchase_{\text{new}}) = \frac{1}{N} \sum_{i=1}^{N} \frac{\exp(V_{\text{new}})}{\exp(V_{\text{new}}) + 1} $$$$ \text{Lift} = \frac{p_{\text{new}} - p_{\text{old}}}{p_{\text{old}}} $$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=o>&gt;</span> <span class=c1># mean predicted base probability</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>mean</span><span class=p>(</span><span class=n>RFMdata</span><span class=o>$</span><span class=n>Base</span><span class=o>.</span><span class=n>Probability</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=mf>0.45</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=c1># mean new predicted probability</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>mean</span><span class=p>(</span><span class=n>RFMdata</span><span class=o>$</span><span class=n>New</span><span class=o>.</span><span class=n>Probability</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=mf>0.4578851</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=c1># lift</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=p>(</span><span class=n>mean</span><span class=p>(</span><span class=n>RFMdata</span><span class=o>$</span><span class=n>New</span><span class=o>.</span><span class=n>Probability</span><span class=p>)</span> <span class=o>-</span> <span class=n>mean</span><span class=p>(</span><span class=n>RFMdata</span><span class=o>$</span><span class=n>Base</span><span class=o>.</span><span class=n>Probability</span><span class=p>))</span><span class=o>/</span><span class=n>mean</span><span class=p>(</span><span class=n>RFMdata</span><span class=o>$</span><span class=n>Base</span><span class=o>.</span><span class=n>Probability</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=mf>0.01752255</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=c1># remove predicted purchase variable</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>RFMdata</span><span class=o>$</span><span class=n>Predicted</span><span class=o>.</span><span class=n>Purchase</span> <span class=o>&lt;-</span> <span class=n>NULL</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=c1># data</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=n>kable</span><span class=p>(</span><span class=n>head</span><span class=p>(</span><span class=n>RFMdata</span><span class=p>,</span><span class=mi>5</span><span class=p>),</span><span class=n>row</span><span class=o>.</span><span class=n>names</span> <span class=o>=</span> <span class=n>TRUE</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>|</span>   <span class=o>|</span> <span class=n>Recency</span><span class=o>|</span> <span class=n>Frequency</span><span class=o>|</span> <span class=n>Monetary</span><span class=o>|</span> <span class=n>Purchase</span><span class=o>|</span> <span class=n>Base</span><span class=o>.</span><span class=n>Probability</span><span class=o>|</span> <span class=n>New</span><span class=o>.</span><span class=n>Probability</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=p>:</span><span class=o>--|-------</span><span class=p>:</span><span class=o>|---------</span><span class=p>:</span><span class=o>|--------</span><span class=p>:</span><span class=o>|--------</span><span class=p>:</span><span class=o>|----------------</span><span class=p>:</span><span class=o>|---------------</span><span class=p>:</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=mi>1</span>  <span class=o>|</span>     <span class=mi>120</span><span class=o>|</span>         <span class=mi>7</span><span class=o>|</span>    <span class=mf>41.66</span><span class=o>|</span>        <span class=mi>0</span><span class=o>|</span>        <span class=mf>0.0030728</span><span class=o>|</span>       <span class=mf>0.0036319</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=mi>2</span>  <span class=o>|</span>      <span class=mi>90</span><span class=o>|</span>         <span class=mi>9</span><span class=o>|</span>    <span class=mf>46.71</span><span class=o>|</span>        <span class=mi>0</span><span class=o>|</span>        <span class=mf>0.0008332</span><span class=o>|</span>       <span class=mf>0.0009852</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=mi>3</span>  <span class=o>|</span>     <span class=mi>120</span><span class=o>|</span>         <span class=mi>6</span><span class=o>|</span>   <span class=mf>103.99</span><span class=o>|</span>        <span class=mi>1</span><span class=o>|</span>        <span class=mf>0.9833225</span><span class=o>|</span>       <span class=mf>0.9858611</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=mi>4</span>  <span class=o>|</span>     <span class=mi>270</span><span class=o>|</span>        <span class=mi>17</span><span class=o>|</span>    <span class=mf>37.13</span><span class=o>|</span>        <span class=mi>1</span><span class=o>|</span>        <span class=mf>0.9999999</span><span class=o>|</span>       <span class=mf>0.9999999</span><span class=o>|</span>
</span></span><span class=line><span class=cl><span class=o>|</span><span class=mi>5</span>  <span class=o>|</span>      <span class=mi>60</span><span class=o>|</span>         <span class=mi>5</span><span class=o>|</span>    <span class=mf>88.92</span><span class=o>|</span>        <span class=mi>0</span><span class=o>|</span>        <span class=mf>0.0032378</span><span class=o>|</span>       <span class=mf>0.0038267</span><span class=o>|</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=4-recap>4. Recap</h1><p>â€¢ Logistic regression is a powerful method and a particularly good fit for many marketing problems with binary outcomes. We will cover the choice model later for modelling product choice among sets of alternatives.<br>â€¢ Logistic regression relates a binary outcome such as purchase to predictors that may include continuous and factor variable by modelling the variableâ€™s association with the probability of the outcome.</p><blockquote><p>Although we performed logistic regression here with categorical predictors (factor variables) due to the structure of the amusement park sales data, we could also use continuous predictors in glm(). Just add those to the right-hand side of the model formula as we did with lm()<br>â€¢ A logistic regression model, also known as a logit model, is a member of the generalized linear model family and is fit using glm( , family = binomial).<br>â€¢ Coefficient in a logit model can be interpreted in terms of odds ratios, the degree to which they are associated with the increased or decreased likelihood of an outcome. This is done simply by exponentiating the coefficients with exp().<br>â€¢ A statistically significant result does not always mean that the model is appropriate. It is important to explore data thoroughly and construct models on the basis of careful consideration.<br>We saw that the estimated effect of promotion was positive when we estimated one model yet negative when we estimated another. This shows that it is crucial to explore data thoroughly before modelling or interpreting a model. For most marketing data, no model is ever definitive. However, through careful data exploration and consideration of multiple models, we may increase our confidence in our models and the inferences drawn from them.</p></blockquote><p>â€¢ é€»è¾‘å›å½’æ˜¯ä¸€ç§å¼ºå¤§çš„æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºè®¸å¤šå…·æœ‰äºŒå…ƒç»“æœçš„è¥é”€é—®é¢˜ã€‚æˆ‘ä»¬ç¨åå°†ä»‹ç»é€‰æ‹©æ¨¡å‹ï¼Œç”¨äºå¯¹ä¸€ç»„æ›¿ä»£å“ä¸­çš„äº§å“é€‰æ‹©è¿›è¡Œå»ºæ¨¡ã€‚<br>â€¢ é€»è¾‘å›å½’å°†äºŒå…ƒç»“æœï¼ˆå¦‚è´­ä¹°ï¼‰ä¸å¯èƒ½åŒ…æ‹¬è¿ç»­å’Œå› å­å˜é‡çš„é¢„æµ‹å˜é‡å…³è”èµ·æ¥ï¼Œæ–¹æ³•æ˜¯é€šè¿‡æ¨¡æ‹Ÿå˜é‡ä¸ç»“æœçš„æ¦‚ç‡ä¹‹é—´çš„å…³è”ã€‚</p><blockquote><p>å°½ç®¡æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨äº†å› å­å˜é‡ï¼ˆåˆ†ç±»å˜é‡ï¼‰æ‰§è¡Œé€»è¾‘å›å½’ï¼Œå› ä¸ºå¨±ä¹å›­é”€å”®æ•°æ®çš„ç»“æ„å¦‚æ­¤ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨glm()ä¸­ä½¿ç”¨è¿ç»­é¢„æµ‹å˜é‡ã€‚åªéœ€åƒæˆ‘ä»¬åœ¨lm()ä¸­é‚£æ ·å°†å®ƒä»¬æ·»åŠ åˆ°æ¨¡å‹å…¬å¼çš„å³ä¾§å³å¯ã€‚<br>â€¢ é€»è¾‘å›å½’æ¨¡å‹ï¼Œä¹Ÿç§°ä¸ºlogitæ¨¡å‹ï¼Œæ˜¯å¹¿ä¹‰çº¿æ€§æ¨¡å‹å®¶æ—çš„ä¸€å‘˜ï¼Œä½¿ç”¨glm()æ‹Ÿåˆï¼Œå®¶æ—è®¾ç½®ä¸ºbinomialã€‚<br>â€¢ åœ¨logitæ¨¡å‹ä¸­ï¼Œç³»æ•°å¯ä»¥é€šè¿‡å°†å…¶æŒ‡æ•°åŒ–ä¸ºexp()æ¥è§£é‡Šä¸ºå‡ ç‡æ¯”ï¼Œå³å®ƒä»¬ä¸ç»“æœçš„å¢åŠ æˆ–å‡å°‘å¯èƒ½æ€§çš„ç›¸å…³ç¨‹åº¦ã€‚<br>â€¢ ç»Ÿè®¡æ˜¾è‘—ç»“æœå¹¶ä¸æ€»æ„å‘³ç€æ¨¡å‹æ˜¯é€‚å½“çš„ã€‚åœ¨å»ºæ¨¡æˆ–è§£é‡Šæ¨¡å‹ä¹‹å‰ï¼Œå½»åº•æ¢ç´¢æ•°æ®å¹¶åŸºäºæ·±æ€ç†Ÿè™‘æ„å»ºæ¨¡å‹æ˜¯éå¸¸é‡è¦çš„ã€‚<br>æˆ‘ä»¬çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬ä¼°è®¡ä¸€ä¸ªæ¨¡å‹æ—¶ï¼Œä¿ƒé”€çš„ä¼°è®¡æ•ˆæœæ˜¯æ­£å‘çš„ï¼Œä½†å½“æˆ‘ä»¬ä¼°è®¡å¦ä¸€ä¸ªæ¨¡å‹æ—¶ï¼Œæ•ˆæœæ˜¯è´Ÿå‘çš„ã€‚è¿™è¡¨æ˜ï¼Œåœ¨å»ºæ¨¡æˆ–è§£é‡Šæ¨¡å‹ä¹‹å‰ï¼Œå½»åº•æ¢ç´¢æ•°æ®æ˜¯è‡³å…³é‡è¦çš„ã€‚å¯¹äºå¤§å¤šæ•°è¥é”€æ•°æ®ï¼Œæ²¡æœ‰ä¸€ä¸ªæ¨¡å‹æ˜¯ç»å¯¹çš„ã€‚ç„¶è€Œï¼Œé€šè¿‡å¯¹æ•°æ®è¿›è¡Œæ·±å…¥æ¢ç´¢å¹¶è€ƒè™‘å¤šä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¢åŠ å¯¹æ¨¡å‹åŠå…¶æ¨æ–­çš„ä¿¡å¿ƒã€‚</p></blockquote></section><footer class=article-footer><section class=article-tags><a href=/tags/r-language/>R-Language</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//weasley.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Kunkka</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>